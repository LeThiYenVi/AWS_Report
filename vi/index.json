[{"uri":"https://github.com/LeThiYenVi/AWS-Report.git/vi/","title":"Báo cáo thực tập","tags":[],"description":"","content":"Báo cáo thực tập Thông tin sinh viên: Họ và tên: Lê Thị Yến Vi\nSố điện thoại: 0985868349\nEmail: viltyse182544@fpt.edu.vn\nTrường: Đại học FPT\nNgành: Kỹ Thuật Phần Mềm\nLớp: AWS082025\nCông ty thực tập: Công ty TNHH Amazon Web Services Vietnam\nVị trí thực tập: FCJ Cloud Intern\nThời gian thực tập: Từ ngày 08/09/2025 đến ngày 12/12/2025\nNội dung báo cáo Worklog Proposal Các bài blogs đã dịch Các events đã tham gia Workshop Tự đánh giá Chia sẻ, đóng góp ý kiến "},{"uri":"https://github.com/LeThiYenVi/AWS-Report.git/vi/3-blogstranslated/3.1-blog1/","title":"Blog 1","tags":[],"description":"","content":" ⚠️ Lưu ý: Các thông tin dưới đây chỉ nhằm mục đích tham khảo, vui lòng không sao chép nguyên văn cho bài báo cáo của bạn kể cả warning này.\nBắt đầu với healthcare data lakes: Sử dụng microservices Các data lake có thể giúp các bệnh viện và cơ sở y tế chuyển dữ liệu thành những thông tin chi tiết về doanh nghiệp và duy trì hoạt động kinh doanh liên tục, đồng thời bảo vệ quyền riêng tư của bệnh nhân. Data lake là một kho lưu trữ tập trung, được quản lý và bảo mật để lưu trữ tất cả dữ liệu của bạn, cả ở dạng ban đầu và đã xử lý để phân tích. data lake cho phép bạn chia nhỏ các kho chứa dữ liệu và kết hợp các loại phân tích khác nhau để có được thông tin chi tiết và đưa ra các quyết định kinh doanh tốt hơn.\nBài đăng trên blog này là một phần của loạt bài lớn hơn về việc bắt đầu cài đặt data lake dành cho lĩnh vực y tế. Trong bài đăng blog cuối cùng của tôi trong loạt bài, “Bắt đầu với data lake dành cho lĩnh vực y tế: Đào sâu vào Amazon Cognito”, tôi tập trung vào các chi tiết cụ thể của việc sử dụng Amazon Cognito và Attribute Based Access Control (ABAC) để xác thực và ủy quyền người dùng trong giải pháp data lake y tế. Trong blog này, tôi trình bày chi tiết cách giải pháp đã phát triển ở cấp độ cơ bản, bao gồm các quyết định thiết kế mà tôi đã đưa ra và các tính năng bổ sung được sử dụng. Bạn có thể truy cập các code samples cho giải pháp tại Git repo này để tham khảo.\nHướng dẫn kiến trúc Thay đổi chính kể từ lần trình bày cuối cùng của kiến trúc tổng thể là việc tách dịch vụ đơn lẻ thành một tập hợp các dịch vụ nhỏ để cải thiện khả năng bảo trì và tính linh hoạt. Việc tích hợp một lượng lớn dữ liệu y tế khác nhau thường yêu cầu các trình kết nối chuyên biệt cho từng định dạng; bằng cách giữ chúng được đóng gói riêng biệt với microservices, chúng ta có thể thêm, xóa và sửa đổi từng trình kết nối mà không ảnh hưởng đến những kết nối khác. Các microservices được kết nối rời thông qua tin nhắn publish/subscribe tập trung trong cái mà tôi gọi là “pub/sub hub”.\nGiải pháp này đại diện cho những gì tôi sẽ coi là một lần lặp nước rút hợp lý khác từ last post của tôi. Phạm vi vẫn được giới hạn trong việc nhập và phân tích cú pháp đơn giản của các HL7v2 messages được định dạng theo Quy tắc mã hóa 7 (ER7) thông qua giao diện REST.\nKiến trúc giải pháp bây giờ như sau:\nHình 1. Kiến trúc tổng thể; những ô màu thể hiện những dịch vụ riêng biệt.\nMặc dù thuật ngữ microservices có một số sự mơ hồ cố hữu, một số đặc điểm là chung:\nChúng nhỏ, tự chủ, kết hợp rời rạc Có thể tái sử dụng, giao tiếp thông qua giao diện được xác định rõ Chuyên biệt để giải quyết một việc Thường được triển khai trong event-driven architecture Khi xác định vị trí tạo ranh giới giữa các microservices, cần cân nhắc:\nNội tại: công nghệ được sử dụng, hiệu suất, độ tin cậy, khả năng mở rộng Bên ngoài: chức năng phụ thuộc, tần suất thay đổi, khả năng tái sử dụng Con người: quyền sở hữu nhóm, quản lý cognitive load Lựa chọn công nghệ và phạm vi giao tiếp Phạm vi giao tiếp Các công nghệ / mô hình cần xem xét Trong một microservice Amazon Simple Queue Service (Amazon SQS), AWS Step Functions Giữa các microservices trong một dịch vụ AWS CloudFormation cross-stack references, Amazon Simple Notification Service (Amazon SNS) Giữa các dịch vụ Amazon EventBridge, AWS Cloud Map, Amazon API Gateway The pub/sub hub Việc sử dụng kiến trúc hub-and-spoke (hay message broker) hoạt động tốt với một số lượng nhỏ các microservices liên quan chặt chẽ.\nMỗi microservice chỉ phụ thuộc vào hub Kết nối giữa các microservice chỉ giới hạn ở nội dung của message được xuất Giảm số lượng synchronous calls vì pub/sub là push không đồng bộ một chiều Nhược điểm: cần phối hợp và giám sát để tránh microservice xử lý nhầm message.\nCore microservice Cung cấp dữ liệu nền tảng và lớp truyền thông, gồm:\nAmazon S3 bucket cho dữ liệu Amazon DynamoDB cho danh mục dữ liệu AWS Lambda để ghi message vào data lake và danh mục Amazon SNS topic làm hub Amazon S3 bucket cho artifacts như mã Lambda Chỉ cho phép truy cập ghi gián tiếp vào data lake qua hàm Lambda → đảm bảo nhất quán.\nFront door microservice Cung cấp API Gateway để tương tác REST bên ngoài Xác thực \u0026amp; ủy quyền dựa trên OIDC thông qua Amazon Cognito Cơ chế deduplication tự quản lý bằng DynamoDB thay vì SNS FIFO vì: SNS deduplication TTL chỉ 5 phút SNS FIFO yêu cầu SQS FIFO Chủ động báo cho sender biết message là bản sao Staging ER7 microservice Lambda “trigger” đăng ký với pub/sub hub, lọc message theo attribute Step Functions Express Workflow để chuyển ER7 → JSON Hai Lambda: Sửa format ER7 (newline, carriage return) Parsing logic Kết quả hoặc lỗi được đẩy lại vào pub/sub hub Tính năng mới trong giải pháp 1. AWS CloudFormation cross-stack references Ví dụ outputs trong core microservice:\nOutputs: Bucket: Value: !Ref Bucket Export: Name: !Sub ${AWS::StackName}-Bucket ArtifactBucket: Value: !Ref ArtifactBucket Export: Name: !Sub ${AWS::StackName}-ArtifactBucket Topic: Value: !Ref Topic Export: Name: !Sub ${AWS::StackName}-Topic Catalog: Value: !Ref Catalog Export: Name: !Sub ${AWS::StackName}-Catalog CatalogArn: Value: !GetAtt Catalog.Arn Export: Name: !Sub ${AWS::StackName}-CatalogArn "},{"uri":"https://github.com/LeThiYenVi/AWS-Report.git/vi/3-blogstranslated/3.2-blog2/","title":"Blog 2","tags":[],"description":"","content":" ⚠️ Lưu ý: Các thông tin dưới đây chỉ nhằm mục đích tham khảo, vui lòng không sao chép nguyên văn cho bài báo cáo của bạn kể cả warning này.\nBắt đầu với healthcare data lakes: Sử dụng microservices Các data lake có thể giúp các bệnh viện và cơ sở y tế chuyển dữ liệu thành những thông tin chi tiết về doanh nghiệp và duy trì hoạt động kinh doanh liên tục, đồng thời bảo vệ quyền riêng tư của bệnh nhân. Data lake là một kho lưu trữ tập trung, được quản lý và bảo mật để lưu trữ tất cả dữ liệu của bạn, cả ở dạng ban đầu và đã xử lý để phân tích. data lake cho phép bạn chia nhỏ các kho chứa dữ liệu và kết hợp các loại phân tích khác nhau để có được thông tin chi tiết và đưa ra các quyết định kinh doanh tốt hơn.\nBài đăng trên blog này là một phần của loạt bài lớn hơn về việc bắt đầu cài đặt data lake dành cho lĩnh vực y tế. Trong bài đăng blog cuối cùng của tôi trong loạt bài, “Bắt đầu với data lake dành cho lĩnh vực y tế: Đào sâu vào Amazon Cognito”, tôi tập trung vào các chi tiết cụ thể của việc sử dụng Amazon Cognito và Attribute Based Access Control (ABAC) để xác thực và ủy quyền người dùng trong giải pháp data lake y tế. Trong blog này, tôi trình bày chi tiết cách giải pháp đã phát triển ở cấp độ cơ bản, bao gồm các quyết định thiết kế mà tôi đã đưa ra và các tính năng bổ sung được sử dụng. Bạn có thể truy cập các code samples cho giải pháp tại Git repo này để tham khảo.\nHướng dẫn kiến trúc Thay đổi chính kể từ lần trình bày cuối cùng của kiến trúc tổng thể là việc tách dịch vụ đơn lẻ thành một tập hợp các dịch vụ nhỏ để cải thiện khả năng bảo trì và tính linh hoạt. Việc tích hợp một lượng lớn dữ liệu y tế khác nhau thường yêu cầu các trình kết nối chuyên biệt cho từng định dạng; bằng cách giữ chúng được đóng gói riêng biệt với microservices, chúng ta có thể thêm, xóa và sửa đổi từng trình kết nối mà không ảnh hưởng đến những kết nối khác. Các microservices được kết nối rời thông qua tin nhắn publish/subscribe tập trung trong cái mà tôi gọi là “pub/sub hub”.\nGiải pháp này đại diện cho những gì tôi sẽ coi là một lần lặp nước rút hợp lý khác từ last post của tôi. Phạm vi vẫn được giới hạn trong việc nhập và phân tích cú pháp đơn giản của các HL7v2 messages được định dạng theo Quy tắc mã hóa 7 (ER7) thông qua giao diện REST.\nKiến trúc giải pháp bây giờ như sau:\nHình 1. Kiến trúc tổng thể; những ô màu thể hiện những dịch vụ riêng biệt.\nMặc dù thuật ngữ microservices có một số sự mơ hồ cố hữu, một số đặc điểm là chung:\nChúng nhỏ, tự chủ, kết hợp rời rạc Có thể tái sử dụng, giao tiếp thông qua giao diện được xác định rõ Chuyên biệt để giải quyết một việc Thường được triển khai trong event-driven architecture Khi xác định vị trí tạo ranh giới giữa các microservices, cần cân nhắc:\nNội tại: công nghệ được sử dụng, hiệu suất, độ tin cậy, khả năng mở rộng Bên ngoài: chức năng phụ thuộc, tần suất thay đổi, khả năng tái sử dụng Con người: quyền sở hữu nhóm, quản lý cognitive load Lựa chọn công nghệ và phạm vi giao tiếp Phạm vi giao tiếp Các công nghệ / mô hình cần xem xét Trong một microservice Amazon Simple Queue Service (Amazon SQS), AWS Step Functions Giữa các microservices trong một dịch vụ AWS CloudFormation cross-stack references, Amazon Simple Notification Service (Amazon SNS) Giữa các dịch vụ Amazon EventBridge, AWS Cloud Map, Amazon API Gateway The pub/sub hub Việc sử dụng kiến trúc hub-and-spoke (hay message broker) hoạt động tốt với một số lượng nhỏ các microservices liên quan chặt chẽ.\nMỗi microservice chỉ phụ thuộc vào hub Kết nối giữa các microservice chỉ giới hạn ở nội dung của message được xuất Giảm số lượng synchronous calls vì pub/sub là push không đồng bộ một chiều Nhược điểm: cần phối hợp và giám sát để tránh microservice xử lý nhầm message.\nCore microservice Cung cấp dữ liệu nền tảng và lớp truyền thông, gồm:\nAmazon S3 bucket cho dữ liệu Amazon DynamoDB cho danh mục dữ liệu AWS Lambda để ghi message vào data lake và danh mục Amazon SNS topic làm hub Amazon S3 bucket cho artifacts như mã Lambda Chỉ cho phép truy cập ghi gián tiếp vào data lake qua hàm Lambda → đảm bảo nhất quán.\nFront door microservice Cung cấp API Gateway để tương tác REST bên ngoài Xác thực \u0026amp; ủy quyền dựa trên OIDC thông qua Amazon Cognito Cơ chế deduplication tự quản lý bằng DynamoDB thay vì SNS FIFO vì: SNS deduplication TTL chỉ 5 phút SNS FIFO yêu cầu SQS FIFO Chủ động báo cho sender biết message là bản sao Staging ER7 microservice Lambda “trigger” đăng ký với pub/sub hub, lọc message theo attribute Step Functions Express Workflow để chuyển ER7 → JSON Hai Lambda: Sửa format ER7 (newline, carriage return) Parsing logic Kết quả hoặc lỗi được đẩy lại vào pub/sub hub Tính năng mới trong giải pháp 1. AWS CloudFormation cross-stack references Ví dụ outputs trong core microservice:\nOutputs: Bucket: Value: !Ref Bucket Export: Name: !Sub ${AWS::StackName}-Bucket ArtifactBucket: Value: !Ref ArtifactBucket Export: Name: !Sub ${AWS::StackName}-ArtifactBucket Topic: Value: !Ref Topic Export: Name: !Sub ${AWS::StackName}-Topic Catalog: Value: !Ref Catalog Export: Name: !Sub ${AWS::StackName}-Catalog CatalogArn: Value: !GetAtt Catalog.Arn Export: Name: !Sub ${AWS::StackName}-CatalogArn "},{"uri":"https://github.com/LeThiYenVi/AWS-Report.git/vi/3-blogstranslated/3.3-blog3/","title":"Blog 3","tags":[],"description":"","content":" ⚠️ Lưu ý: Các thông tin dưới đây chỉ nhằm mục đích tham khảo, vui lòng không sao chép nguyên văn cho bài báo cáo của bạn kể cả warning này.\nBắt đầu với healthcare data lakes: Sử dụng microservices Các data lake có thể giúp các bệnh viện và cơ sở y tế chuyển dữ liệu thành những thông tin chi tiết về doanh nghiệp và duy trì hoạt động kinh doanh liên tục, đồng thời bảo vệ quyền riêng tư của bệnh nhân. Data lake là một kho lưu trữ tập trung, được quản lý và bảo mật để lưu trữ tất cả dữ liệu của bạn, cả ở dạng ban đầu và đã xử lý để phân tích. data lake cho phép bạn chia nhỏ các kho chứa dữ liệu và kết hợp các loại phân tích khác nhau để có được thông tin chi tiết và đưa ra các quyết định kinh doanh tốt hơn.\nBài đăng trên blog này là một phần của loạt bài lớn hơn về việc bắt đầu cài đặt data lake dành cho lĩnh vực y tế. Trong bài đăng blog cuối cùng của tôi trong loạt bài, “Bắt đầu với data lake dành cho lĩnh vực y tế: Đào sâu vào Amazon Cognito”, tôi tập trung vào các chi tiết cụ thể của việc sử dụng Amazon Cognito và Attribute Based Access Control (ABAC) để xác thực và ủy quyền người dùng trong giải pháp data lake y tế. Trong blog này, tôi trình bày chi tiết cách giải pháp đã phát triển ở cấp độ cơ bản, bao gồm các quyết định thiết kế mà tôi đã đưa ra và các tính năng bổ sung được sử dụng. Bạn có thể truy cập các code samples cho giải pháp tại Git repo này để tham khảo.\nHướng dẫn kiến trúc Thay đổi chính kể từ lần trình bày cuối cùng của kiến trúc tổng thể là việc tách dịch vụ đơn lẻ thành một tập hợp các dịch vụ nhỏ để cải thiện khả năng bảo trì và tính linh hoạt. Việc tích hợp một lượng lớn dữ liệu y tế khác nhau thường yêu cầu các trình kết nối chuyên biệt cho từng định dạng; bằng cách giữ chúng được đóng gói riêng biệt với microservices, chúng ta có thể thêm, xóa và sửa đổi từng trình kết nối mà không ảnh hưởng đến những kết nối khác. Các microservices được kết nối rời thông qua tin nhắn publish/subscribe tập trung trong cái mà tôi gọi là “pub/sub hub”.\nGiải pháp này đại diện cho những gì tôi sẽ coi là một lần lặp nước rút hợp lý khác từ last post của tôi. Phạm vi vẫn được giới hạn trong việc nhập và phân tích cú pháp đơn giản của các HL7v2 messages được định dạng theo Quy tắc mã hóa 7 (ER7) thông qua giao diện REST.\nKiến trúc giải pháp bây giờ như sau:\nHình 1. Kiến trúc tổng thể; những ô màu thể hiện những dịch vụ riêng biệt.\nMặc dù thuật ngữ microservices có một số sự mơ hồ cố hữu, một số đặc điểm là chung:\nChúng nhỏ, tự chủ, kết hợp rời rạc Có thể tái sử dụng, giao tiếp thông qua giao diện được xác định rõ Chuyên biệt để giải quyết một việc Thường được triển khai trong event-driven architecture Khi xác định vị trí tạo ranh giới giữa các microservices, cần cân nhắc:\nNội tại: công nghệ được sử dụng, hiệu suất, độ tin cậy, khả năng mở rộng Bên ngoài: chức năng phụ thuộc, tần suất thay đổi, khả năng tái sử dụng Con người: quyền sở hữu nhóm, quản lý cognitive load Lựa chọn công nghệ và phạm vi giao tiếp Phạm vi giao tiếp Các công nghệ / mô hình cần xem xét Trong một microservice Amazon Simple Queue Service (Amazon SQS), AWS Step Functions Giữa các microservices trong một dịch vụ AWS CloudFormation cross-stack references, Amazon Simple Notification Service (Amazon SNS) Giữa các dịch vụ Amazon EventBridge, AWS Cloud Map, Amazon API Gateway The pub/sub hub Việc sử dụng kiến trúc hub-and-spoke (hay message broker) hoạt động tốt với một số lượng nhỏ các microservices liên quan chặt chẽ.\nMỗi microservice chỉ phụ thuộc vào hub Kết nối giữa các microservice chỉ giới hạn ở nội dung của message được xuất Giảm số lượng synchronous calls vì pub/sub là push không đồng bộ một chiều Nhược điểm: cần phối hợp và giám sát để tránh microservice xử lý nhầm message.\nCore microservice Cung cấp dữ liệu nền tảng và lớp truyền thông, gồm:\nAmazon S3 bucket cho dữ liệu Amazon DynamoDB cho danh mục dữ liệu AWS Lambda để ghi message vào data lake và danh mục Amazon SNS topic làm hub Amazon S3 bucket cho artifacts như mã Lambda Chỉ cho phép truy cập ghi gián tiếp vào data lake qua hàm Lambda → đảm bảo nhất quán.\nFront door microservice Cung cấp API Gateway để tương tác REST bên ngoài Xác thực \u0026amp; ủy quyền dựa trên OIDC thông qua Amazon Cognito Cơ chế deduplication tự quản lý bằng DynamoDB thay vì SNS FIFO vì: SNS deduplication TTL chỉ 5 phút SNS FIFO yêu cầu SQS FIFO Chủ động báo cho sender biết message là bản sao Staging ER7 microservice Lambda “trigger” đăng ký với pub/sub hub, lọc message theo attribute Step Functions Express Workflow để chuyển ER7 → JSON Hai Lambda: Sửa format ER7 (newline, carriage return) Parsing logic Kết quả hoặc lỗi được đẩy lại vào pub/sub hub Tính năng mới trong giải pháp 1. AWS CloudFormation cross-stack references Ví dụ outputs trong core microservice:\nOutputs: Bucket: Value: !Ref Bucket Export: Name: !Sub ${AWS::StackName}-Bucket ArtifactBucket: Value: !Ref ArtifactBucket Export: Name: !Sub ${AWS::StackName}-ArtifactBucket Topic: Value: !Ref Topic Export: Name: !Sub ${AWS::StackName}-Topic Catalog: Value: !Ref Catalog Export: Name: !Sub ${AWS::StackName}-Catalog CatalogArn: Value: !GetAtt Catalog.Arn Export: Name: !Sub ${AWS::StackName}-CatalogArn "},{"uri":"https://github.com/LeThiYenVi/AWS-Report.git/vi/3-blogstranslated/3.4-blog4/","title":"Blog 4","tags":[],"description":"","content":" ⚠️ Lưu ý: Các thông tin dưới đây chỉ nhằm mục đích tham khảo, vui lòng không sao chép nguyên văn cho bài báo cáo của bạn kể cả warning này.\nBắt đầu với healthcare data lakes: Sử dụng microservices Các data lake có thể giúp các bệnh viện và cơ sở y tế chuyển dữ liệu thành những thông tin chi tiết về doanh nghiệp và duy trì hoạt động kinh doanh liên tục, đồng thời bảo vệ quyền riêng tư của bệnh nhân. Data lake là một kho lưu trữ tập trung, được quản lý và bảo mật để lưu trữ tất cả dữ liệu của bạn, cả ở dạng ban đầu và đã xử lý để phân tích. data lake cho phép bạn chia nhỏ các kho chứa dữ liệu và kết hợp các loại phân tích khác nhau để có được thông tin chi tiết và đưa ra các quyết định kinh doanh tốt hơn.\nBài đăng trên blog này là một phần của loạt bài lớn hơn về việc bắt đầu cài đặt data lake dành cho lĩnh vực y tế. Trong bài đăng blog cuối cùng của tôi trong loạt bài, “Bắt đầu với data lake dành cho lĩnh vực y tế: Đào sâu vào Amazon Cognito”, tôi tập trung vào các chi tiết cụ thể của việc sử dụng Amazon Cognito và Attribute Based Access Control (ABAC) để xác thực và ủy quyền người dùng trong giải pháp data lake y tế. Trong blog này, tôi trình bày chi tiết cách giải pháp đã phát triển ở cấp độ cơ bản, bao gồm các quyết định thiết kế mà tôi đã đưa ra và các tính năng bổ sung được sử dụng. Bạn có thể truy cập các code samples cho giải pháp tại Git repo này để tham khảo.\nHướng dẫn kiến trúc Thay đổi chính kể từ lần trình bày cuối cùng của kiến trúc tổng thể là việc tách dịch vụ đơn lẻ thành một tập hợp các dịch vụ nhỏ để cải thiện khả năng bảo trì và tính linh hoạt. Việc tích hợp một lượng lớn dữ liệu y tế khác nhau thường yêu cầu các trình kết nối chuyên biệt cho từng định dạng; bằng cách giữ chúng được đóng gói riêng biệt với microservices, chúng ta có thể thêm, xóa và sửa đổi từng trình kết nối mà không ảnh hưởng đến những kết nối khác. Các microservices được kết nối rời thông qua tin nhắn publish/subscribe tập trung trong cái mà tôi gọi là “pub/sub hub”.\nGiải pháp này đại diện cho những gì tôi sẽ coi là một lần lặp nước rút hợp lý khác từ last post của tôi. Phạm vi vẫn được giới hạn trong việc nhập và phân tích cú pháp đơn giản của các HL7v2 messages được định dạng theo Quy tắc mã hóa 7 (ER7) thông qua giao diện REST.\nKiến trúc giải pháp bây giờ như sau:\nHình 1. Kiến trúc tổng thể; những ô màu thể hiện những dịch vụ riêng biệt.\nMặc dù thuật ngữ microservices có một số sự mơ hồ cố hữu, một số đặc điểm là chung:\nChúng nhỏ, tự chủ, kết hợp rời rạc Có thể tái sử dụng, giao tiếp thông qua giao diện được xác định rõ Chuyên biệt để giải quyết một việc Thường được triển khai trong event-driven architecture Khi xác định vị trí tạo ranh giới giữa các microservices, cần cân nhắc:\nNội tại: công nghệ được sử dụng, hiệu suất, độ tin cậy, khả năng mở rộng Bên ngoài: chức năng phụ thuộc, tần suất thay đổi, khả năng tái sử dụng Con người: quyền sở hữu nhóm, quản lý cognitive load Lựa chọn công nghệ và phạm vi giao tiếp Phạm vi giao tiếp Các công nghệ / mô hình cần xem xét Trong một microservice Amazon Simple Queue Service (Amazon SQS), AWS Step Functions Giữa các microservices trong một dịch vụ AWS CloudFormation cross-stack references, Amazon Simple Notification Service (Amazon SNS) Giữa các dịch vụ Amazon EventBridge, AWS Cloud Map, Amazon API Gateway The pub/sub hub Việc sử dụng kiến trúc hub-and-spoke (hay message broker) hoạt động tốt với một số lượng nhỏ các microservices liên quan chặt chẽ.\nMỗi microservice chỉ phụ thuộc vào hub Kết nối giữa các microservice chỉ giới hạn ở nội dung của message được xuất Giảm số lượng synchronous calls vì pub/sub là push không đồng bộ một chiều Nhược điểm: cần phối hợp và giám sát để tránh microservice xử lý nhầm message.\nCore microservice Cung cấp dữ liệu nền tảng và lớp truyền thông, gồm:\nAmazon S3 bucket cho dữ liệu Amazon DynamoDB cho danh mục dữ liệu AWS Lambda để ghi message vào data lake và danh mục Amazon SNS topic làm hub Amazon S3 bucket cho artifacts như mã Lambda Chỉ cho phép truy cập ghi gián tiếp vào data lake qua hàm Lambda → đảm bảo nhất quán.\nFront door microservice Cung cấp API Gateway để tương tác REST bên ngoài Xác thực \u0026amp; ủy quyền dựa trên OIDC thông qua Amazon Cognito Cơ chế deduplication tự quản lý bằng DynamoDB thay vì SNS FIFO vì: SNS deduplication TTL chỉ 5 phút SNS FIFO yêu cầu SQS FIFO Chủ động báo cho sender biết message là bản sao Staging ER7 microservice Lambda “trigger” đăng ký với pub/sub hub, lọc message theo attribute Step Functions Express Workflow để chuyển ER7 → JSON Hai Lambda: Sửa format ER7 (newline, carriage return) Parsing logic Kết quả hoặc lỗi được đẩy lại vào pub/sub hub Tính năng mới trong giải pháp 1. AWS CloudFormation cross-stack references Ví dụ outputs trong core microservice:\nOutputs: Bucket: Value: !Ref Bucket Export: Name: !Sub ${AWS::StackName}-Bucket ArtifactBucket: Value: !Ref ArtifactBucket Export: Name: !Sub ${AWS::StackName}-ArtifactBucket Topic: Value: !Ref Topic Export: Name: !Sub ${AWS::StackName}-Topic Catalog: Value: !Ref Catalog Export: Name: !Sub ${AWS::StackName}-Catalog CatalogArn: Value: !GetAtt Catalog.Arn Export: Name: !Sub ${AWS::StackName}-CatalogArn "},{"uri":"https://github.com/LeThiYenVi/AWS-Report.git/vi/3-blogstranslated/3.5-blog5/","title":"Blog 5","tags":[],"description":"","content":" ⚠️ Lưu ý: Các thông tin dưới đây chỉ nhằm mục đích tham khảo, vui lòng không sao chép nguyên văn cho bài báo cáo của bạn kể cả warning này.\nBắt đầu với healthcare data lakes: Sử dụng microservices Các data lake có thể giúp các bệnh viện và cơ sở y tế chuyển dữ liệu thành những thông tin chi tiết về doanh nghiệp và duy trì hoạt động kinh doanh liên tục, đồng thời bảo vệ quyền riêng tư của bệnh nhân. Data lake là một kho lưu trữ tập trung, được quản lý và bảo mật để lưu trữ tất cả dữ liệu của bạn, cả ở dạng ban đầu và đã xử lý để phân tích. data lake cho phép bạn chia nhỏ các kho chứa dữ liệu và kết hợp các loại phân tích khác nhau để có được thông tin chi tiết và đưa ra các quyết định kinh doanh tốt hơn.\nBài đăng trên blog này là một phần của loạt bài lớn hơn về việc bắt đầu cài đặt data lake dành cho lĩnh vực y tế. Trong bài đăng blog cuối cùng của tôi trong loạt bài, “Bắt đầu với data lake dành cho lĩnh vực y tế: Đào sâu vào Amazon Cognito”, tôi tập trung vào các chi tiết cụ thể của việc sử dụng Amazon Cognito và Attribute Based Access Control (ABAC) để xác thực và ủy quyền người dùng trong giải pháp data lake y tế. Trong blog này, tôi trình bày chi tiết cách giải pháp đã phát triển ở cấp độ cơ bản, bao gồm các quyết định thiết kế mà tôi đã đưa ra và các tính năng bổ sung được sử dụng. Bạn có thể truy cập các code samples cho giải pháp tại Git repo này để tham khảo.\nHướng dẫn kiến trúc Thay đổi chính kể từ lần trình bày cuối cùng của kiến trúc tổng thể là việc tách dịch vụ đơn lẻ thành một tập hợp các dịch vụ nhỏ để cải thiện khả năng bảo trì và tính linh hoạt. Việc tích hợp một lượng lớn dữ liệu y tế khác nhau thường yêu cầu các trình kết nối chuyên biệt cho từng định dạng; bằng cách giữ chúng được đóng gói riêng biệt với microservices, chúng ta có thể thêm, xóa và sửa đổi từng trình kết nối mà không ảnh hưởng đến những kết nối khác. Các microservices được kết nối rời thông qua tin nhắn publish/subscribe tập trung trong cái mà tôi gọi là “pub/sub hub”.\nGiải pháp này đại diện cho những gì tôi sẽ coi là một lần lặp nước rút hợp lý khác từ last post của tôi. Phạm vi vẫn được giới hạn trong việc nhập và phân tích cú pháp đơn giản của các HL7v2 messages được định dạng theo Quy tắc mã hóa 7 (ER7) thông qua giao diện REST.\nKiến trúc giải pháp bây giờ như sau:\nHình 1. Kiến trúc tổng thể; những ô màu thể hiện những dịch vụ riêng biệt.\nMặc dù thuật ngữ microservices có một số sự mơ hồ cố hữu, một số đặc điểm là chung:\nChúng nhỏ, tự chủ, kết hợp rời rạc Có thể tái sử dụng, giao tiếp thông qua giao diện được xác định rõ Chuyên biệt để giải quyết một việc Thường được triển khai trong event-driven architecture Khi xác định vị trí tạo ranh giới giữa các microservices, cần cân nhắc:\nNội tại: công nghệ được sử dụng, hiệu suất, độ tin cậy, khả năng mở rộng Bên ngoài: chức năng phụ thuộc, tần suất thay đổi, khả năng tái sử dụng Con người: quyền sở hữu nhóm, quản lý cognitive load Lựa chọn công nghệ và phạm vi giao tiếp Phạm vi giao tiếp Các công nghệ / mô hình cần xem xét Trong một microservice Amazon Simple Queue Service (Amazon SQS), AWS Step Functions Giữa các microservices trong một dịch vụ AWS CloudFormation cross-stack references, Amazon Simple Notification Service (Amazon SNS) Giữa các dịch vụ Amazon EventBridge, AWS Cloud Map, Amazon API Gateway The pub/sub hub Việc sử dụng kiến trúc hub-and-spoke (hay message broker) hoạt động tốt với một số lượng nhỏ các microservices liên quan chặt chẽ.\nMỗi microservice chỉ phụ thuộc vào hub Kết nối giữa các microservice chỉ giới hạn ở nội dung của message được xuất Giảm số lượng synchronous calls vì pub/sub là push không đồng bộ một chiều Nhược điểm: cần phối hợp và giám sát để tránh microservice xử lý nhầm message.\nCore microservice Cung cấp dữ liệu nền tảng và lớp truyền thông, gồm:\nAmazon S3 bucket cho dữ liệu Amazon DynamoDB cho danh mục dữ liệu AWS Lambda để ghi message vào data lake và danh mục Amazon SNS topic làm hub Amazon S3 bucket cho artifacts như mã Lambda Chỉ cho phép truy cập ghi gián tiếp vào data lake qua hàm Lambda → đảm bảo nhất quán.\nFront door microservice Cung cấp API Gateway để tương tác REST bên ngoài Xác thực \u0026amp; ủy quyền dựa trên OIDC thông qua Amazon Cognito Cơ chế deduplication tự quản lý bằng DynamoDB thay vì SNS FIFO vì: SNS deduplication TTL chỉ 5 phút SNS FIFO yêu cầu SQS FIFO Chủ động báo cho sender biết message là bản sao Staging ER7 microservice Lambda “trigger” đăng ký với pub/sub hub, lọc message theo attribute Step Functions Express Workflow để chuyển ER7 → JSON Hai Lambda: Sửa format ER7 (newline, carriage return) Parsing logic Kết quả hoặc lỗi được đẩy lại vào pub/sub hub Tính năng mới trong giải pháp 1. AWS CloudFormation cross-stack references Ví dụ outputs trong core microservice:\nOutputs: Bucket: Value: !Ref Bucket Export: Name: !Sub ${AWS::StackName}-Bucket ArtifactBucket: Value: !Ref ArtifactBucket Export: Name: !Sub ${AWS::StackName}-ArtifactBucket Topic: Value: !Ref Topic Export: Name: !Sub ${AWS::StackName}-Topic Catalog: Value: !Ref Catalog Export: Name: !Sub ${AWS::StackName}-Catalog CatalogArn: Value: !GetAtt Catalog.Arn Export: Name: !Sub ${AWS::StackName}-CatalogArn "},{"uri":"https://github.com/LeThiYenVi/AWS-Report.git/vi/3-blogstranslated/3.6-blog6/","title":"Blog 6","tags":[],"description":"","content":" ⚠️ Lưu ý: Các thông tin dưới đây chỉ nhằm mục đích tham khảo, vui lòng không sao chép nguyên văn cho bài báo cáo của bạn kể cả warning này.\nBắt đầu với healthcare data lakes: Sử dụng microservices Các data lake có thể giúp các bệnh viện và cơ sở y tế chuyển dữ liệu thành những thông tin chi tiết về doanh nghiệp và duy trì hoạt động kinh doanh liên tục, đồng thời bảo vệ quyền riêng tư của bệnh nhân. Data lake là một kho lưu trữ tập trung, được quản lý và bảo mật để lưu trữ tất cả dữ liệu của bạn, cả ở dạng ban đầu và đã xử lý để phân tích. data lake cho phép bạn chia nhỏ các kho chứa dữ liệu và kết hợp các loại phân tích khác nhau để có được thông tin chi tiết và đưa ra các quyết định kinh doanh tốt hơn.\nBài đăng trên blog này là một phần của loạt bài lớn hơn về việc bắt đầu cài đặt data lake dành cho lĩnh vực y tế. Trong bài đăng blog cuối cùng của tôi trong loạt bài, “Bắt đầu với data lake dành cho lĩnh vực y tế: Đào sâu vào Amazon Cognito”, tôi tập trung vào các chi tiết cụ thể của việc sử dụng Amazon Cognito và Attribute Based Access Control (ABAC) để xác thực và ủy quyền người dùng trong giải pháp data lake y tế. Trong blog này, tôi trình bày chi tiết cách giải pháp đã phát triển ở cấp độ cơ bản, bao gồm các quyết định thiết kế mà tôi đã đưa ra và các tính năng bổ sung được sử dụng. Bạn có thể truy cập các code samples cho giải pháp tại Git repo này để tham khảo.\nHướng dẫn kiến trúc Thay đổi chính kể từ lần trình bày cuối cùng của kiến trúc tổng thể là việc tách dịch vụ đơn lẻ thành một tập hợp các dịch vụ nhỏ để cải thiện khả năng bảo trì và tính linh hoạt. Việc tích hợp một lượng lớn dữ liệu y tế khác nhau thường yêu cầu các trình kết nối chuyên biệt cho từng định dạng; bằng cách giữ chúng được đóng gói riêng biệt với microservices, chúng ta có thể thêm, xóa và sửa đổi từng trình kết nối mà không ảnh hưởng đến những kết nối khác. Các microservices được kết nối rời thông qua tin nhắn publish/subscribe tập trung trong cái mà tôi gọi là “pub/sub hub”.\nGiải pháp này đại diện cho những gì tôi sẽ coi là một lần lặp nước rút hợp lý khác từ last post của tôi. Phạm vi vẫn được giới hạn trong việc nhập và phân tích cú pháp đơn giản của các HL7v2 messages được định dạng theo Quy tắc mã hóa 7 (ER7) thông qua giao diện REST.\nKiến trúc giải pháp bây giờ như sau:\nHình 1. Kiến trúc tổng thể; những ô màu thể hiện những dịch vụ riêng biệt.\nMặc dù thuật ngữ microservices có một số sự mơ hồ cố hữu, một số đặc điểm là chung:\nChúng nhỏ, tự chủ, kết hợp rời rạc Có thể tái sử dụng, giao tiếp thông qua giao diện được xác định rõ Chuyên biệt để giải quyết một việc Thường được triển khai trong event-driven architecture Khi xác định vị trí tạo ranh giới giữa các microservices, cần cân nhắc:\nNội tại: công nghệ được sử dụng, hiệu suất, độ tin cậy, khả năng mở rộng Bên ngoài: chức năng phụ thuộc, tần suất thay đổi, khả năng tái sử dụng Con người: quyền sở hữu nhóm, quản lý cognitive load Lựa chọn công nghệ và phạm vi giao tiếp Phạm vi giao tiếp Các công nghệ / mô hình cần xem xét Trong một microservice Amazon Simple Queue Service (Amazon SQS), AWS Step Functions Giữa các microservices trong một dịch vụ AWS CloudFormation cross-stack references, Amazon Simple Notification Service (Amazon SNS) Giữa các dịch vụ Amazon EventBridge, AWS Cloud Map, Amazon API Gateway The pub/sub hub Việc sử dụng kiến trúc hub-and-spoke (hay message broker) hoạt động tốt với một số lượng nhỏ các microservices liên quan chặt chẽ.\nMỗi microservice chỉ phụ thuộc vào hub Kết nối giữa các microservice chỉ giới hạn ở nội dung của message được xuất Giảm số lượng synchronous calls vì pub/sub là push không đồng bộ một chiều Nhược điểm: cần phối hợp và giám sát để tránh microservice xử lý nhầm message.\nCore microservice Cung cấp dữ liệu nền tảng và lớp truyền thông, gồm:\nAmazon S3 bucket cho dữ liệu Amazon DynamoDB cho danh mục dữ liệu AWS Lambda để ghi message vào data lake và danh mục Amazon SNS topic làm hub Amazon S3 bucket cho artifacts như mã Lambda Chỉ cho phép truy cập ghi gián tiếp vào data lake qua hàm Lambda → đảm bảo nhất quán.\nFront door microservice Cung cấp API Gateway để tương tác REST bên ngoài Xác thực \u0026amp; ủy quyền dựa trên OIDC thông qua Amazon Cognito Cơ chế deduplication tự quản lý bằng DynamoDB thay vì SNS FIFO vì: SNS deduplication TTL chỉ 5 phút SNS FIFO yêu cầu SQS FIFO Chủ động báo cho sender biết message là bản sao Staging ER7 microservice Lambda “trigger” đăng ký với pub/sub hub, lọc message theo attribute Step Functions Express Workflow để chuyển ER7 → JSON Hai Lambda: Sửa format ER7 (newline, carriage return) Parsing logic Kết quả hoặc lỗi được đẩy lại vào pub/sub hub Tính năng mới trong giải pháp 1. AWS CloudFormation cross-stack references Ví dụ outputs trong core microservice:\nOutputs: Bucket: Value: !Ref Bucket Export: Name: !Sub ${AWS::StackName}-Bucket ArtifactBucket: Value: !Ref ArtifactBucket Export: Name: !Sub ${AWS::StackName}-ArtifactBucket Topic: Value: !Ref Topic Export: Name: !Sub ${AWS::StackName}-Topic Catalog: Value: !Ref Catalog Export: Name: !Sub ${AWS::StackName}-Catalog CatalogArn: Value: !GetAtt Catalog.Arn Export: Name: !Sub ${AWS::StackName}-CatalogArn "},{"uri":"https://github.com/LeThiYenVi/AWS-Report.git/vi/5-workshop/5.4-s3-onprem/5.4.1-prepare/","title":"Chuẩn bị tài nguyên","tags":[],"description":"","content":"Để chuẩn bị cho phần này của workshop, bạn sẽ cần phải:\nTriển khai CloudFormation stack Sửa đổi bảng định tuyến VPC. Các thành phần này hoạt động cùng nhau để mô phỏng DNS forwarding và name resolution.\nTriển khai CloudFormation stack Mẫu CloudFormation sẽ tạo các dịch vụ bổ sung để hỗ trợ mô phỏng môi trường truyền thống:\nMột Route 53 Private Hosted Zone lưu trữ các bản ghi Bí danh (Alias records) cho điểm cuối PrivateLink S3 Một Route 53 Inbound Resolver endpoint cho phép \u0026ldquo;VPC Cloud\u0026rdquo; giải quyết các yêu cầu resolve DNS gửi đến Private Hosted Zone Một Route 53 Outbound Resolver endpoint cho phép \u0026ldquo;VPC On-prem\u0026rdquo; chuyển tiếp các yêu cầu DNS cho S3 sang \u0026ldquo;VPC Cloud\u0026rdquo; Click link sau để mở AWS CloudFormation console. Mẫu yêu cầu sẽ được tải sẵn vào menu. Chấp nhận tất cả mặc định và nhấp vào Tạo stack. Có thể mất vài phút để triển khai stack hoàn tất. Bạn có thể tiếp tục với bước tiếp theo mà không cần đợi quá trình triển khai kết thúc.\nCập nhật bảng định tuyến private on-premise Workshop này sử dụng StrongSwan VPN chạy trên EC2 instance để mô phỏng khả năng kết nối giữa trung tâm dữ liệu truyền thống và môi trường cloud AWS. Hầu hết các thành phần bắt buộc đều được cung cấp trước khi bạn bắt đầu. Để hoàn tất cấu hình VPN, bạn sẽ sửa đổi bảng định tuyến \u0026ldquo;VPC on-prem\u0026rdquo; để hướng lưu lượng đến cloud đi qua StrongSwan VPN instance.\nMở Amazon EC2 console\nChọn instance tên infra-vpngw-test. Từ Details tab, copy Instance ID và paste vào text editor của bạn để sử dụng ở những bước tiếp theo\nĐi đến VPC menu bằng cách gõ \u0026ldquo;VPC\u0026rdquo; vào Search box\nClick vào Route Tables, chọn RT Private On-prem route table, chọn Routes tab, và click Edit Routes.\nClick Add route. Destination: CIDR block của Cloud VPC Target: ID của infra-vpngw-test instance (bạn đã lưu lại ở bước trên) Click Save changes "},{"uri":"https://github.com/LeThiYenVi/AWS-Report.git/vi/4-eventparticipated/4.1-event1/","title":"Event 1","tags":[],"description":"","content":"BÁO CÁO THU HOẠCH SỰ KIỆN Sự kiện: Vietnam Cloud Day 2025: Ho Chi Minh City Connect Edition for Builders\nChuyên đề (Track 1): GenAI \u0026amp; Data\n1. MỤC TIÊU THAM DỰ Việc tham dự sự kiện tập trung vào 4 mục tiêu cốt lõi nhằm nâng cao năng lực kỹ thuật và tư duy chiến lược:\nBảo mật GenAI: Tìm hiểu cơ chế bảo mật trong GenAI và AI Agent để đảm bảo an toàn dữ liệu doanh nghiệp. Quy trình phát triển (AI-DLC): Khám phá mô hình AI-Driven Development Lifecycle và cách tích hợp vào quy trình DevOps hiện tại. Nền tảng dữ liệu: Phương pháp xây dựng nền tảng dữ liệu hợp nhất (Unified Data Platform) tối ưu cho Analytics và AI. Cập nhật xu hướng: Nắm bắt chiến lược, tầm nhìn và các công nghệ GenAI mới nhất trên AWS. 2. DANH SÁCH DIỄN GIẢ (AWS EXPERTS) Sự kiện quy tụ các chuyên gia hàng đầu từ Amazon Web Services:\nJun Kai Loke – AI/ML Specialist SA Kien Nguyen – Solutions Architect Tamelly Lim – Storage Specialist SA Binh Tran – Senior Solutions Architect Taiki Dang – Solutions Architect Michael Armentano – Principal WW GTM Specialist 3. NỘI DUNG CHUYÊN MÔN NỔI BẬT 3.1. Nền tảng dữ liệu thống nhất (Unified Data Platform) Dữ liệu là nền tảng cốt lõi (\u0026ldquo;Data is the fuel\u0026rdquo;) để triển khai AI thành công.\nKiến trúc End-to-End: Quy trình khép kín từ Ingestion $\\rightarrow$ Lưu trữ $\\rightarrow$ Xử lý $\\rightarrow$ Truy cập $\\rightarrow$ Quản trị. Mục tiêu: Xóa bỏ \u0026ldquo;Silo\u0026rdquo; (sự cô lập) về dữ liệu, con người và quy trình. Hướng tới Self-service và chuẩn hóa Governance. Dịch vụ AWS chủ chốt: S3, Glue, Redshift, Lake Formation, OpenSearch, Kinesis/MSK. Công nghệ nổi bật: Zero-ETL integration (kết nối S3 $\\leftrightarrow$ Redshift, Aurora, DynamoDB\u0026hellip;) giúp giảm thiểu độ trễ và phức tạp trong luân chuyển dữ liệu. 3.2. Chiến lược \u0026amp; Công cụ GenAI trên AWS Amazon Bedrock: Dịch vụ chủ đạo cho phép lựa chọn Foundation Models (FM), tích hợp RAG, Guardrails, tối ưu hóa giữa chi phí và độ trễ. Amazon SageMaker Unified Studio: Nền tảng hợp nhất cho Data, Analytics \u0026amp; AI. Hỗ trợ MLOps toàn diện (Pipelines, Registry, Deployment, Monitoring). AI Agents - Tăng cường năng suất: Chuyển dịch từ Assistant đơn lẻ sang Multi-agent systems (như AgentCore, Amazon Nova). Hỗ trợ các framework: CrewAI, LangGraph, LlamaIndex. Ứng dụng thực tế: Chăm sóc khách hàng (CSKH), Business Intelligence (BI) với Amazon Q (trong QuickSight), tự động hóa quy trình nghiệp vụ. 3.3. Bảo mật \u0026amp; Độ tin cậy của GenAI (Security \u0026amp; Trust) Mô hình bảo mật đa lớp: Bảo vệ từ Hạ tầng $\\rightarrow$ Mô hình $\\rightarrow$ Ứng dụng. 5 Trụ cột bảo mật: Compliance, Privacy, Controls, Risk Management, Resilience. Giảm thiểu ảo giác (Hallucination): Kết hợp Prompt Engineering, RAG (Retrieval-Augmented Generation), và Fine-tuning. Quy trình RAG: Input $\\rightarrow$ Embedding $\\rightarrow$ Context $\\rightarrow$ LLM $\\rightarrow$ Output. Công cụ kiểm soát: Bedrock Guardrails, Human-in-the-loop, Observability (OpenTelemetry) để phòng chống rủi ro theo chuẩn OWASP LLM. 3.4. AI-Driven Development Lifecycle (AI-DLC) Một khái niệm mới về vòng đời phát triển phần mềm:\nTiến hóa: AI-Assisted $\\rightarrow$ AI-Driven $\\rightarrow$ AI-Managed. Các giai đoạn: Inception (Khởi tạo) $\\rightarrow$ Construction (Xây dựng) $\\rightarrow$ Operation (Vận hành). Triển khai: Tích hợp Infrastructure as Code (IaC), kiểm thử tự động, giám sát và quản trị rủi ro ngay trong quy trình. 4. TỔNG HỢP BÀI HỌC \u0026amp; TƯ DUY MỚI (KEY TAKEAWAYS) Sau sự kiện, tôi đã đúc kết được những thay đổi quan trọng về tư duy và chiến lược:\nTư duy thiết kế hệ thống (Design Thinking):\nPhải thiết kế hệ thống Dữ liệu \u0026amp; AI theo hướng End-to-end, kiên quyết loại bỏ Data Silo. Áp dụng nguyên tắc Self-service và Governance ngay từ giai đoạn đầu. Kiến trúc kỹ thuật (Technical Architecture):\nTận dụng sức mạnh của Zero-ETL và Lakehouse để hệ thống vận hành bền vững, dễ mở rộng. Kết hợp các mảnh ghép dịch vụ (S3, Glue, Bedrock\u0026hellip;) thành một nền tảng thống nhất thay vì các công cụ rời rạc. Chiến lược phát triển (Development Strategy):\nBusiness-first: Mọi quyết định công nghệ phải xuất phát từ bài toán kinh doanh. Dữ liệu và Bảo mật là nền tảng (\u0026ldquo;Foundation\u0026rdquo;), không có nền móng này thì AI không thể phát huy giá trị. Cân bằng: Giữa tốc độ đổi mới (Innovation) và chi phí/an toàn (Cost/Security). AI-DLC: Chuẩn hóa quy trình phát triển với sự tham gia của AI ở mọi giai đoạn (Code, Review, Test, Doc). 5. KẾ HOẠCH ỨNG DỤNG VÀO CÔNG VIỆC Dựa trên những kiến thức đã học, tôi đề xuất kế hoạch ứng dụng cụ thể như sau:\nTrong dự án thực tế:\nTriển khai thử nghiệm AI Agent cho module Đăng ký/Đăng nhập và Hỗ trợ khách hàng (Chatbot). Tích hợp Validation/Guardrails để đảm bảo an toàn dữ liệu đầu vào/ra của GenAI. Trong học tập \u0026amp; Teamwork:\nÁp dụng mô hình AI-DLC: Sử dụng AI để hỗ trợ viết code khung (boilerplate), tạo tài liệu kỹ thuật; con người tập trung vào Review và Approve. Phân tích rõ ràng khi nào sử dụng Serverless (Lambda) (cho tác vụ ngắn, sự kiện) và khi nào dùng Container (ECS/Fargate) (cho ứng dụng dài hạn, phức tạp). Trong vai trò cá nhân:\nRèn luyện tư duy viết tài liệu và thu thập yêu cầu theo hướng Business-first. Tập trung xây dựng Data Foundation vững chắc trước khi triển khai các mô hình AI phức tạp. 6. TRẢI NGHIỆM SỰ KIỆN \u0026amp; WORKSHOP (Phần ghi nhận trải nghiệm thực tế tại sự kiện)\nĐiểm nhấn đáng nhớ nhất là Workshop \u0026ldquo;GenAI-powered App-DB Modernization\u0026rdquo;. Đây là cơ hội quý giá để tôi thực hành hiện đại hóa ứng dụng và cơ sở dữ liệu:\nTrải nghiệm kỹ thuật: Tự tay thiết kế pipeline dữ liệu end-to-end và tiếp cận các công cụ mới nhất như Amazon Bedrock, AgentCore. Thực hành RAG: Hiểu sâu về cách giảm thiểu Hallucination thông qua việc phối hợp Prompt Engineering và RAG workflow. Kết nối chuyên gia: Trao đổi trực tiếp với các kỹ sư AWS về các Case Study thực tế, giúp củng cố niềm tin vào mô hình Multi-agent và AI-DLC. Kết luận: GenAI không chỉ là một công cụ xu hướng (trend), mà đòi hỏi một chiến lược tổng thể từ Kiến trúc hạ tầng, Dữ liệu đến Bảo mật để thực sự mang lại giá trị cho doanh nghiệp.\n"},{"uri":"https://github.com/LeThiYenVi/AWS-Report.git/vi/1-worklog/","title":"Nhật ký công việc","tags":[],"description":"","content":"Đây là nhật ký công việc chi tiết của chương trình First Cloud Journey (FCJ) Workforce được thực hiện trong 12 tuần (84 ngày). Mỗi tuần tập trung vào một khía cạnh khác nhau của AWS Cloud, từ nền tảng cơ bản đến các dịch vụ nâng cao, giúp xây dựng kiến thức vững chắc cho vai trò AWS Cloud Engineer.\nLộ trình học tập 12 tuần: Tuần 1: Nền tảng AWS - Làm quen với Account, IAM, VPC và EC2\nTạo tài khoản AWS, cấu hình IAM, hiểu về VPC và EC2 cơ bản Tuần 2: Bảo mật và Mạng lưới - Security Foundations \u0026amp; Networking\nThiết lập IAM Users/Groups, MFA, xây dựng Custom VPC với Public/Private Subnets Tuần 3: Điện toán và Định danh Ứng dụng - EC2 \u0026amp; Instance Profiling\nKhởi chạy EC2, sử dụng IAM Roles, quản lý EBS Volumes Tuần 4: Lưu trữ và Cơ sở dữ liệu - Cloud9, S3 \u0026amp; RDS\nThiết lập môi trường Cloud9, triển khai S3 Static Website, khởi tạo RDS MySQL Tuần 5: Khả năng mở rộng - Lightsail \u0026amp; Auto Scaling\nLàm quen với Docker, triển khai Application Load Balancer và Auto Scaling Groups Tuần 6: Giám sát và Tự động hóa - CloudWatch \u0026amp; Lambda\nXây dựng Dashboard, tạo Alarms, viết Lambda functions cho automation Tuần 7: Quản lý Hệ thống - AWS Systems Manager\nSử dụng SSM Session Manager, Run Command, quản lý fleet với Tagging Tuần 8: Infrastructure as Code - CloudFormation \u0026amp; CDK\nHọc CloudFormation, triển khai hạ tầng với AWS CDK (TypeScript) Tuần 9: Tối ưu hóa Mạng và Chi phí - VPC Flow Logs \u0026amp; Cost Optimization\nPhân tích network traffic, sử dụng Cost Explorer và Compute Optimizer Tuần 10: Kiến trúc Serverless - API Gateway, Lambda \u0026amp; DynamoDB\nXây dựng RESTful API hoàn chỉnh với serverless architecture Tuần 11: Quản trị và Tuân thủ - Governance \u0026amp; Well-Architected Review\nKiểm toán hạ tầng, quản lý Service Quotas, áp dụng Well-Architected Framework Tuần 12: Dự án Capstone và Chuẩn bị Nghề nghiệp - Career Readiness\nTriển khai dự án tổng hợp, luyện thi chứng chỉ SAA-C03, chuẩn bị portfolio "},{"uri":"https://github.com/LeThiYenVi/AWS-Report.git/vi/5-workshop/5.3-s3-vpc/5.3.1-create-gwe/","title":"Tạo một Gateway Endpoint","tags":[],"description":"","content":" Mở Amazon VPC console Trong thanh điều hướng, chọn Endpoints, click Create Endpoint: Bạn sẽ thấy 6 điểm cuối VPC hiện có hỗ trợ AWS Systems Manager (SSM). Các điểm cuối này được Mẫu CloudFormation triển khai tự động cho workshop này.\nTrong Create endpoint console: Đặt tên cho endpoint: s3-gwe Trong service category, chọn aws services Trong Services, gõ \u0026ldquo;s3\u0026rdquo; trong hộp tìm kiếm và chọn dịch vụ với loại gateway Đối với VPC, chọn VPC Cloud từ drop-down menu. Đối với Route tables, chọn bảng định tuyến mà đã liên kết với 2 subnets (lưu ý: đây không phải là bảng định tuyến chính cho VPC mà là bảng định tuyến thứ hai do CloudFormation tạo). Đối với Policy, để tùy chọn mặc định là Full access để cho phép toàn quyền truy cập vào dịch vụ. Bạn sẽ triển khai VPC endpoint policy trong phần sau để chứng minh việc hạn chế quyền truy cập vào S3 bucket dựa trên các policies. Không thêm tag vào VPC endpoint. Click Create endpoint, click x sau khi nhận được thông báo tạo thành công. "},{"uri":"https://github.com/LeThiYenVi/AWS-Report.git/vi/5-workshop/5.1-workshop-overview/","title":"Tổng quan Workshop","tags":[],"description":"","content":"Giới thiệu về EV Rental AI Agent AI Agent là gì? AI Agent là một hệ thống thông minh có thể:\nHiểu các câu hỏi bằng ngôn ngữ tự nhiên Tự động chọn và thực thi các công cụ/chức năng phù hợp Đưa ra quyết định dựa trên ngữ cảnh Cung cấp phản hồi có cấu trúc kèm dữ liệu Khác với chatbot truyền thống có câu trả lời cố định, AI Agent có thể suy luận và hành động một cách linh hoạt.\nKiến trúc hệ thống EV Rental AI Agent sử dụng kiến trúc đa tầng:\n┌─────────────────┐ │ Giao diện │ ← React Frontend (Chat UI) └────────┬────────┘ │ HTTP/REST ↓ ┌─────────────────┐ │ FastAPI Server │ ← Backend điều phối └────────┬────────┘ │ ┌────┴────────────────┐ ↓ ↓ ┌──────────┐ ┌──────────────┐ │ Strands │ │ PostgreSQL │ │ Agent SDK│ │ (Lịch sử) │ └────┬─────┘ └──────────────┘ │ ├─────→ AWS Bedrock (Claude 3.5 Sonnet) ├─────→ Knowledge Base (Chính sách/FAQ) └─────→ Backend API (Xe/Trạm sạc) Các thành phần chính Thành phần Công nghệ Vai trò AI Model AWS Bedrock - Claude 3.5 Sonnet Xử lý ngôn ngữ tự nhiên \u0026amp; sinh phản hồi Agent Framework Strands Agent SDK Tự động chọn tool \u0026amp; điều phối Backend API FastAPI (Python) REST API server cho logic agent Cơ sở dữ liệu PostgreSQL Lưu trữ lịch sử chat \u0026amp; phiên Frontend React + Chakra UI Giao diện chat tương tác Knowledge Base AWS Bedrock KB Truy xuất tài liệu (chính sách, FAQ) Các tính năng chính 1. Tìm kiếm Knowledge Base Agent tìm kiếm trong tài liệu đã upload để trả lời câu hỏi về:\nChính sách thuê xe Thông tin giá cả Quy trình đặt xe Điều khoản và điều kiện Ví dụ câu hỏi:\n\u0026ldquo;Chính sách thuê xe của bạn là gì?\u0026rdquo;\nPhản hồi của Agent:\n## 📋 Chính sách thuê xe VinFast ### 📄 Giấy tờ cần thiết: - ✅ CMND/CCCD còn hiệu lực - ✅ Bằng lái xe (Hạng B1 trở lên) - ✅ Chứng minh nơi cư trú ### 💰 Giá thuê: - **VF8**: 1,500,000 VNĐ/ngày - **VF9**: 2,000,000 VNĐ/ngày - **Đặt cọc**: 10,000,000 VNĐ 2. Tìm kiếm xe Agent truy vấn backend API để tìm xe available dựa trên:\nĐịa điểm (thành phố) Khoảng thời gian Mẫu/loại xe Định dạng phản hồi: Card xe tương tác với thông số kỹ thuật\n3. Tìm trạm sạc Agent lấy thông tin trạm sạc gần đó với:\nĐịa chỉ và trạng thái Số trạm sạc khả dụng Khoảng cách (nếu có vị trí) Định dạng phản hồi: Card trạm sạc với tình trạng thời gian thực\nMục tiêu Workshop Sau khi hoàn thành workshop, bạn sẽ có thể:\n✅ Cấu hình AWS Bedrock - Kích hoạt Claude models và tạo Knowledge Base ✅ Xây dựng Backend AI Agent - Sử dụng Strands SDK để điều phối nhiều tools ✅ Triển khai giao diện Chat - Tạo React chat UI responsive ✅ Kiểm thử End-to-End - Tương tác với AI agent và xác minh tất cả chức năng Công nghệ sử dụng AWS Services:\nAWS Bedrock (Claude 3.5 Sonnet v2) AWS Bedrock Knowledge Bases AWS S3 (lưu trữ tài liệu) IAM (quản lý truy cập) Backend:\nPython 3.11+ FastAPI Strands Agent SDK PostgreSQL SQLAlchemy Frontend:\nReact 18 Chakra UI Axios React Markdown Luồng Workshop Bước 1: Yêu cầu chuẩn bị ↓ Bước 2: Thiết lập AWS Bedrock \u0026amp; Knowledge Base ↓ Bước 3: Triển khai Backend API (FastAPI) ↓ Bước 4: Triển khai Frontend (React) ↓ Bước 5: Kiểm thử AI Agent ↓ Bước 6: Dọn dẹp tài nguyên Tiếp theo: Chuyển sang Yêu cầu chuẩn bị để chuẩn bị môi trường.\n"},{"uri":"https://github.com/LeThiYenVi/AWS-Report.git/vi/1-worklog/1.1-week1/","title":"Worklog Tuần 1","tags":[],"description":"","content":"Mục tiêu tuần 1: Kết nối, làm quen với các thành viên trong First Cloud Journey. Hiểu các dịch vụ nền tảng cốt lõi của AWS, bao gồm Account (Tài khoản), Billing (Thanh toán), IAM, VPC và EC2. Học cách quản lý chi phí và quyền truy cập. Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Làm quen với các thành viên FCJ - Đọc và lưu ý các nội quy, quy định tại đơn vị thực tập -Khám phá các dịch vụ AWS: Có cái nhìn tổng quan về các nhóm dịch vụ chính. 08/09/2025 08/09/2025 3 - Tìm hiểu về Tạo tài khoản AWS đầu tiên (Creating Your First AWS Account) - Tìm hiểu về Quản lý chi phí với AWS Budgets - Tìm hiểu về Nhận hỗ trợ với AWS Support - Thực hành: + Tạo tài khoản AWS Free Tier + Thiết lập cảnh báo ngân sách (budget alert) +\u0026hellip; 09/09/2025 09/09/2025 https://cloudjourney.awsstudygroup.com/ 4 - Tìm hiểu về Quản lý truy cập với AWS IAM (Identity and Access Management) - Thực hành: + Tạo IAM User, Group + Gắn các policy (chính sách) để cấp quyền 10/09/2025 10/09/2025 https://cloudjourney.awsstudygroup.com/ 5 - Tìm hiểu về Kiến thức mạng cơ bản với Amazon VPC (Virtual Private Cloud) - Tìm hiểu về Kiến thức tính toán cơ bản với Amazon EC2 (Elastic Compute Cloud) - Thực hành: + Thiết lập một VPC tùy chỉnh + Khởi chạy một EC2 instance vào VPC đó 11/09/2025 11/09/2025 https://cloudjourney.awsstudygroup.com/ 6 - Tìm hiểu về Instance Profiling với IAM Roles cho EC2 - Thực hành: + Tạo IAM Role cho EC2 + Gắn Role vào một EC2 instance hiện có 12/09/2025 12/09/2025 https://cloudjourney.awsstudygroup.com/ Kết quả đạt được tuần 1: Hiểu các nhóm dịch vụ nền tảng của AWS:\nCompute (Amazon EC2) Networking (Amazon VPC) Identity \u0026amp; Access Management (IAM) Billing \u0026amp; Cost Management (AWS Budgets) \u0026hellip; Đã tạo và cấu hình thành công tài khoản AWS Free Tier.\nLàm quen với AWS Management Console và biết cách tìm, truy cập, sử dụng dịch vụ qua giao diện web.\nĐã thực hành với Identity and Access Management (IAM), bao gồm:\nTạo Users và Groups Gắn Policies (Chính sách) Tạo IAM Roles cho EC2 \u0026hellip; Sử dụng AWS CLI để thực hiện các thao tác cơ bản như:\nKiểm tra thông tin tài khoản \u0026amp; cấu hình Lấy danh sách region Xem dịch vụ EC2 Tạo và quản lý key pair Kiểm tra thông tin dịch vụ đang chạy \u0026hellip; Có khả năng kết nối giữa giao diện web và CLI để quản lý tài nguyên AWS song song.\n\u0026hellip;\n"},{"uri":"https://github.com/LeThiYenVi/AWS-Report.git/vi/2-proposal/","title":"Bản đề xuất","tags":[],"description":"","content":"Hệ thống cho thuê xe điện tại điểm cố định Phần mềm cho thuê và trả xe điện tại các điểm cố định – Giải pháp di chuyển xanh cho đô thị thông minh 1. Tóm tắt điều hành Hệ thống EV Station-based Rental System được phát triển nhằm cung cấp một nền tảng tất cả trong một cho việc thuê và quản lý xe điện. Hệ thống tích hợp việc đặt xe theo thời gian thực, thanh toán và quản lý điểm thuê thông qua giải pháp đám mây thống nhất. Ứng dụng bao gồm app di động React Native và backend Spring Boot triển khai trên AWS ECS Fargate, với PostgreSQL (RDS) và Redis (ElastiCache) để lưu trữ dữ liệu và tăng tốc độ truy xuất. Xác thực người dùng được quản lý qua Amazon Cognito, trong khi phân phối nội dung toàn cầu được tối ưu bằng CloudFront. Thiết kế theo AWS Well-Architected Framework giúp nền tảng đảm bảo khả năng mở rộng, độ sẵn sàng cao, bảo mật, đồng thời tối ưu chi phí vận hành.\n2. Tuyên bố vấn đề Vấn đề hiện tại\nCác dịch vụ thuê xe điện hiện nay còn phân mảnh, buộc người dùng phải sử dụng nhiều ứng dụng khác nhau để tìm, đặt và quản lý xe tại các điểm cố định. Điều này gây ra sự bất tiện, hiệu suất chậm và trải nghiệm thiếu tin cậy — người dùng thường đến các điểm thuê “không khả dụng” hoặc “ngoại tuyến”, dẫn đến bức xúc và mất niềm tin.\nĐối với chủ xe và nhà vận hành, việc quản lý đội xe, điều phối đơn thuê và theo dõi bảo trì thủ công gây ra nhiều bất cập, giảm hiệu quả vận hành và mất doanh thu. Hiện chưa có nền tảng thống nhất và thời gian thực kết nối người thuê, chủ xe và nhà vận hành điểm thuê.\nGiải pháp\nHệ thống cho thuê và trả xe điện tại điểm cố định hợp nhất việc thuê và trả xe vào một nền tảng đám mây duy nhất. Hệ thống được xây dựng với React Native cho di động và Spring Boot cho backend, cung cấp tính năng đặt xe theo thời gian thực, theo dõi phương tiện và tích hợp thanh toán.\nCác dịch vụ AWS cốt lõi bao gồm ECS Fargate cho xử lý tính toán, RDS PostgreSQL cho lưu trữ dữ liệu, ElastiCache cho hiệu năng truy xuất nhanh, API Gateway và Cognito cho truy cập bảo mật, và CloudFront cho phân phối nội dung toàn cầu. Nền tảng hỗ trợ cả hình thức quản lý đội xe và chia sẻ xe P2P, cung cấp giao diện tập trung cho người dùng và nhà vận hành để quản lý việc thuê xe hiệu quả, an toàn và dễ mở rộng.\nLợi ích và hoàn vốn đầu tư (ROI)\nNền tảng loại bỏ sự phân mảnh ứng dụng và thao tác thủ công, mang lại trải nghiệm thống nhất, tự động cho cả người thuê và chủ xe. Dữ liệu thời gian thực đảm bảo độ tin cậy và minh bạch về tình trạng xe và điểm thuê.\nThiết kế theo AWS Well-Architected Framework giúp tối ưu chi phí vận hành thông qua mô hình serverless, trả theo mức sử dụng, đồng thời duy trì khả năng mở rộng và độ sẵn sàng 99,99%. Trong vòng 12–24 tháng, nền tảng dự kiến đạt 50.000+ người dùng hoạt động hàng tháng, hợp tác với 200+ điểm thuê, và mang lại hiệu quả đáng kể về thời gian, chi phí và vận hành cho cả người dùng và nhà vận hành.\n3. Kiến trúc giải pháp Nền tảng áp dụng kiến trúc AWS Serverless để quản lý dữ liệu từ 5 trạm dựa trên Raspberry Pi, có thể mở rộng lên 15 trạm. Dữ liệu được tiếp nhận qua AWS IoT Core, lưu trữ trong S3 data lake và xử lý bởi AWS Glue Crawlers và ETL jobs để chuyển đổi và tải vào một S3 bucket khác cho mục đích phân tích. Lambda và API Gateway xử lý bổ sung, trong khi Amplify với Next.js cung cấp bảng điều khiển được bảo mật bởi Cognito.\nDịch vụ AWS sử dụng\nAWS IoT Core: Tiếp nhận dữ liệu MQTT từ 5 trạm, mở rộng lên 15. AWS Lambda: Xử lý dữ liệu và kích hoạt Glue jobs (2 hàm). Amazon API Gateway: Giao tiếp với ứng dụng web. Amazon S3: Lưu trữ dữ liệu thô (data lake) và dữ liệu đã xử lý (2 bucket). AWS Glue: Crawlers lập chỉ mục dữ liệu, ETL jobs chuyển đổi và tải dữ liệu. AWS Amplify: Lưu trữ giao diện web Next.js. Amazon Cognito: Quản lý quyền truy cập cho người dùng phòng lab. Thiết kế thành phần\nThiết bị biên: Raspberry Pi thu thập và lọc dữ liệu cảm biến, gửi tới IoT Core. Tiếp nhận dữ liệu: AWS IoT Core nhận tin nhắn MQTT từ thiết bị biên. Lưu trữ dữ liệu: Dữ liệu thô lưu trong S3 data lake; dữ liệu đã xử lý lưu ở một S3 bucket khác. Xử lý dữ liệu: AWS Glue Crawlers lập chỉ mục dữ liệu; ETL jobs chuyển đổi để phân tích. Giao diện web: AWS Amplify lưu trữ ứng dụng Next.js cho bảng điều khiển và phân tích thời gian thực. Quản lý người dùng: Amazon Cognito giới hạn 5 tài khoản hoạt động. 4. Triển khai kỹ thuật Các giai đoạn triển khai\nDự án gồm 2 phần — thiết lập trạm thời tiết biên và xây dựng nền tảng thời tiết — mỗi phần trải qua 4 giai đoạn:\nNghiên cứu và vẽ kiến trúc: Nghiên cứu Raspberry Pi với cảm biến ESP32 và thiết kế kiến trúc AWS Serverless (1 tháng trước kỳ thực tập). Tính toán chi phí và kiểm tra tính khả thi: Sử dụng AWS Pricing Calculator để ước tính và điều chỉnh (Tháng 1). Điều chỉnh kiến trúc để tối ưu chi phí/giải pháp: Tinh chỉnh (ví dụ tối ưu Lambda với Next.js) để đảm bảo hiệu quả (Tháng 2). Phát triển, kiểm thử, triển khai: Lập trình Raspberry Pi, AWS services với CDK/SDK và ứng dụng Next.js, sau đó kiểm thử và đưa vào vận hành (Tháng 2–3). Yêu cầu kỹ thuật\nTrạm thời tiết biên: Cảm biến (nhiệt độ, độ ẩm, lượng mưa, tốc độ gió), vi điều khiển ESP32, Raspberry Pi làm thiết bị biên. Raspberry Pi chạy Raspbian, sử dụng Docker để lọc dữ liệu và gửi 1 MB/ngày/trạm qua MQTT qua Wi-Fi. Nền tảng thời tiết: Kiến thức thực tế về AWS Amplify (lưu trữ Next.js), Lambda (giảm thiểu do Next.js xử lý), AWS Glue (ETL), S3 (2 bucket), IoT Core (gateway và rules), và Cognito (5 người dùng). Sử dụng AWS CDK/SDK để lập trình (ví dụ IoT Core rules tới S3). Next.js giúp giảm tải Lambda cho ứng dụng web fullstack. 5. Lộ trình \u0026amp; Mốc triển khai Trước thực tập (Tháng 0): 1 tháng lên kế hoạch và đánh giá trạm cũ. Thực tập (Tháng 1–3): Tháng 1: Học AWS và nâng cấp phần cứng. Tháng 2: Thiết kế và điều chỉnh kiến trúc. Tháng 3: Triển khai, kiểm thử, đưa vào sử dụng. Sau triển khai: Nghiên cứu thêm trong vòng 1 năm. 6. Ước tính ngân sách Chi phí hạ tầng\nAWS Lambda: 0,00 USD/tháng (1.000 request, 512 MB lưu trữ). S3 Standard: 0,15 USD/tháng (6 GB, 2.100 request, 1 GB quét). Truyền dữ liệu: 0,02 USD/tháng (1 GB vào, 1 GB ra). AWS Amplify: 0,35 USD/tháng (256 MB, request 500 ms). Amazon API Gateway: 0,01 USD/tháng (2.000 request). AWS Glue ETL Jobs: 0,02 USD/tháng (2 DPU). AWS Glue Crawlers: 0,07 USD/tháng (1 crawler). MQTT (IoT Core): 0,08 USD/tháng (5 thiết bị, 45.000 tin nhắn). Tổng: 0,7 USD/tháng, 8,40 USD/12 tháng\nPhần cứng: 265 USD một lần (Raspberry Pi 5 và cảm biến). 7. Đánh giá rủi ro Ma trận rủi ro\nMất mạng: Ảnh hưởng trung bình, xác suất trung bình. Hỏng cảm biến: Ảnh hưởng cao, xác suất thấp. Vượt ngân sách: Ảnh hưởng trung bình, xác suất thấp. Chiến lược giảm thiểu\nMạng: Lưu trữ cục bộ trên Raspberry Pi với Docker. Cảm biến: Kiểm tra định kỳ, dự phòng linh kiện. Chi phí: Cảnh báo ngân sách AWS, tối ưu dịch vụ. Kế hoạch dự phòng\nQuay lại thu thập thủ công nếu AWS gặp sự cố. Sử dụng CloudFormation để khôi phục cấu hình liên quan đến chi phí. 8. Kết quả kỳ vọng Cải tiến kỹ thuật: Dữ liệu và phân tích thời gian thực thay thế quy trình thủ công. Có thể mở rộng tới 10–15 trạm.\nGiá trị dài hạn: Nền tảng dữ liệu 1 năm cho nghiên cứu AI, có thể tái sử dụng cho các dự án tương lai.\n"},{"uri":"https://github.com/LeThiYenVi/AWS-Report.git/vi/5-workshop/5.2-prerequiste/","title":"Điều kiện tiên quyết","tags":[],"description":"","content":"Điều kiện tiên quyết cho Workshop EV Rental AI Agent Trước khi bắt đầu workshop này, hãy đảm bảo bạn đã chuẩn bị các yêu cầu sau:\n1. Tài khoản AWS Bạn cần một Tài khoản AWS với quyền phù hợp để:\nTruy cập dịch vụ AWS Bedrock Tạo và quản lý IAM users Tạo S3 buckets (cho Knowledge Base) Tạo Knowledge Bases Lưu ý: Bedrock chỉ khả dụng ở một số vùng cụ thể. Các vùng được khuyến nghị:\nus-west-2 (Oregon) us-east-1 (N. Virginia) ap-southeast-1 (Singapore) 2. IAM User với Quyền Bedrock Bạn cần tạo IAM User với quyền truy cập AWS Bedrock cho ứng dụng.\nBước 1: Tạo IAM User\nVào AWS Console → IAM → Users → Create User Tên user: bedrock-agent-user ✅ Chọn: Provide user access to the AWS Management Console (tùy chọn) ✅ Chọn: I want to create an IAM user Click Next Bước 2: Gán Quyền\nChọn: Attach policies directly Tìm và chọn các policies sau: ✅ AmazonBedrockFullAccess - Quyền truy cập đầy đủ Bedrock models và Knowledge Bases ✅ (Tùy chọn) AmazonS3ReadOnlyAccess - Nếu sử dụng Knowledge Base với S3 Click Next → Create User Bước 3: Tạo Access Keys\nClick vào user vừa tạo: bedrock-agent-user Vào tab Security credentials Cuộn xuống Access keys → Click Create access key ⚠️ QUAN TRỌNG: Copy và lưu lại: Access Key ID (ví dụ: AKIAIOSFODNN7EXAMPLE) Secret Access Key (chỉ hiển thị 1 lần, ví dụ: wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY) Click Done ⚠️ Lưu ý Bảo mật:\n# Lưu vào file .env (KHÔNG commit lên Git) AWS_ACCESS_KEY_ID=YOUR_ACCESS_KEY_ID_HERE AWS_SECRET_ACCESS_KEY=YOUR_SECRET_ACCESS_KEY_HERE AWS_REGION=us-west-2 3. Môi trường Phát triển 3.1. Môi trường Python Python 3.11 hoặc cao hơn Trình quản lý package: pip Kiểm tra cài đặt:\npython --version # Mong đợi: Python 3.11.x hoặc cao hơn pip --version 3.2. Môi trường Node.js Node.js 18+ và npm Yêu cầu cho React frontend Kiểm tra cài đặt:\nnode --version # Mong đợi: v18.x.x hoặc cao hơn npm --version 3.3. Cơ sở dữ liệu PostgreSQL PostgreSQL 14+ cài đặt local hoặc sử dụng Docker Tùy chọn 1: Cài đặt local\nTải từ: https://www.postgresql.org/download/ Tạo database: ev_rental_db Tùy chọn 2: Sử dụng Docker\ndocker run -d \\ --name postgres-ev \\ -e POSTGRES_PASSWORD=password \\ -e POSTGRES_DB=ev_rental_db \\ -p 5432:5432 \\ postgres:14 Kiểm tra PostgreSQL:\n# Kiểm tra PostgreSQL đang chạy psql --version # Kết nối database psql -U postgres -d ev_rental_db 4. Code Editor \u0026amp; Công cụ VS Code hoặc IDE bạn ưa thích Git để clone repositories Postman hoặc cURL để test API (tùy chọn) Cài đặt VS Code:\nTải từ: https://code.visualstudio.com/ Cài đặt Git:\n# macOS brew install git # Windows # Tải từ: https://git-scm.com/download/win # Kiểm tra git --version 5. AWS CLI (Tùy chọn) Cài đặt AWS CLI để tương tác với các dịch vụ AWS từ command line:\n# macOS/Linux curl \u0026#34;https://awscli.amazonaws.com/AWSCLIV2.pkg\u0026#34; -o \u0026#34;AWSCLIV2.pkg\u0026#34; sudo installer -pkg AWSCLIV2.pkg -target / # Windows # Tải từ: https://awscli.amazonaws.com/AWSCLIV2.msi # Kiểm tra aws --version Cấu hình AWS CLI:\naws configure # Nhập Access Key ID: AKIA5GPEMGJZK6E7PMEB # Nhập Secret Access Key: (dán secret key của bạn) # Default region name: us-west-2 # Default output format: json Test AWS CLI:\n# Liệt kê các Bedrock models có sẵn aws bedrock list-foundation-models --region us-west-2 # Kiểm tra identity của bạn aws sts get-caller-identity Danh sách Kiểm tra Trước khi tiếp tục bước tiếp theo, đảm bảo bạn có:\n✅ Tài khoản AWS với quyền truy cập Bedrock ở vùng được hỗ trợ ✅ IAM User đã tạo với policy AmazonBedrockFullAccess ✅ Access Key ID và Secret Access Key đã lưu an toàn ✅ Python 3.11+ đã cài đặt và kiểm tra ✅ Node.js 18+ và npm đã cài đặt và kiểm tra ✅ PostgreSQL 14+ database đang chạy ✅ Code editor (VS Code khuyến nghị) đã cài đặt ✅ Git đã cài đặt và cấu hình ✅ (Tùy chọn) AWS CLI đã cài đặt và cấu hình Chi phí Ước tính Workshop này sử dụng các dịch vụ AWS sau:\nDịch vụ Chi phí Ước tính Ghi chú AWS Bedrock - Claude 3.5 Sonnet ~$0.50 - $2.00 Tính theo API call (input/output tokens) AWS Bedrock - Knowledge Base ~$0.10 - $0.50 Vector storage + retrieval S3 Storage ~$0.02 Tối thiểu cho documents Data Transfer ~$0.05 Thường trong free tier Tổng ~$0.67 - $2.57 Cho toàn bộ workshop 💡 Lưu ý: Nhớ dọn dẹp tài nguyên sau workshop để tránh phí phát sinh!\nTiếp theo: Chuyển sang Thiết lập AWS Bedrock để enable models và tạo Knowledge Base.\n"},{"uri":"https://github.com/LeThiYenVi/AWS-Report.git/vi/4-eventparticipated/4.2-event2/","title":"Event 2","tags":[],"description":"","content":"BÁO CÁO THU HOẠCH SỰ KIỆN Sự kiện: AWS Cloud Mastery Series #1: Generative AI, RAG \u0026amp; AWS Agentic AI\n1. MỤC TIÊU THAM DỰ Việc tham dự sự kiện tập trung vào 5 mục tiêu cốt lõi nhằm nâng cao năng lực kỹ thuật và tư duy chiến lược:\nPrompt Engineering: Thành thạo kỹ thuật Prompt Engineering để tối ưu hóa khả năng điều khiển các mô hình ngôn ngữ. AWS AI Services: Tìm hiểu hệ sinh thái các dịch vụ AI được huấn luyện sẵn (Pretrained AI Services) của AWS. RAG Architecture: Đi sâu vào quy trình xây dựng ứng dụng thông minh sử dụng kỹ thuật RAG (Retrieval-Augmented Generation). Agentic AI: Cập nhật xu hướng Agentic AI và phương pháp chuyển đổi AI Agent từ giai đoạn thử nghiệm (POC) sang vận hành thực tế (Production) thông qua Amazon Bedrock AgentCore. Voice AI Framework: Tiếp cận Pipecat – Framework hỗ trợ xây dựng trợ lý ảo tương tác bằng giọng nói trong thời gian thực. 2. DANH SÁCH DIỄN GIẢ Sự kiện quy tụ các chuyên gia hàng đầu về AI và Cloud:\nLâm Tuấn Kiệt – Sr DevOps Engineer (FPT Software) Danh Hoàng Hiếu Nghị – AI Engineer (Renova Cloud) Đinh Lê Hoàng Anh – Cloud Engineer Trainee (First Cloud AI Journey) 3. NỘI DUNG CHUYÊN MÔN NỔI BẬT 3.1. Prompt Engineering \u0026amp; Foundation Models (Nền Tảng Cốt Lõi) Trước khi tiếp cận các dịch vụ nâng cao, sự kiện nhấn mạnh tầm quan trọng của việc giao tiếp hiệu quả với các Mô hình nền tảng (Foundation Models) trên Amazon Bedrock:\nZero-shot / Few-shot Prompting: Kỹ thuật ra lệnh trực tiếp hoặc cung cấp một vài ví dụ mẫu để định hướng đầu ra mong muốn. Chain of Thought (CoT): Yêu cầu mô hình \u0026ldquo;suy luận từng bước\u0026rdquo;, giúp nâng cao độ chính xác khi giải quyết các bài toán logic phức tạp. 3.2. Các Dịch Vụ AI Được Huấn Luyện Trước (AWS AI Services) Giới thiệu bộ API tiện lợi, cho phép tích hợp trí tuệ nhân tạo mà không cần tốn công huấn luyện mô hình:\nHình ảnh/Video: Amazon Rekognition. Ngôn ngữ: Amazon Translate, Comprehend, Textract (OCR). Âm thanh: Amazon Polly (Chuyển văn bản thành giọng nói), Transcribe (Chuyển giọng nói thành văn bản). 3.3. RAG - Retrieval Augmented Generation Giải pháp giúp AI phản hồi dựa trên dữ liệu nội bộ của doanh nghiệp, giảm thiểu rủi ro cung cấp thông tin sai lệch:\nEmbeddings: Ứng dụng Amazon Titan Text Embeddings V2 để vector hóa dữ liệu, phục vụ cho việc tìm kiếm theo ngữ nghĩa. Knowledge Bases for Amazon Bedrock: Quản lý toàn trình từ khâu phân mảnh dữ liệu (Chunking) $\\rightarrow$ Lưu trữ Vector $\\rightarrow$ Truy xuất (Retrieval) $\\rightarrow$ Sinh câu trả lời (Generation). 3.4. Sự Tiến Hóa Lên Agentic AI (Kỷ Nguyên AI Tác Vụ) Bức tranh tiến hóa của GenAI:\nGenAI Assistants: Hỗ trợ tự động hóa các tác vụ lặp lại theo quy tắc. GenAI Agents: Hướng tới mục tiêu cụ thể (Goal-oriented), xử lý chuỗi công việc rộng hơn. Agentic AI Systems: Hệ thống đa tác nhân (Multi-agent) hoạt động hoàn toàn tự chủ với sự can thiệp tối thiểu của con người. Thách thức \u0026ldquo;Hố sâu ngăn cách\u0026rdquo; (The Prototype to Production Chasm): Việc đưa Agent ra thị trường gặp rào cản lớn về Hiệu năng (Performance), Bảo mật \u0026amp; Quản trị (Security \u0026amp; Governance), và Sự phức tạp (Complexity) trong quản lý ngữ cảnh/kiểm toán. 3.5. Amazon Bedrock AgentCore: Giải Pháp Đưa Agent Ra Thị Trường AWS giới thiệu AgentCore để giải quyết bài toán vận hành Agent:\nCác thành phần cốt lõi: Runtime \u0026amp; Memory (Môi trường chạy \u0026amp; Ghi nhớ), Identity \u0026amp; Gateway (Định danh \u0026amp; Kết nối), Code Interpreter (Tự viết và chạy code), Observability (Giám sát hoạt động). Lợi ích: Giúp lập trình viên tập trung vào logic nghiệp vụ thay vì loay hoay với hạ tầng bảo mật hay lưu trữ ngữ cảnh. 3.6. Pipecat: Framework Cho AI Voice Thời Gian Thực Giới thiệu framework mã nguồn mở tối ưu cho các trợ lý ảo đa phương thức (Multimodal):\nĐặc điểm: Tối ưu cho độ trễ thấp (Real-time) và xử lý luồng (Streaming). Cơ chế hoạt động: WebRTC Input (Nhận âm thanh) $\\rightarrow$ STT (Chuyển thành chữ) $\\rightarrow$ LLM Processing (Xử lý) $\\rightarrow$ TTS (Chuyển thành giọng nói) $\\rightarrow$ Output (Phát lại). 4. TRẢI NGHIỆM CHI TIẾT TRONG EVENT Buổi workshop đã giúp tôi mở rộng tầm nhìn từ những kiến thức nền tảng đến các công nghệ tiên phong đang định hình tương lai AI.\n4.1. Sự chuyển dịch từ \u0026ldquo;Hỏi - Đáp\u0026rdquo; sang \u0026ldquo;Hành động\u0026rdquo; (Agentic AI) Điều khiến tôi ấn tượng nhất là khái niệm Agentic AI. Nó thay đổi tư duy của tôi về AI từ việc chỉ biết chat/tóm tắt sang hình ảnh những \u0026ldquo;nhân viên ảo\u0026rdquo; có khả năng tự lập kế hoạch, sử dụng công cụ (duyệt web, viết code) để giải quyết vấn đề mà không cần cầm tay chỉ việc.\n4.2. Giải quyết bài toán \u0026ldquo;Production\u0026rdquo; Tôi đánh giá cao phần chia sẻ về \u0026ldquo;Hố sâu ngăn cách\u0026rdquo; giữa POC và Production. Các công cụ như Amazon Bedrock AgentCore thực sự là lời giải cho bài toán niềm tin của doanh nghiệp, nhờ vào các cơ chế bảo mật (Identity) và giám sát (Observability) chặt chẽ mà AWS cung cấp.\n4.3. Tiềm năng của Voice AI với Pipecat Phần demo Pipecat thực sự thú vị. Sự kết hợp giữa WebRTC và AI để tạo ra các cuộc hội thoại mượt mà, độ trễ cực thấp mở ra tiềm năng ứng dụng to lớn: từ Tổng đài ảo, Trợ lý phỏng vấn cho đến Giáo viên ngôn ngữ AI.\n5. KẾT LUẬN Buổi workshop \u0026ldquo;Generative AI \u0026amp; Agentic AI on AWS\u0026rdquo; đã vẽ nên một bức tranh toàn cảnh giá trị:\nHiện tại: Chúng ta tối ưu hóa dữ liệu với RAG và Prompt Engineering. Tương lai: Kỷ nguyên Agentic AI đang đến gần, nơi các hệ thống tự chủ (Autonomous Agents) sẽ thay đổi cách vận hành doanh nghiệp. Công cụ: Với hệ sinh thái AWS (Bedrock, AgentCore) và các Framework (Pipecat, LangChain), rào cản kỹ thuật đang dần được xóa bỏ, tạo đà cho các kỹ sư hiện thực hóa những ý tưởng đột phá. "},{"uri":"https://github.com/LeThiYenVi/AWS-Report.git/vi/5-workshop/5.3-s3-vpc/5.3.2-test-gwe/","title":"Kiểm tra Gateway Endpoint","tags":[],"description":"","content":"Tạo S3 bucket Đi đến S3 management console Trong Bucket console, chọn Create bucket Trong Create bucket console Đặt tên bucket: chọn 1 tên mà không bị trùng trong phạm vi toàn cầu (gợi ý: lab\u0026lt;số-lab\u0026gt;\u0026lt;tên-bạn\u0026gt;) Giữ nguyên giá trị của các fields khác (default) Kéo chuột xuống và chọn Create bucket Tạo thành công S3 bucket Kết nối với EC2 bằng session manager Trong workshop này, bạn sẽ dùng AWS Session Manager để kết nối đến các EC2 instances. Session Manager là 1 tính năng trong dịch vụ Systems Manager được quản lý hoàn toàn bởi AWS. System manager cho phép bạn quản lý Amazon EC2 instances và các máy ảo on-premises (VMs)thông qua 1 browser-based shell. Session Manager cung cấp khả năng quản lý phiên bản an toàn và có thể kiểm tra mà không cần mở cổng vào, duy trì máy chủ bastion host hoặc quản lý khóa SSH.\nFirst cloud journey Lab để hiểu sâu hơn về Session manager.\nTrong AWS Management Console, gõ Systems Manager trong ô tìm kiếm và nhấn Enter: Từ Systems Manager menu, tìm Node Management ở thanh bên trái và chọn Session Manager: Click Start Session, và chọn EC2 instance tên Test-Gateway-Endpoint. Phiên bản EC2 này đã chạy trong \u0026ldquo;VPC cloud\u0026rdquo; và sẽ được dùng để kiểm tra khả năng kết nối với Amazon S3 thông qua điểm cuối Cổng mà bạn vừa tạo (s3-gwe).\nSession Manager sẽ mở browser tab mới với shell prompt: sh-4.2 $\nBạn đã bắt đầu phiên kết nối đến EC2 trong VPC Cloud thành công. Trong bước tiếp theo, chúng ta sẽ tạo một S3 bucket và một tệp trong đó.\nCreate a file and upload to s3 bucket Đổi về ssm-user\u0026rsquo;s thư mục bằng lệnh \u0026ldquo;cd ~\u0026rdquo; Tạo 1 file để kiểm tra bằng lệnh \u0026ldquo;fallocate -l 1G testfile.xyz\u0026rdquo;, 1 file tên \u0026ldquo;testfile.xyz\u0026rdquo; có kích thước 1GB sẽ được tạo. Tải file mình vừa tạo lên S3 với lệnh \u0026ldquo;aws s3 cp testfile.xyz s3://your-bucket-name\u0026rdquo;. Thay your-bucket-name bằng tên S3 bạn đã tạo. Bạn đã tải thành công tệp lên bộ chứa S3 của mình. Bây giờ bạn có thể kết thúc session.\nKiểm tra object trong S3 bucket Đi đến S3 console. Click tên s3 bucket của bạn Trong Bucket console, bạn sẽ thấy tệp bạn đã tải lên S3 bucket của mình Tóm tắt Chúc mừng bạn đã hoàn thành truy cập S3 từ VPC. Trong phần này, bạn đã tạo gateway endpoint cho Amazon S3 và sử dụng AWS CLI để tải file lên. Quá trình tải lên hoạt động vì gateway endpoint cho phép giao tiếp với S3 mà không cần Internet gateway gắn vào \u0026ldquo;VPC Cloud\u0026rdquo;. Điều này thể hiện chức năng của gateway endpoint như một đường dẫn an toàn đến S3 mà không cần đi qua pub lic Internet.\n"},{"uri":"https://github.com/LeThiYenVi/AWS-Report.git/vi/5-workshop/5.4-s3-onprem/5.4.2-create-interface-enpoint/","title":"Tạo một S3 Interface endpoint","tags":[],"description":"","content":"Trong phần này, bạn sẽ tạo và kiểm tra Interface Endpoint S3 bằng cách sử dụng môi trường truyền thống mô phỏng.\nQuay lại Amazon VPC menu. Trong thanh điều hướng bên trái, chọn Endpoints, sau đó click Create Endpoint.\nTrong Create endpoint console:\nĐặt tên interface endpoint Trong Service category, chọn aws services Trong Search box, gõ S3 và nhấn Enter. Chọn endpoint có tên com.amazonaws.us-east-1.s3. Đảm bảo rằng cột Type có giá trị Interface. Đối với VPC, chọn VPC Cloud từ drop-down. Đảm bảo rằng bạn chọn \u0026ldquo;VPC Cloud\u0026rdquo; và không phải \u0026ldquo;VPC On-prem\u0026rdquo;\nMở rộng Additional settings và đảm bảo rằng Enable DNS name không được chọn (sẽ sử dụng điều này trong phần tiếp theo của workshop) Chọn 2 subnets trong AZs sau: us-east-1a and us-east-1b Đối với Security group, chọn SGforS3Endpoint: Giữ default policy - full access và click Create endpoint Chúc mừng bạn đã tạo thành công S3 interface endpoint. Ở bước tiếp theo, chúng ta sẽ kiểm tra interface endpoint.\n"},{"uri":"https://github.com/LeThiYenVi/AWS-Report.git/vi/1-worklog/1.2-week2/","title":"Worklog Tuần 2","tags":[],"description":"","content":"Mục tiêu tuần 2: Thiết lập Bảo mật Định danh: Loại bỏ hoàn toàn việc sử dụng tài khoản Root cho tác vụ quản trị hàng ngày; thiết lập cấu trúc User/Group chuẩn. Kiến trúc Mạng lưới: Thiết kế và triển khai một Custom VPC thay vì sử dụng Default VPC, đảm bảo hiểu sâu về quy hoạch IP. Kiểm soát Lưu lượng: Cấu hình Route Tables để phân định rõ ràng giữa Public và Private Subnets. Tuân thủ: Kích hoạt Multi-Factor Authentication (MFA) như một yêu cầu bắt buộc cho mọi tài khoản truy cập Console. Các công việc cần triển khai trong tuần này: Task ID Thứ Công việc Ngày bắt đầu Ngày hoàn thành Trạng thái Nguồn tài liệu T2.1 2 IAM - Securing Root: - Đăng nhập Root, kích hoạt MFA (Virtual Authenticator App) - Xóa bỏ mọi Access Keys của Root (nếu có) 15/09/2025 15/09/2025 Hoàn thành https://cloudjourney.awsstudygroup.com/ T2.2 2 IAM - Admin Group Setup: - Tạo IAM Group CloudAdmins - Gắn policy AdministratorAccess (AWS Managed Policy) 15/09/2025 15/09/2025 Hoàn thành https://cloudjourney.awsstudygroup.com/ T2.3 3 IAM - User Creation: - Tạo IAM User cho bản thân - Thiết lập Password Policy (độ phức tạp, xoay vòng) - Thêm vào group CloudAdmins 16/09/2025 16/09/2025 Hoàn thành https://cloudjourney.awsstudygroup.com/ T2.4 4 VPC - IP Planning: - Tính toán CIDR cho VPC (10.0.0.0/16) - Thiết kế Subnets để hỗ trợ tối đa 65,536 địa chỉ IP 17/09/2025 17/09/2025 Hoàn thành https://cloudjourney.awsstudygroup.com/ T2.5 4 VPC - Deploy VPC: - Khởi tạo VPC tại Region ap-southeast-1 (Singapore) - Gắn thẻ tag Project=FCJ 17/09/2025 17/09/2025 Hoàn thành https://cloudjourney.awsstudygroup.com/ T2.6 5 VPC - Subnet Design: - Tạo 4 Subnets: 2 Public (10.0.1.0/24, 10.0.2.0/24) - 2 Private (10.0.3.0/24, 10.0.4.0/24) - Chia đều trên 2 AZs 18/09/2025 18/09/2025 Hoàn thành https://cloudjourney.awsstudygroup.com/ T2.7 5 VPC - Internet Access: - Tạo và gắn Internet Gateway (IGW) vào VPC - Cấu hình Route Table của Public Subnet trỏ 0.0.0.0/0 tới IGW 18/09/2025 19/09/2025 Hoàn thành https://cloudjourney.awsstudygroup.com/ T2.8 6 Security - Firewall Basics: - Tạo Security Group Web-SG - Cho phép Inbound HTTP (80) từ 0.0.0.0/0 - Cho phép SSH (22) từ MyIP 19/09/2025 21/09/2025 Hoàn thành https://cloudjourney.awsstudygroup.com/ Kết quả đạt được tuần 2: An ninh Tài khoản:\nĐã chuyển sang sử dụng IAM User với MFA để đăng nhập Root account được bảo vệ bằng mật khẩu mạnh và MFA vật lý/ứng dụng riêng biệt Áp dụng nguyên tắc \u0026ldquo;Least Privilege\u0026rdquo; (Quyền tối thiểu) Hạ tầng Mạng:\nMột VPC tùy chỉnh hoàn chỉnh đang hoạt động Đã kiểm chứng khả năng phân giải DNS (DNS Hostnames enabled) Thiết lập mô hình mạng 2 tầng (2-Tier Network Architecture) Kiến trúc:\nSẵn sàng cho việc triển khai ứng dụng Web và Database trong các tuần tiếp theo Hiểu rõ sự khác biệt giữa Public và Private Subnet Nắm vững khái niệm CIDR và subnet mask Bài học:\nSecurity Group là tường lửa cấp độ Instance (stateful) Network ACL là tường lửa cấp độ Subnet (stateless) Hiểu về AWS Shared Responsibility Model "},{"uri":"https://github.com/LeThiYenVi/AWS-Report.git/vi/3-blogstranslated/","title":"Các bài blogs đã dịch","tags":[],"description":"","content":" ⚠️ Lưu ý: Các thông tin dưới đây chỉ nhằm mục đích tham khảo, vui lòng không sao chép nguyên văn cho bài báo cáo của bạn kể cả warning này.\nTại đây sẽ là phần liệt kê, giới thiệu các blogs mà các bạn đã dịch. Ví dụ:\nBlog 1 - Getting started with healthcare data lakes: Using microservices Blog này giới thiệu cách bắt đầu xây dựng data lake trong lĩnh vực y tế bằng cách áp dụng kiến trúc microservices. Bạn sẽ tìm hiểu vì sao data lake quan trọng trong việc lưu trữ và phân tích dữ liệu y tế đa dạng (hồ sơ bệnh án điện tử, dữ liệu xét nghiệm, thiết bị IoT y tế…), cách microservices giúp hệ thống linh hoạt, dễ mở rộng và dễ bảo trì hơn. Bài viết cũng hướng dẫn các bước khởi tạo môi trường, tổ chức pipeline xử lý dữ liệu, và đảm bảo tuân thủ các tiêu chuẩn bảo mật \u0026amp; quyền riêng tư như HIPAA.\nBlog 2 - \u0026hellip; Blog này giới thiệu cách bắt đầu xây dựng data lake trong lĩnh vực y tế bằng cách áp dụng kiến trúc microservices. Bạn sẽ tìm hiểu vì sao data lake quan trọng trong việc lưu trữ và phân tích dữ liệu y tế đa dạng (hồ sơ bệnh án điện tử, dữ liệu xét nghiệm, thiết bị IoT y tế…), cách microservices giúp hệ thống linh hoạt, dễ mở rộng và dễ bảo trì hơn. Bài viết cũng hướng dẫn các bước khởi tạo môi trường, tổ chức pipeline xử lý dữ liệu, và đảm bảo tuân thủ các tiêu chuẩn bảo mật \u0026amp; quyền riêng tư như HIPAA.\nBlog 3 - \u0026hellip; Blog này giới thiệu cách bắt đầu xây dựng data lake trong lĩnh vực y tế bằng cách áp dụng kiến trúc microservices. Bạn sẽ tìm hiểu vì sao data lake quan trọng trong việc lưu trữ và phân tích dữ liệu y tế đa dạng (hồ sơ bệnh án điện tử, dữ liệu xét nghiệm, thiết bị IoT y tế…), cách microservices giúp hệ thống linh hoạt, dễ mở rộng và dễ bảo trì hơn. Bài viết cũng hướng dẫn các bước khởi tạo môi trường, tổ chức pipeline xử lý dữ liệu, và đảm bảo tuân thủ các tiêu chuẩn bảo mật \u0026amp; quyền riêng tư như HIPAA.\nBlog 4 - \u0026hellip; Blog này giới thiệu cách bắt đầu xây dựng data lake trong lĩnh vực y tế bằng cách áp dụng kiến trúc microservices. Bạn sẽ tìm hiểu vì sao data lake quan trọng trong việc lưu trữ và phân tích dữ liệu y tế đa dạng (hồ sơ bệnh án điện tử, dữ liệu xét nghiệm, thiết bị IoT y tế…), cách microservices giúp hệ thống linh hoạt, dễ mở rộng và dễ bảo trì hơn. Bài viết cũng hướng dẫn các bước khởi tạo môi trường, tổ chức pipeline xử lý dữ liệu, và đảm bảo tuân thủ các tiêu chuẩn bảo mật \u0026amp; quyền riêng tư như HIPAA.\nBlog 5 - \u0026hellip; Blog này giới thiệu cách bắt đầu xây dựng data lake trong lĩnh vực y tế bằng cách áp dụng kiến trúc microservices. Bạn sẽ tìm hiểu vì sao data lake quan trọng trong việc lưu trữ và phân tích dữ liệu y tế đa dạng (hồ sơ bệnh án điện tử, dữ liệu xét nghiệm, thiết bị IoT y tế…), cách microservices giúp hệ thống linh hoạt, dễ mở rộng và dễ bảo trì hơn. Bài viết cũng hướng dẫn các bước khởi tạo môi trường, tổ chức pipeline xử lý dữ liệu, và đảm bảo tuân thủ các tiêu chuẩn bảo mật \u0026amp; quyền riêng tư như HIPAA.\nBlog 6 - \u0026hellip; Blog này giới thiệu cách bắt đầu xây dựng data lake trong lĩnh vực y tế bằng cách áp dụng kiến trúc microservices. Bạn sẽ tìm hiểu vì sao data lake quan trọng trong việc lưu trữ và phân tích dữ liệu y tế đa dạng (hồ sơ bệnh án điện tử, dữ liệu xét nghiệm, thiết bị IoT y tế…), cách microservices giúp hệ thống linh hoạt, dễ mở rộng và dễ bảo trì hơn. Bài viết cũng hướng dẫn các bước khởi tạo môi trường, tổ chức pipeline xử lý dữ liệu, và đảm bảo tuân thủ các tiêu chuẩn bảo mật \u0026amp; quyền riêng tư như HIPAA.\n"},{"uri":"https://github.com/LeThiYenVi/AWS-Report.git/vi/4-eventparticipated/4.3-event3/","title":"Event 3","tags":[],"description":"","content":"BÁO CÁO THU HOẠCH SỰ KIỆN Sự kiện: AWS Cloud Mastery Series #2: Từ DevOps, IaC đến Container \u0026amp; Observability\n1. MỤC TIÊU THAM DỰ Việc tham dự sự kiện tập trung vào 4 mục tiêu cốt lõi nhằm nâng cao năng lực kỹ thuật và tư duy chiến lược:\nĐịnh hình tư duy (Mindset): Nắm bắt bản chất Vòng đời giá trị (Value Cycle) và sứ mệnh của DevOps trong việc đảm bảo dòng chảy phần mềm liên tục và đáng tin cậy. Tự động hóa hạ tầng (IaC): Chấm dứt kỷ nguyên thao tác thủ công (ClickOps), chuyển sang quản trị hạ tầng bằng mã nguồn với bộ ba công cụ: CloudFormation, Terraform và CDK. Chiến lược Container hóa: Hiểu sâu kiến trúc và tiêu chí lựa chọn nền tảng vận hành Container tối ưu: App Runner cho đơn giản, ECS cho hiệu quả hoặc EKS cho sự linh hoạt. Giám sát chủ động (Observability): Thiết lập hệ thống \u0026ldquo;tai mắt\u0026rdquo; toàn diện để phát hiện sự cố và tối ưu hiệu năng thông qua CloudWatch và X-Ray. 2. DANH SÁCH DIỄN GIẢ Sự kiện quy tụ các chuyên gia hàng đầu từ AWS và Cloud Engineering:\nĐội ngũ chuyên gia AWS \u0026amp; Cloud Engineers – Các kỹ sư và kiến trúc sư giải pháp chia sẻ về mô hình Platform Engineering và demo kỹ thuật thực chiến. 3. NỘI DUNG CHUYÊN MÔN NỔI BẬT 3.1. DevOps Mindset \u0026amp; CI/CD Pipeline (Nền Tảng Tư Duy) Sự kiện tái định nghĩa DevOps không chỉ là công cụ, mà là văn hóa tối ưu hóa dòng chảy giá trị:\nThe Value Cycle (Vòng Đời Giá Trị): Chu trình 5 giai đoạn khép kín từ Phân tích (Insights) $\\rightarrow$ Danh mục (Portfolio) $\\rightarrow$ Tích hợp (CI) $\\rightarrow$ Kiểm thử (Testing) $\\rightarrow$ Chuyển giao (CD). Mục tiêu là cân bằng giữa Tốc độ phát hành (Speed) và Sự ổn định (Stability). Phân biệt rõ các cấp độ tự động hóa: Continuous Integration (CI): Merge code hàng ngày, tự động Build và Test để phát hiện lỗi sớm (Fail fast). Continuous Delivery: Tự động deploy đến Staging, nhưng cần con người duyệt (Manual Trigger) để ra Production. Continuous Deployment: Tự động hóa 100% dòng chảy từ Commit đến Production. Chiến lược Pipeline tối ưu: Centralized CI: Xây dựng CI tập trung để quản lý nhưng trao quyền tự phục vụ (Self-service) cho Developer. Artifact Management: Tuân thủ nguyên tắc \u0026ldquo;Build Once, Deploy Anywhere\u0026rdquo;. Chỉ đóng gói mã nguồn một lần duy nhất (Artifact) và dùng nó cho mọi môi trường để đảm bảo tính nhất quán. Điều kiện Fail: Pipeline phải dừng ngay nếu gặp lỗi biên dịch, vi phạm chuẩn code, lỗ hổng bảo mật hoặc test quá chậm. Metrics: Dùng Heatmap và các chỉ số DORA (Tần suất deploy, Tỷ lệ lỗi, MTTR) để đo lường sức khỏe quy trình. 3.2. Infrastructure as Code (IaC) - Từ ClickOps Đến Code Hành trình loại bỏ rủi ro từ thao tác tay (ClickOps) để hướng tới sự Chính xác, Mở rộng và Cộng tác:\nAWS CloudFormation (Native): Sử dụng YAML/JSON để định nghĩa tài nguyên. Quản lý vòng đời qua khái niệm Stack (xóa Stack là dọn sạch tài nguyên). Terraform (Multi-Cloud): Sức mạnh mã nguồn mở với ngôn ngữ HCL. Quy trình chuẩn: Write $\\rightarrow$ Plan (Xem trước thay đổi) $\\rightarrow$ Apply. Điểm mạnh là khả năng quản lý đa nền tảng (AWS, Azure, GCP) và quản lý trạng thái qua State File. AWS CDK (Code-based): Định nghĩa hạ tầng bằng ngôn ngữ lập trình (Python, TypeScript\u0026hellip;). Constructs: Từ L1 (Cấu hình chi tiết) đến L3 (Patterns kiến trúc dựng sẵn). Drift Detection: Tính năng sống còn để phát hiện sự sai lệch cấu hình do sửa thủ công, giúp duy trì kỷ luật hệ thống. 3.3. Containerization - Chiến Lược Chạy Ứng Dụng Phân tích các lựa chọn điều phối (Orchestration) và tính toán (Compute):\nSo sánh ECS vs. EKS: Amazon ECS: Đơn giản, tích hợp chặt chẽ với hệ sinh thái AWS, phù hợp team muốn deploy nhanh, giảm vận hành. Amazon EKS: Chuẩn Kubernetes, mạnh mẽ và linh hoạt, dành cho hệ thống Enterprise phức tạp hoặc Hybrid-cloud. Mô hình tính toán: EC2 Launch Type: Kiểm soát tối đa nhưng tốn công quản lý server. AWS Fargate: Serverless cho container, chỉ cần quan tâm CPU/RAM, AWS lo hạ tầng bên dưới. AWS App Runner: Giải pháp \u0026ldquo;Zero-ops\u0026rdquo;, đưa code/image thành Web App có HTTPS chỉ trong vài bước, không cần cấu hình mạng/server. 3.4. Observability - Giám Sát \u0026amp; Tối Ưu Hóa Đảm bảo khả năng quan sát sâu rộng để vận hành ổn định:\nAmazon CloudWatch: Thu thập dữ liệu hiệu năng (Metrics), nhật ký tập trung (Logs) và tự động phản ứng (Alarms) khi hệ thống gặp sự cố. AWS X-Ray: Công cụ truy vết phân tán (Distributed Tracing), giúp vẽ lại hành trình request qua các microservices để tìm điểm nghẽn (Bottlenecks) và nguyên nhân gốc rễ. Best Practices: Phân biệt rõ vai trò của Logs (sự kiện) và Traces (hành trình); sử dụng các Patterns chuẩn của AWS để thiết lập giám sát. 4. TRẢI NGHIỆM CHI TIẾT TRONG EVENT Chuyên đề này đã thay đổi hoàn toàn góc nhìn của tôi về vận hành hệ thống:\n4.1. Sự chuyển dịch từ \u0026ldquo;Ops\u0026rdquo; sang \u0026ldquo;Platform Engineering\u0026rdquo; Tôi nhận ra DevOps hiện đại không phải là người chạy theo Developer để deploy giúp họ. DevOps là người xây dựng \u0026ldquo;Đường cao tốc\u0026rdquo; (Pipeline \u0026amp; Platform). Một nền tảng tốt là nơi Developer có thể tự phục vụ (Self-service) nhu cầu hạ tầng trong khuôn khổ an toàn (Governance) mà đội ngũ DevOps đã thiết lập sẵn.\n4.2. Kỷ luật trong vận hành (Operational Discipline) Nguyên tắc Artifact Management và Drift Detection là bài học đắt giá. Trong môi trường doanh nghiệp, sự nhất quán (Consistency) là yếu tố sống còn. Tuyệt đối không build lại code ở từng môi trường khác nhau và nghiêm cấm việc sửa đổi cấu hình thủ công (Manual changes) khi đã áp dụng IaC.\n4.3. Chiến lược lựa chọn công cụ thông minh Không có công cụ \u0026ldquo;tốt nhất\u0026rdquo;, chỉ có sự lựa chọn \u0026ldquo;phù hợp nhất\u0026rdquo;:\nCần sự ổn định và hỗ trợ native: Chọn CloudFormation. Doanh nghiệp đa nền tảng (Multi-cloud): Terraform là bắt buộc. Team mạnh về lập trình, cần tái sử dụng kiến trúc phức tạp: AWS CDK là vũ khí tối thượng. Web App đơn giản: Dùng App Runner thay vì lãng phí nhân lực vận hành Kubernetes. 5. KẾT LUẬN Chuyên đề \u0026ldquo;DevOps \u0026amp; IaC Mastery\u0026rdquo; đã vẽ ra tấm bản đồ hoàn chỉnh cho hành trình hiện đại hóa trên Cloud:\nVề Tư duy: Chuyển dịch triệt để từ thủ công sang tự động hóa và đo lường bằng dữ liệu. Về Hạ tầng: Làm chủ IaC để đảm bảo khả năng mở rộng, tái tạo và kiểm soát cấu hình. Về Vận hành: Sự kết hợp giữa Containerization linh hoạt và Observability sâu rộng là chìa khóa cho một hệ thống hiệu năng cao và bền vững. Đây là nền tảng kiến thức vững chắc để tôi tự tin xây dựng và vận hành các hệ thống phần mềm quy mô lớn trên AWS.\n"},{"uri":"https://github.com/LeThiYenVi/AWS-Report.git/vi/5-workshop/5.4-s3-onprem/5.4.3-test-endpoint/","title":"Kiểm tra Interface Endpoint","tags":[],"description":"","content":"Lấy regional DNS name (tên DNS khu vực) của S3 interface endpoint Trong Amazon VPC menu, chọn Endpoints.\nClick tên của endpoint chúng ta mới tạo ở mục 4.2: s3-interface-endpoint. Click details và lưu lại regional DNS name của endpoint (cái đầu tiên) vào text-editor của bạn để dùng ở các bước sau.\nKết nối đến EC2 instance ở trong \u0026ldquo;VPC On-prem\u0026rdquo; (giả lập môi trường truyền thống) Đi đến Session manager bằng cách gõ \u0026ldquo;session manager\u0026rdquo; vào ô tìm kiếm\nClick Start Session, chọn EC2 instance có tên Test-Interface-Endpoint. EC2 instance này đang chạy trên \u0026ldquo;VPC On-prem\u0026rdquo; và sẽ được sử dụng để kiểm tra kết nối đến Amazon S3 thông qua Interface endpoint. Session Manager sẽ mở 1 browser tab mới với shell prompt: sh-4.2 $\nĐi đến ssm-user\u0026rsquo;s home directory với lệnh \u0026ldquo;cd ~\u0026rdquo;\nTạo 1 file tên testfile2.xyz\nfallocate -l 1G testfile2.xyz Copy file vào S3 bucket mình tạo ở section 4.2 aws s3 cp --endpoint-url https://bucket.\u0026lt;Regional-DNS-Name\u0026gt; testfile2.xyz s3://\u0026lt;your-bucket-name\u0026gt; Câu lệnh này yêu cầu thông số \u0026ndash;endpoint-url, bởi vì bạn cần sử dụng DNS name chỉ định cho endpoint để truy cập vào S3 thông qua Interface endpoint. Không lấy \u0026rsquo; * \u0026rsquo; khi copy/paste tên DNS khu vực. Cung cấp tên S3 bucket của bạn Bây giờ tệp đã được thêm vào bộ chứa S3 của bạn. Hãy kiểm tra bộ chứa S3 của bạn trong bước tiếp theo.\nKiểm tra Object trong S3 bucket Đi đến S3 console Click Buckets Click tên bucket của bạn và bạn sẽ thấy testfile2.xyz đã được thêm vào s3 bucket của bạn "},{"uri":"https://github.com/LeThiYenVi/AWS-Report.git/vi/5-workshop/5.3-setup-bedrock/","title":"Thiết lập AWS Bedrock","tags":[],"description":"","content":"Thiết lập AWS Bedrock \u0026amp; Knowledge Base Trong phần này, bạn sẽ cấu hình AWS Bedrock để sử dụng Claude 3.5 Sonnet và tạo Knowledge Base cho việc truy xuất tài liệu.\nBước 1: Kích hoạt Model Access QUAN TRỌNG: Bạn phải kích hoạt quyền truy cập model trước khi sử dụng Bedrock, nếu không sẽ gặp lỗi ValidationException.\nVào AWS Console → Services → Bedrock Ở thanh sidebar bên trái, click Model access (trong mục Foundation models) Click nút Manage model access (màu cam) Tìm và chọn các models sau: ✅ Anthropic - Claude 3.5 Sonnet v2 (anthropic.claude-3-5-sonnet-20241022-v2:0) ✅ Amazon - Titan Embeddings G1 - Text (cho Knowledge Base) Click Request model access (góc dưới bên phải) Đợi phê duyệt: Instant access models: Có sẵn ngay lập tức (màu xanh ✅) Models khác: Đợi 5-30 phút (trạng thái đổi từ \u0026ldquo;In progress\u0026rdquo; → \u0026ldquo;Access granted\u0026rdquo;) Kiểm tra models đã được kích hoạt:\n# Sử dụng AWS CLI aws bedrock list-foundation-models --region us-west-2 # Hoặc kiểm tra trong Console: # Bedrock → Model access → Status phải là \u0026#34;Access granted\u0026#34; Bước 2: Tạo S3 Bucket cho Knowledge Base Knowledge Base yêu cầu S3 bucket để lưu trữ tài liệu.\nVào S3 → Create bucket Tên bucket: ev-rental-knowledge-docs (phải là tên duy nhất toàn cầu) Region: Giống với region Bedrock của bạn (ví dụ: us-west-2) Block all public access: ✅ Bật (khuyến nghị) Click Create bucket Bước 3: Upload tài liệu lên S3 Upload các tài liệu chính sách thuê xe (PDF, TXT, DOCX):\nCác tài liệu mẫu cần upload:\nrental-policy.pdf - Chính sách và điều khoản thuê xe pricing.pdf - Thông tin giá xe faq.txt - Câu hỏi thường gặp booking-process.pdf - Cách đặt xe Upload qua Console:\nVào S3 bucket của bạn: ev-rental-knowledge-docs Click Upload → Add files Chọn các tài liệu Click Upload Upload qua AWS CLI:\naws s3 cp rental-policy.pdf s3://ev-rental-knowledge-docs/ aws s3 cp pricing.pdf s3://ev-rental-knowledge-docs/ aws s3 cp faq.txt s3://ev-rental-knowledge-docs/ aws s3 cp booking-process.pdf s3://ev-rental-knowledge-docs/ Bước 4: Tạo Knowledge Base Vào Bedrock → Knowledge Bases → Create Knowledge base name: ev-rental-knowledge-base Description: \u0026ldquo;Chính sách và FAQ cho thuê xe điện VinFast\u0026rdquo; Click Next Cấu hình Data source:\nData source name: rental-docs S3 URI: s3://ev-rental-knowledge-docs/ Click Next Embeddings model:\nChọn: Titan Embeddings G1 - Text (amazon.titan-embed-text-v1) Vector database: Chọn Bedrock managed (OpenSearch Serverless) (tùy chọn dễ nhất) Click Next Review và tạo:\nXem lại tất cả cài đặt Click Create knowledge base Đợi quá trình tạo hoàn tất (2-3 phút) Bước 5: Sync Data Source Sau khi Knowledge Base được tạo, bạn cần đồng bộ dữ liệu:\nTrong Knowledge Base, vào tab Data sources Chọn data source của bạn: rental-docs Click nút Sync Đợi sync hoàn tất (kiểm tra trạng thái: \u0026ldquo;Syncing\u0026rdquo; → \u0026ldquo;Ready\u0026rdquo;) Quá trình này sẽ lập chỉ mục tất cả tài liệu và tạo vector embeddings Trạng thái Sync:\n🔄 Syncing: Đang xử lý ✅ Ready: Hoàn thành thành công ❌ Failed: Kiểm tra quyền S3 hoặc định dạng tài liệu Bước 6: Lấy Knowledge Base ID Bạn sẽ cần ID này cho ứng dụng backend:\nTrong trang Knowledge Base Copy Knowledge Base ID (định dạng: 89CI1JSSE4 hoặc tương tự) Lưu vào ghi chú - bạn sẽ sử dụng nó ở bước tiếp theo Ví dụ Knowledge Base ID:\nKnowledge Base ID: 89CI1JSSE4 Knowledge Base ARN: arn:aws:bedrock:us-west-2:123456789:knowledge-base/89CI1JSSE4 Bước 7: Test Knowledge Base (Tùy chọn) Test Knowledge Base trực tiếp trong console:\nVào Knowledge Base của bạn Click tab Test Nhập câu hỏi: \u0026ldquo;Chính sách thuê xe là gì?\u0026rdquo; Click Run Xác minh nó trả về thông tin liên quan từ tài liệu Checklist xác minh Trước khi chuyển sang bước tiếp theo, đảm bảo:\n✅ Quyền truy cập Claude 3.5 Sonnet v2 đã được cấp ✅ Quyền truy cập Titan Embeddings đã được cấp ✅ S3 bucket đã tạo và upload tài liệu ✅ Knowledge Base đã tạo và sync thành công ✅ Knowledge Base ID đã lưu ✅ Câu hỏi test trả về kết quả liên quan Xử lý sự cố Vấn đề: \u0026ldquo;ValidationException: Model not enabled\u0026rdquo;\nGiải pháp: Vào Bedrock → Model access và kích hoạt model Vấn đề: \u0026ldquo;Sync failed\u0026rdquo;\nKiểm tra quyền truy cập S3 bucket Xác minh định dạng tài liệu (hỗ trợ PDF, TXT, DOCX) Kiểm tra CloudWatch Logs để xem lỗi chi tiết Vấn đề: \u0026ldquo;Không có kết quả từ Knowledge Base\u0026rdquo;\nĐảm bảo tài liệu đã upload lên S3 Chạy sync lại Đợi vài phút sau khi sync hoàn tất Thử đặt câu hỏi theo cách khác Tiếp theo: Chuyển sang Deploy Backend API để xây dựng FastAPI server.\n"},{"uri":"https://github.com/LeThiYenVi/AWS-Report.git/vi/5-workshop/5.3-s3-vpc/","title":"Truy cập S3 từ VPC","tags":[],"description":"","content":"Sử dụng Gateway endpoint Trong phần này, bạn sẽ tạo một Gateway endpoint để truy cập Amazon S3 từ một EC2 instance. Gateway endpoint sẽ cho phép tải một object lên S3 bucket mà không cần sử dụng Internet Công cộng. Để tạo endpoint, bạn phải chỉ định VPC mà bạn muốn tạo endpoint và dịch vụ (trong trường hợp này là S3) mà bạn muốn thiết lập kết nối.\nNội dung Tạo gateway endpoint Test gateway endpoint "},{"uri":"https://github.com/LeThiYenVi/AWS-Report.git/vi/1-worklog/1.3-week3/","title":"Worklog Tuần 3","tags":[],"description":"","content":"Mục tiêu tuần 3: Triển khai Điện toán: Khởi chạy thành công một EC2 Instance trong Public Subnet của VPC đã tạo. Quản lý Truy cập: Cấu hình Key Pair (ED25519) và Security Group để truy cập an toàn qua SSH. Ủy quyền Ứng dụng: Sử dụng IAM Role để cấp quyền truy cập S3 cho EC2 mà không cần lưu trữ Access Keys trên máy. Lưu trữ Khối: Tạo, gắn và định dạng thêm một EBS Volume để hiểu về lưu trữ bền vững. Các công việc cần triển khai trong tuần này: Task ID Thứ Công việc Ngày bắt đầu Ngày hoàn thành Trạng thái Nguồn tài liệu T3.1 2 EC2 - AMI Selection: - Lựa chọn Amazon Linux 2023 AMI (HVM) - Tối ưu hóa hiệu năng và bảo mật mặc định 22/09/2025 22/09/2025 Hoàn thành https://cloudjourney.awsstudygroup.com/ T3.2 2 Security - Key Management: - Tạo Key Pair loại ED25519 (an toàn hơn RSA) - Lưu trữ file .pem cục bộ với quyền 400 22/09/2025 22/09/2025 Hoàn thành https://cloudjourney.awsstudygroup.com/ T3.3 3 Compute - Launch Instance: - Khởi chạy instance t3.micro (Free Tier) - Trong Public Subnet 1 - Gán Security Group Web-SG đã tạo ở Tuần 2 23/09/2025 23/09/2025 Hoàn thành https://cloudjourney.awsstudygroup.com/ T3.4 4 IAM - Role Creation: - Tạo IAM Role EC2-S3-Access-Role - Policy: AmazonS3ReadOnlyAccess - Trust entity: ec2.amazonaws.com 24/09/2025 24/09/2025 Hoàn thành https://cloudjourney.awsstudygroup.com/ T3.5 4 Compute - Attach Role: - Gán IAM Role vào instance đang chạy - Thông qua Actions \u0026gt; Security \u0026gt; Modify IAM Role 24/09/2025 25/09/2025 Hoàn thành https://cloudjourney.awsstudygroup.com/ T3.6 5 CLI - Verification: - SSH vào instance - Cài đặt AWS CLI (nếu chưa có) - Chạy lệnh aws s3 ls để kiểm chứng quyền truy cập 25/09/2025 26/09/2025 Hoàn thành https://cloudjourney.awsstudygroup.com/ T3.7 6 Storage - EBS Operations: - Tạo volume EBS gp3 1GB cùng AZ với instance - Gán vào instance - Dùng lệnh lsblk, mkfs -t xfs, và mount 26/09/2025 28/09/2025 Hoàn thành https://cloudjourney.awsstudygroup.com/ Kết quả đạt được tuần 3: Hạ tầng hoạt động:\nMáy chủ Web đầu tiên đã online, có Public IP Truy cập được qua SSH an toàn Hiểu rõ sự khác biệt giữa các Instance Types (T3, C5, R5) Bảo mật Ứng dụng:\nĐã chứng minh EC2 có thể truy cập S3 Buckets mà không cần aws configure Không cần lưu Access Keys trên server Áp dụng cơ chế \u0026ldquo;Temporary Credentials\u0026rdquo; thông qua IAM Role Lưu trữ:\nHiểu sự khác biệt giữa EBS (bền vững) và Instance Store (tạm thời) Thực hành gắn và mount EBS volume Biết cách format và sử dụng ổ đĩa mới Khắc phục sự cố:\nBan đầu gặp lỗi \u0026ldquo;Connection Timeout\u0026rdquo; khi SSH Nguyên nhân: Quên thêm rule Inbound Port 22 trong Security Group Đã khắc phục và rút kinh nghiệm về troubleshooting Kỹ năng:\nThành thạo việc khởi chạy và quản lý EC2 instances Hiểu về vòng đời instance (Launch, Stop, Start, Terminate) Nắm vững khái niệm Instance Profiles và IAM Roles for EC2 "},{"uri":"https://github.com/LeThiYenVi/AWS-Report.git/vi/4-eventparticipated/","title":"Các events đã tham gia","tags":[],"description":"","content":"Trong suốt quá trình thực tập tại First Cloud Journey, em đã có cơ hội tham gia 4 sự kiện công nghệ quan trọng. Mỗi sự kiện không chỉ mang đến những kiến thức chuyên sâu về AWS Cloud và GenAI, mà còn là dịp để em mở rộng mạng lưới kết nối, học hỏi từ các chuyên gia hàng đầu, và trải nghiệm những khoảnh khắc đáng nhớ cùng cộng đồng Cloud Builders.\nEvent 1 Tên sự kiện: Vietnam Cloud Day 2025 - Ho Chi Minh City Connect Edition for Builders (Track 1: GenAI \u0026amp; Data)\nThời gian: 09:00 ngày 18/09/2025\nĐịa điểm: Tầng 26, tòa nhà Bitexco, số 02 đường Hải Triều, phường Sài Gòn, thành phố Hồ Chí Minh\nVai trò trong sự kiện: Người tham dự\nEvent 2 Tên sự kiện: AWS Cloud Mastery Series #1\nThời gian: 08:30 ngày 15/11/2025\nĐịa điểm: Tầng 26, tòa nhà Bitexco, số 02 đường Hải Triều, phường Sài Gòn, thành phố Hồ Chí Minh\nVai trò trong sự kiện: Người tham dự\nEvent 3 Tên sự kiện: AWS Cloud Mastery Series #2\nThời gian: 08:30 ngày 17/11/2025\nĐịa điểm: Tầng 26, tòa nhà Bitexco, số 02 đường Hải Triều, phường Sài Gòn, thành phố Hồ Chí Minh\nVai trò trong sự kiện: Người tham dự\nEvent 4 Tên sự kiện: AWS Cloud Mastery Series #3\nThời gian: 08:30 ngày 29/11/2025\nĐịa điểm: Tầng 26, tòa nhà Bitexco, số 02 đường Hải Triều, phường Sài Gòn, thành phố Hồ Chí Minh\nVai trò trong sự kiện: Người tham dự\n"},{"uri":"https://github.com/LeThiYenVi/AWS-Report.git/vi/4-eventparticipated/4.4-event4/","title":"Event 4","tags":[],"description":"","content":"BÁO CÁO THU HOẠCH SỰ KIỆN Sự kiện: AWS Cloud Mastery Series #3: Cloud Security \u0026amp; Operations\n1. MỤC TIÊU THAM DỰ Chuỗi sự kiện này không chỉ dừng lại ở việc giới thiệu công cụ, mà hướng tới việc xây dựng Tư duy hệ thống (System Thinking) vững chắc để chuyển mình từ hạ tầng truyền thống sang mô hình Cloud-Native Security. Các mục tiêu trọng tâm bao gồm:\nKết nối cộng đồng (Community): Lan tỏa tinh thần học hỏi thông qua AWS Cloud Clubs. Thiết lập nền móng quản trị (Governance): Đảm bảo tính tuân thủ khi vận hành hệ thống quy mô lớn với hàng trăm tài khoản AWS. Phòng thủ chiều sâu (Defense in Depth): Loại bỏ điểm chết duy nhất bằng cách phối hợp chặt chẽ giữa Định danh, Mạng lưới và Bảo vệ dữ liệu. Tự động hóa phản ứng (Automated Response): Khắc phục độ trễ do con người bằng các quy trình xử lý sự cố tự động. 2. DANH SÁCH DIỄN GIẢ Sự kiện quy tụ dàn chuyên gia từ AWS Community, Cloud Engineers và thành viên nòng cốt chương trình First Cloud Journey:\nAWS Cloud Clubs Captains: Le Vu Xuan An (HCMUTE), Tran Duc Anh (SGU), Tran Doan Cong Ly (PTIT), Danh Hoang Hieu Nghi (HUFLIT) Identity \u0026amp; Governance: Huynh Hoang Long, Dinh Le Hoang Anh (AWS Community Builders) Detection \u0026amp; Monitoring: Tran Duc Anh, Nguyen Tuan Thinh, Nguyen Do Thanh Dat Network Security: Kha Van (Cloud Security Engineer | AWS Community Builder) Data Protection: Thinh Lam, Viet Nguyen Incident Response: Mendel Grabski (Long) - ex Head of Security \u0026amp; DevOps, Tinh Truong - Platform Engineer 3. NỘI DUNG CHUYÊN MÔN NỔI BẬT 3.1. AWS Cloud Clubs \u0026amp; Cơ Hội Phát Triển Mở đầu là lời giới thiệu về AWS Cloud Clubs - vườn ươm tài năng Cloud tương lai:\nTầm nhìn: Trao quyền cho sinh viên làm chủ công nghệ đám mây, rèn luyện kỹ năng lãnh đạo và kết nối toàn cầu. Lợi ích: \u0026ldquo;Học đi đôi với hành\u0026rdquo; qua dự án thực tế, nhận voucher thi AWS, tài khoản Udemy và cơ hội nghề nghiệp. The Badging Journey: Lộ trình thăng tiến được game hóa qua các cấp bậc từ Bronze đến Diamond. Phần thưởng hấp dẫn gồm AWS Credits ($200+), voucher thi và đặc quyền tại Student Community Day. 3.2. Nền Tảng Định Danh Và Quản Trị (Identity \u0026amp; Governance) Kiểm soát \u0026ldquo;Ai được quyền làm gì\u0026rdquo; là bước đầu tiên của bảo mật:\nTư duy IAM hiện đại: Định danh (Identity) chính là bức tường lửa mới trên Cloud. Ưu tiên tuyệt đối Short-term Credentials (STS tokens tự hết hạn) thay vì Long-term Credentials (Access Keys đầy rủi ro). Nguyên tắc quyền tối thiểu (Least Privilege): Hạn chế tối đa việc dùng ký tự đại diện * trong Policy. Quản trị quy mô lớn: Sử dụng AWS Organizations để phân chia tổ chức thành các đơn vị (OUs) biệt lập. Áp dụng Service Control Policies (SCPs) như một \u0026ldquo;bản hiến pháp\u0026rdquo; để thiết lập các rào chắn (Guardrails) bất khả xâm phạm, ngăn chặn các hành động nguy hiểm ngay từ gốc. 3.3. Khả Năng Quan Sát Và Phát Hiện (Visibility \u0026amp; Detection) Không thể bảo vệ những gì ta không nhìn thấy:\nAmazon GuardDuty: \u0026ldquo;Trinh sát viên\u0026rdquo; sử dụng Machine Learning để soi chiếu 3 nguồn dữ liệu: CloudTrail, VPC Flow Logs và DNS Logs. Tính năng Runtime Monitoring cho phép nhìn sâu vào hệ điều hành để bắt các tiến trình lạ hay hành vi leo thang đặc quyền. AWS Security Hub: \u0026ldquo;Trung tâm chỉ huy\u0026rdquo; giúp chuẩn hóa mọi cảnh báo từ nhiều nguồn về định dạng chung ASFF. Đồng thời tự động đánh giá mức độ tuân thủ của hệ thống theo các chuẩn bảo mật quốc tế (CIS, PCI-DSS). 3.4. Bảo Mật Mạng Lưới (Network Security) Chiến lược xây dựng \u0026ldquo;Pháo đài số\u0026rdquo; phòng thủ nhiều lớp:\nKiểm soát cơ bản: Sử dụng Security Groups (Stateful) với kỹ thuật Micro-segmentation (tham chiếu theo nhóm thay vì IP cứng). Kết hợp NACLs (Stateless) để chặn thô tại biên giới Subnet. Phòng thủ nâng cao: DNS Firewall: Chặn kết nối đến máy chủ C2 của hacker ngay từ khâu phân giải tên miền. AWS Network Firewall: Tường lửa thế hệ mới với khả năng kiểm tra gói tin sâu (DPI), kết hợp bộ lọc Stateful engine (tương thích Suricata) để kiểm soát traffic ra Internet. Kiến trúc hiện đại: Tích hợp AWS Transit Gateway để đơn giản hóa định tuyến và áp dụng Active Threat Defense - tự động đồng bộ danh sách đen từ GuardDuty để chặn mối đe dọa tức thì. 3.5. Bảo Vệ Dữ Liệu (Data Protection) Bảo vệ tài sản số bằng mã hóa thông minh:\nMã hóa bao thư (Envelope Encryption): Hiểu rõ cơ chế KMS: Master Key bảo vệ Data Key, và Data Key mới trực tiếp mã hóa dữ liệu. Điều này đảm bảo hiệu năng và an toàn tối đa. Quản lý bí mật: Thay vì hardcode mật khẩu, hãy dùng AWS Secrets Manager kết hợp với Lambda để tự động xoay vòng (Automatic Rotation) mật khẩu Database định kỳ. Hạ tầng phần cứng: Tận dụng AWS Nitro System để đẩy tác vụ mã hóa xuống chip chuyên dụng, đảm bảo dữ liệu được bảo vệ mà không ảnh hưởng đến hiệu năng CPU máy chủ. 3.6. Ứng Phó Sự Cố (Incident Response) Quy trình phản ứng quyết định mức độ thiệt hại khi phòng thủ thất bại:\nChiến lược phòng ngừa: \u0026ldquo;Phòng bệnh hơn chữa bệnh\u0026rdquo; bằng cách loại bỏ SSH/Key dài hạn, chặn S3 Public. Bắt buộc quản lý hạ tầng bằng Code (IaC) để tránh sai sót thủ công (ClickOps). Quy trình 5 bước: Chuẩn bị $\\rightarrow$ Phát hiện $\\rightarrow$ Cô lập (đổi Security Group/gỡ quyền IAM) $\\rightarrow$ Diệt trừ \u0026amp; Phục hồi $\\rightarrow$ Hậu sự cố (Bài học kinh nghiệm). Tự động hóa là chìa khóa: Con người không thể nhanh bằng máy. Cần sử dụng EventBridge + Lambda để tự động cô lập tài nguyên bị nhiễm hoặc khắc phục lỗi cấu hình chỉ trong vài giây. 4. TRẢI NGHIỆM CHI TIẾT TRONG EVENT Chuỗi chuyên đề này đã hoàn toàn thay đổi cách tôi nhìn nhận về bảo mật Cloud:\n4.1. Tư duy \u0026ldquo;Security by Design\u0026rdquo; Điểm nhấn quan trọng nhất là việc chuyển từ tư duy \u0026ldquo;Bảo mật là bức tường\u0026rdquo; sang \u0026ldquo;Bảo mật là DNA\u0026rdquo;. Mỗi dịch vụ, mỗi kiến trúc đều phải được thiết kế với bảo mật ngay từ đầu, không phải là lớp vá sau cùng.\n4.2. Sức mạnh của tự động hóa Phần demo về Incident Response tự động đã khiến tôi ấn tượng sâu sắc. Việc sử dụng EventBridge kết hợp Lambda để phản ứng với các sự kiện bất thường trong vài giây thay vì phải chờ con người can thiệp thật sự là bước tiến lớn trong vận hành bảo mật.\n4.3. Cộng đồng là chìa khóa AWS Cloud Clubs không chỉ là nơi học kỹ thuật mà còn là môi trường rèn luyện kỹ năng mềm, networking và cơ hội nghề nghiệp. The Badging Journey đã game hóa quá trình học tập, tạo động lực mạnh mẽ để phát triển bản thân.\n5. KẾT LUẬN Chuỗi chuyên đề \u0026ldquo;Cloud Security \u0026amp; Operations Mastery\u0026rdquo; đã vẽ nên lộ trình toàn diện để kiến tạo hệ thống an toàn trên AWS:\nQuản trị \u0026amp; Định danh: Xây dựng nền móng vững chắc từ chính sách tổ chức và quản lý người dùng. Mạng lưới \u0026amp; Giám sát: Thiết lập hệ thống phòng thủ đa lớp cùng khả năng quan sát sâu rộng. Dữ liệu \u0026amp; Ứng phó: Bảo vệ tài sản cốt lõi bằng mã hóa và sẵn sàng các kịch bản phản ứng tự động để đảm bảo tính liên tục của doanh nghiệp. Đây là nền tảng kiến thức quan trọng để tôi có thể tự tin triển khai và vận hành các hệ thống Cloud với tư duy bảo mật toàn diện.\n"},{"uri":"https://github.com/LeThiYenVi/AWS-Report.git/vi/5-workshop/5.4-s3-onprem/5.4.4-dns-simulation/","title":"Mô phỏng On-premises DNS ","tags":[],"description":"","content":"AWS PrivateLink endpoint có một địa chỉ IP cố định trong từng AZ nơi chúng được triển khai, trong suốt thời gian tồn tại của endpoint (cho đến khi endpoint bị xóa). Các địa chỉ IP này được gắn vào Elastic network interface (ENI). AWS khuyến nghị sử dụng DNS để resolve địa chỉ IP cho endpoint để các ứng dụng downstream sử dụng địa chỉ IP mới nhất khi ENIs được thêm vào AZ mới hoặc bị xóa theo thời gian.\nTrong phần này, bạn sẽ tạo một quy tắc chuyển tiếp (forwarding rule) để gửi các yêu cầu resolve DNS từ môi trường truyền thống (mô phỏng) đến Private Hosted Zone trên Route 53. Phần này tận dụng cơ sở hạ tầng do CloudFormation triển khai trong phần Chuẩn bị môi trường.\nTạo DNS Alias Records cho Interface endpoint Click link để đi đến Route 53 management console (Hosted Zones section). Mẫu CloudFormation mà bạn triển khai trong phần Chuẩn bị môi trường đã tạo Private Hosted Zone này. Nhấp vào tên của Private Hosted Zone, s3.us-east-1.amazonaws.com: Tạo 1 record mới trong Private Hosted Zone: Giữ nguyên Record name và record type Alias Button: click để enable Route traffic to: Alias to VPC Endpoint Region: US East (N. Virginia) [us-east-1] Chọn endpoint: Paste tên (Regional VPC Endpoint DNS) bạn đã lưu lại ở phần 4.3 Click Add another record, và add 1 cái record thứ 2 sử dụng những thông số sau: Record name: *. Record type: giữ giá trị default (type A) Alias Button: Click để enable Route traffic to: Alias to VPC Endpoint Region: US East (N. Virginia) [us-east-1] Chọn endpoint: Paste tên (Regional VPC Endpoint DNS) bạn đã lưu lại ở phần 4.3 Click Create records Record mới xuất hiện trên giao diện Route 53.\nTạo một Resolver Forwarding Rule Route 53 Resolver Forwarding Rules cho phép bạn chuyển tiếp các DNS queries từ VPC của bạn đến các nguồn khác để resolve name. Bên ngoài môi trường workshop, bạn có thể sử dụng tính năng này để chuyển tiếp các DNS queries từ VPC của bạn đến các máy chủ DNS chạy trên on-premises. Trong phần này, bạn sẽ mô phỏng một on-premises conditional forwarder bằng cách tạo một forwarding rule để chuyển tiếp các DNS queries for Amazon S3 đến một Private Hosted Zone chạy trong \u0026ldquo;VPC Cloud\u0026rdquo; để resolve PrivateLink interface endpoint regional DNS name.\nTừ giao diện Route 53, chọn Inbound endpoints trên thanh bên trái\nTrong giao diện Inbound endpoint, Chọn ID của Inbound endpoint.\nSao chép 2 địa chỉ IP trong danh sách vào trình chỉnh sửa. Từ giao diện Route 53, chọn Resolver \u0026gt; Rules và chọn Create rule Trong giao diện Create rule Name: myS3Rule Rule type: Forward Domain name: s3.us-east-1.amazonaws.com VPC: VPC On-prem Outbound endpoint: VPCOnpremOutboundEndpoint Target IP Addresses: điền cả hai IP bạn đã lưu trữ trên trình soạn thảo (inbound endpoint addresses) và sau đó chọn Submit Bạn đã tạo thành công resolver forwarding rule.\nKiểm tra on-premises DNS mô phỏng. Kết nối đến Test-Interface-Endpoint EC2 instance với Session Manager Kiểm tra DNS resolution. Lệnh dig sẽ trả về địa chỉ IP được gán cho VPC endpoint interface đang chạy trên VPC (địa chỉ IP của bạn sẽ khác): dig +short s3.us-east-1.amazonaws.com Các địa chỉ IP được trả về là các địa chỉ IP VPC enpoint, KHÔNG phải là các địa chỉ IP Resolver mà bạn đã dán từ trình chỉnh sửa văn bản của mình. Các địa chỉ IP của Resolver endpoint và VPC endpoin trông giống nhau vì chúng đều từ khối CIDR VPC Cloud.\nTruy cập vào menu VPC (phần Endpoints), chọn S3 interface endpoint. Nhấp vào tab Subnets và xác nhận rằng các địa chỉ IP được trả về bởi lệnh Dig khớp với VPC endpoint: Hãy quay lại shell của bạn và sử dụng AWS CLI để kiểm tra danh sách các bucket S3 của bạn: aws s3 ls --endpoint-url https://s3.us-east-1.amazonaws.com Kết thúc phiên làm việc của Session Manager của bạn: Trong phần này, bạn đã tạo một Interface Endpoint cho Amazon S3. Điểm cuối này có thể được truy cập từ on-premises thông qua Site-to-Site VPN hoặc AWS Direct Connect. Các điểm cuối Route 53 Resolver outbound giả lập chuyển tiếp các yêu cầu DNS từ on-premises đến một Private Hosted Zone đang chạy trên đám mây. Các điểm cuối Route 53 inbound nhận yêu cầu giải quyết và trả về một phản hồi chứa địa chỉ IP của Interface Endpoint VPC. Sử dụng DNS để giải quyết các địa chỉ IP của điểm cuối cung cấp tính sẵn sàng cao trong trường hợp một Availability Zone gặp sự cố.\n"},{"uri":"https://github.com/LeThiYenVi/AWS-Report.git/vi/5-workshop/5.4-deploy-backend/","title":"Triển khai Backend API","tags":[],"description":"","content":"Triển khai Backend API với FastAPI Trong phần này, bạn sẽ thiết lập máy chủ backend FastAPI điều phối AI agent sử dụng Strands SDK.\nBước 1: Clone hoặc Tạo Cấu trúc Dự án Tạo thư mục mới cho backend:\nmkdir ev-rental-backend cd ev-rental-backend Cấu trúc dự án:\nev-rental-backend/ ├── app/ │ ├── __init__.py │ ├── main.py # Ứng dụng FastAPI │ ├── agent.py # Thiết lập Strands Agent │ ├── tools.py # Công cụ Agent (tìm xe, trạm) │ └── database.py # Kết nối PostgreSQL ├── requirements.txt # Thư viện Python ├── .env # Biến môi trường └── README.md Bước 2: Cài đặt Thư viện Tạo file requirements.txt:\nfastapi==0.104.1 uvicorn[standard]==0.24.0 strands-agent-sdk==0.1.5 boto3==1.34.10 psycopg2-binary==2.9.9 sqlalchemy==2.0.23 pydantic==2.5.2 python-dotenv==1.0.0 httpx==0.25.2 Cài đặt các thư viện:\n# Tạo môi trường ảo python -m venv venv # Kích hoạt môi trường ảo # Windows: venv\\Scripts\\activate # macOS/Linux: source venv/bin/activate # Cài đặt packages pip install -r requirements.txt Bước 3: Cấu hình Biến Môi trường Tạo file .env với thông tin AWS và Knowledge Base ID:\n# AWS Credentials AWS_ACCESS_KEY_ID=YOUR_ACCESS_KEY_ID AWS_SECRET_ACCESS_KEY=YOUR_SECRET_ACCESS_KEY AWS_REGION=us-west-2 # Cấu hình Bedrock BEDROCK_MODEL_ID=anthropic.claude-3-5-sonnet-20241022-v2:0 KNOWLEDGE_BASE_ID=89CI1JSSE4 # Cấu hình Database DATABASE_URL=postgresql://postgres:password@localhost:5432/ev_rental_db # Cấu hình API BACKEND_API_URL=http://localhost:8080 ⚠️ Lưu ý Bảo mật:\nKhông bao giờ commit .env lên Git Thêm .env vào .gitignore Bước 4: Tạo Database Models Tạo file app/database.py:\nfrom sqlalchemy import create_engine, Column, Integer, String, Text, DateTime from sqlalchemy.ext.declarative import declarative_base from sqlalchemy.orm import sessionmaker from datetime import datetime import os DATABASE_URL = os.getenv(\u0026#34;DATABASE_URL\u0026#34;) engine = create_engine(DATABASE_URL) SessionLocal = sessionmaker(autocommit=False, autoflush=False, bind=engine) Base = declarative_base() class ChatHistory(Base): __tablename__ = \u0026#34;chat_history\u0026#34; id = Column(Integer, primary_key=True, index=True) session_id = Column(String, index=True) user_message = Column(Text) agent_response = Column(Text) timestamp = Column(DateTime, default=datetime.utcnow) # Tạo bảng Base.metadata.create_all(bind=engine) Bước 5: Tạo Agent Tools Tạo file app/tools.py:\nimport httpx import os from typing import List, Dict BACKEND_API_URL = os.getenv(\u0026#34;BACKEND_API_URL\u0026#34;, \u0026#34;http://localhost:8080\u0026#34;) async def search_vehicles(location: str = None, model: str = None) -\u0026gt; List[Dict]: \u0026#34;\u0026#34;\u0026#34;Tìm kiếm xe có sẵn\u0026#34;\u0026#34;\u0026#34; async with httpx.AsyncClient() as client: params = {} if location: params[\u0026#34;location\u0026#34;] = location if model: params[\u0026#34;model\u0026#34;] = model response = await client.get(f\u0026#34;{BACKEND_API_URL}/api/vehicles\u0026#34;, params=params) return response.json() async def search_stations(city: str = None) -\u0026gt; List[Dict]: \u0026#34;\u0026#34;\u0026#34;Tìm kiếm trạm sạc\u0026#34;\u0026#34;\u0026#34; async with httpx.AsyncClient() as client: params = {} if city: params[\u0026#34;city\u0026#34;] = city response = await client.get(f\u0026#34;{BACKEND_API_URL}/api/stations\u0026#34;, params=params) return response.json() Bước 6: Thiết lập Strands Agent Tạo file app/agent.py:\nimport boto3 import os from strands_agent import Agent, Tool # Khởi tạo Bedrock client bedrock_client = boto3.client( \u0026#39;bedrock-runtime\u0026#39;, region_name=os.getenv(\u0026#39;AWS_REGION\u0026#39;), aws_access_key_id=os.getenv(\u0026#39;AWS_ACCESS_KEY_ID\u0026#39;), aws_secret_access_key=os.getenv(\u0026#39;AWS_SECRET_ACCESS_KEY\u0026#39;) ) # Khởi tạo Knowledge Base client bedrock_agent_client = boto3.client( \u0026#39;bedrock-agent-runtime\u0026#39;, region_name=os.getenv(\u0026#39;AWS_REGION\u0026#39;), aws_access_key_id=os.getenv(\u0026#39;AWS_ACCESS_KEY_ID\u0026#39;), aws_secret_access_key=os.getenv(\u0026#39;AWS_SECRET_ACCESS_KEY\u0026#39;) ) # Tạo Agent agent = Agent( model_id=os.getenv(\u0026#39;BEDROCK_MODEL_ID\u0026#39;), client=bedrock_client, knowledge_base_id=os.getenv(\u0026#39;KNOWLEDGE_BASE_ID\u0026#39;), tools=[ Tool( name=\u0026#34;search_vehicles\u0026#34;, description=\u0026#34;Tìm kiếm xe điện có sẵn để thuê\u0026#34;, function=search_vehicles ), Tool( name=\u0026#34;search_stations\u0026#34;, description=\u0026#34;Tìm trạm sạc gần đó\u0026#34;, function=search_stations ) ] ) Bước 7: Tạo Ứng dụng FastAPI Tạo file app/main.py:\nfrom fastapi import FastAPI, HTTPException from fastapi.middleware.cors import CORSMiddleware from pydantic import BaseModel from app.agent import agent from app.database import SessionLocal, ChatHistory import uuid app = FastAPI(title=\u0026#34;EV Rental AI Agent API\u0026#34;) # Bật CORS app.add_middleware( CORSMiddleware, allow_origins=[\u0026#34;*\u0026#34;], allow_credentials=True, allow_methods=[\u0026#34;*\u0026#34;], allow_headers=[\u0026#34;*\u0026#34;], ) class ChatRequest(BaseModel): message: str session_id: str = None class ChatResponse(BaseModel): response: str session_id: str data: dict = None @app.post(\u0026#34;/chat\u0026#34;, response_model=ChatResponse) async def chat(request: ChatRequest): try: # Tạo session ID nếu chưa có session_id = request.session_id or str(uuid.uuid4()) # Lấy phản hồi từ agent agent_response = await agent.run(request.message) # Lưu vào database db = SessionLocal() chat_record = ChatHistory( session_id=session_id, user_message=request.message, agent_response=agent_response[\u0026#34;response\u0026#34;] ) db.add(chat_record) db.commit() db.close() return ChatResponse( response=agent_response[\u0026#34;response\u0026#34;], session_id=session_id, data=agent_response.get(\u0026#34;data\u0026#34;) ) except Exception as e: raise HTTPException(status_code=500, detail=str(e)) @app.get(\u0026#34;/health\u0026#34;) async def health_check(): return {\u0026#34;status\u0026#34;: \u0026#34;healthy\u0026#34;} Bước 8: Chạy Backend Server Khởi động máy chủ FastAPI:\n# Đảm bảo môi trường ảo đã được kích hoạt uvicorn app.main:app --reload --port 8000 # Bạn sẽ thấy: # INFO: Uvicorn running on http://127.0.0.1:8000 # INFO: Application startup complete. Bước 9: Kiểm tra API Kiểm tra endpoint health:\ncurl http://localhost:8000/health # Kết quả: {\u0026#34;status\u0026#34;:\u0026#34;healthy\u0026#34;} Kiểm tra endpoint chat:\ncurl -X POST http://localhost:8000/chat \\ -H \u0026#34;Content-Type: application/json\u0026#34; \\ -d \u0026#39;{\u0026#34;message\u0026#34;: \u0026#34;Chính sách thuê xe của bạn là gì?\u0026#34;}\u0026#39; Kết quả mong đợi:\n{ \u0026#34;response\u0026#34;: \u0026#34;## 📋 Chính sách thuê xe VinFast\\n\\n### 📄 Giấy tờ cần thiết:\\n- CMND/CCCD...\u0026#34;, \u0026#34;session_id\u0026#34;: \u0026#34;abc123-...\u0026#34;, \u0026#34;data\u0026#34;: null } Checklist Xác minh Trước khi tiếp tục, đảm bảo:\n✅ Môi trường ảo đã được tạo và kích hoạt ✅ Tất cả thư viện đã được cài đặt ✅ File .env đã được cấu hình với AWS credentials ✅ PostgreSQL database đang chạy và kết nối được ✅ Máy chủ FastAPI đang chạy trên cổng 8000 ✅ Endpoint health check trả về {\u0026quot;status\u0026quot;:\u0026quot;healthy\u0026quot;} ✅ Endpoint chat trả về phản hồi hợp lệ Xử lý Sự cố Vấn đề: \u0026ldquo;ModuleNotFoundError\u0026rdquo;\nGiải pháp: Đảm bảo môi trường ảo đã được kích hoạt và thư viện đã cài đặt Vấn đề: \u0026ldquo;Database connection failed\u0026rdquo;\nKiểm tra PostgreSQL đang chạy Xác minh DATABASE_URL trong .env Test kết nối: psql -h localhost -U postgres -d ev_rental_db Vấn đề: \u0026ldquo;Bedrock ValidationException\u0026rdquo;\nXác minh AWS credentials trong .env Đảm bảo quyền truy cập model đã được cấp trong Bedrock console Kiểm tra KNOWLEDGE_BASE_ID chính xác Tiếp theo: Chuyển sang Triển khai Frontend để tạo giao diện chat React.\n"},{"uri":"https://github.com/LeThiYenVi/AWS-Report.git/vi/5-workshop/5.4-s3-onprem/","title":"Truy cập S3 từ môi trường truyền thống","tags":[],"description":"","content":"Tổng quan Trong phần này, bạn sẽ tạo một Interface Endpoint để truy cập Amazon S3 từ môi trường truyền thống mô phỏng. Interface Endpoint sẽ cho phép bạn định tuyến đến Amazon S3 qua kết nối VPN từ môi trường truyền thống mô phỏng của bạn.\nTại sao nên sử dụng Interface Endpoint:\nCác Gateway endpoints chỉ hoạt động với các tài nguyên đang chạy trong VPC nơi chúng được tạo. Interface Endpoint hoạt động với tài nguyên chạy trong VPC và cả tài nguyên chạy trong môi trường truyền thống. Khả năng kết nối từ môi trường truyền thống của bạn với aws cloud có thể được cung cấp bởi AWS Site-to-Site VPN hoặc AWS Direct Connect. Interface Endpoint cho phép bạn kết nối với các dịch vụ do AWS PrivateLink cung cấp. Các dịch vụ này bao gồm một số dịch vụ AWS, dịch vụ do các đối tác và khách hàng AWS lưu trữ trong VPC của riêng họ (gọi tắt là Dịch vụ PrivateLink endpoints) và các dịch vụ Đối tác AWS Marketplace. Đối với workshop này, chúng ta sẽ tập trung vào việc kết nối với Amazon S3. "},{"uri":"https://github.com/LeThiYenVi/AWS-Report.git/vi/1-worklog/1.4-week4/","title":"Worklog Tuần 4","tags":[],"description":"","content":"Mục tiêu tuần 4: Môi trường Dev: Thiết lập AWS Cloud9 để làm môi trường phát triển thống nhất. Web Serverless: Triển khai website tĩnh trên S3, cấu hình Bucket Policy để cho phép truy cập công khai an toàn. Cơ sở dữ liệu: Khởi tạo Amazon RDS MySQL trong Private Subnet để đảm bảo bảo mật. Kết nối Đa tầng: Thực hiện kết nối từ EC2/Cloud9 (Public Subnet) tới RDS (Private Subnet). Các công việc cần triển khai trong tuần này: Task ID Thứ Công việc Ngày bắt đầu Ngày hoàn thành Trạng thái Nguồn tài liệu T4.1 2 Cloud9 - Setup IDE: - Khởi tạo môi trường Cloud9 (EC2 t3.small) trong VPC - Kích hoạt tính năng Auto-hibernate sau 30 phút 29/09/2025 29/09/2025 Hoàn thành https://cloudjourney.awsstudygroup.com/ T4.2 3 S3 - Static Hosting: - Tạo S3 Bucket với tên duy nhất - Bật \u0026ldquo;Static website hosting\u0026rdquo; - Upload index.html và error.html 30/09/2025 30/09/2025 Hoàn thành https://cloudjourney.awsstudygroup.com/ T4.3 3 S3 - Public Policy: - Tắt \u0026ldquo;Block Public Access\u0026rdquo; - Viết Bucket Policy (JSON) cho phép s3:GetObject 30/09/2025 01/10/2025 Hoàn thành https://cloudjourney.awsstudygroup.com/ T4.4 4 RDS - Subnet Group: - Tạo DB Subnet Group - Bao gồm 2 Private Subnets đã tạo ở Tuần 2 01/10/2025 01/10/2025 Hoàn thành https://cloudjourney.awsstudygroup.com/ T4.5 4 RDS - Launch DB: - Khởi chạy RDS MySQL (Free Tier) - Tắt Multi-AZ - Tắt Public Accessibility 01/10/2025 02/10/2025 Hoàn thành https://cloudjourney.awsstudygroup.com/ T4.6 5 Security - Security Chaining: - Cấu hình Security Group của RDS - Chỉ cho phép Inbound Port 3306 từ SG của Cloud9/EC2 02/10/2025 03/10/2025 Hoàn thành https://cloudjourney.awsstudygroup.com/ T4.7 6 Database - Connection Test: - Sử dụng terminal trên Cloud9 - Kết nối MySQL: mysql -h \u0026lt;endpoint\u0026gt; -u admin -p 03/10/2025 05/10/2025 Hoàn thành https://cloudjourney.awsstudygroup.com/ Kết quả đạt được tuần 4: Web:\nWebsite tĩnh đã hoạt động tại S3 Endpoint URL Hiểu rõ cách S3 có thể host website mà không cần server Nắm vững cách viết Bucket Policy cho public access an toàn Database:\nDB instance hoạt động biệt lập trong mạng nội bộ Không thể truy cập DB trực tiếp từ Internet (đúng chuẩn bảo mật) Hiểu về RDS Managed Service và lợi ích của nó Kỹ năng:\nĐã nắm vững cú pháp JSON cho S3 Policy Hiểu khái niệm \u0026ldquo;Security Group Referencing\u0026rdquo; (tham chiếu SG lồng nhau) Kỹ thuật quan trọng để xây dựng kiến trúc N-tier năng động Kiến trúc:\nHoàn thiện mô hình \u0026ldquo;3-Tier Web Architecture\u0026rdquo; sơ khai: Presentation Tier (S3) Application Tier (Cloud9/EC2) Data Tier (RDS) Hiểu về separation of concerns trong cloud architecture "},{"uri":"https://github.com/LeThiYenVi/AWS-Report.git/vi/5-workshop/5.5-deploy-frontend/","title":"Triển khai Frontend","tags":[],"description":"","content":"Triển khai Giao diện React Frontend Trong phần này, bạn sẽ thiết lập và chạy giao diện chat React kết nối với backend FastAPI.\nBước 1: Clone hoặc Tạo Dự án React Tạo ứng dụng React mới:\n# Sử dụng Create React App npx create-react-app ev-rental-frontend cd ev-rental-frontend # Hoặc clone repository có sẵn git clone https://github.com/your-org/ev-rental-frontend.git cd ev-rental-frontend Bước 2: Cài đặt Thư viện Cài đặt các gói npm cần thiết:\n# Thư viện cốt lõi npm install axios react-markdown npm install @chakra-ui/react @emotion/react @emotion/styled framer-motion npm install react-icons # Hoặc dùng package.json npm install Ví dụ dependencies trong package.json:\n{ \u0026#34;dependencies\u0026#34;: { \u0026#34;react\u0026#34;: \u0026#34;^18.2.0\u0026#34;, \u0026#34;react-dom\u0026#34;: \u0026#34;^18.2.0\u0026#34;, \u0026#34;axios\u0026#34;: \u0026#34;^1.6.2\u0026#34;, \u0026#34;@chakra-ui/react\u0026#34;: \u0026#34;^2.8.2\u0026#34;, \u0026#34;@emotion/react\u0026#34;: \u0026#34;^11.11.1\u0026#34;, \u0026#34;@emotion/styled\u0026#34;: \u0026#34;^11.11.0\u0026#34;, \u0026#34;framer-motion\u0026#34;: \u0026#34;^10.16.16\u0026#34;, \u0026#34;react-markdown\u0026#34;: \u0026#34;^9.0.1\u0026#34;, \u0026#34;react-icons\u0026#34;: \u0026#34;^4.12.0\u0026#34; } } Bước 3: Cấu trúc Dự án Frontend của bạn nên có cấu trúc như sau:\nev-rental-frontend/ ├── public/ │ ├── index.html │ └── favicon.ico ├── src/ │ ├── App.js # Component chính │ ├── index.js # Entry point │ ├── components/ │ │ ├── ChatInterface.js # Component giao diện chat │ │ ├── MessageList.js # Hiển thị tin nhắn │ │ └── InputBox.js # Nhập liệu người dùng │ ├── services/ │ │ └── api.js # Gọi API tới backend │ ├── utils/ │ │ └── constants.js # Cấu hình │ └── styles/ │ └── App.css ├── package.json └── .env Bước 4: Cấu hình Biến Môi trường Tạo file .env ở thư mục gốc dự án:\n# .env REACT_APP_API_URL=http://localhost:8000 REACT_APP_API_BASE_PATH=/api ⚠️ Quan trọng: Trong React, biến môi trường phải bắt đầu với tiền tố REACT_APP_.\nBước 5: Tạo API Service Tạo file src/services/api.js:\nimport axios from \u0026#39;axios\u0026#39;; const API_URL = process.env.REACT_APP_API_URL || \u0026#39;http://localhost:8000\u0026#39;; const api = axios.create({ baseURL: API_URL, headers: { \u0026#39;Content-Type\u0026#39;: \u0026#39;application/json\u0026#39;, }, }); export const sendMessage = async (sessionId, message) =\u0026gt; { try { const response = await api.post(\u0026#39;/api/chat\u0026#39;, { session_id: sessionId, message: message, }); return response.data; } catch (error) { console.error(\u0026#39;Lỗi API:\u0026#39;, error); throw error; } }; export default api; Bước 6: Tạo Component Giao diện Chat Tạo file src/components/ChatInterface.js:\nimport React, { useState, useEffect, useRef } from \u0026#39;react\u0026#39;; import { Box, VStack, HStack, Input, Button, Text, Container, Heading, } from \u0026#39;@chakra-ui/react\u0026#39;; import ReactMarkdown from \u0026#39;react-markdown\u0026#39;; import { sendMessage } from \u0026#39;../services/api\u0026#39;; function ChatInterface() { const [messages, setMessages] = useState([]); const [input, setInput] = useState(\u0026#39;\u0026#39;); const [loading, setLoading] = useState(false); const [sessionId] = useState(() =\u0026gt; `session-${Date.now()}-${Math.random().toString(36).substr(2, 9)}` ); const messagesEndRef = useRef(null); const scrollToBottom = () =\u0026gt; { messagesEndRef.current?.scrollIntoView({ behavior: \u0026#39;smooth\u0026#39; }); }; useEffect(() =\u0026gt; { scrollToBottom(); }, [messages]); const handleSend = async () =\u0026gt; { if (!input.trim()) return; const userMessage = { role: \u0026#39;user\u0026#39;, content: input }; setMessages((prev) =\u0026gt; [...prev, userMessage]); setInput(\u0026#39;\u0026#39;); setLoading(true); try { const response = await sendMessage(sessionId, input); const assistantMessage = { role: \u0026#39;assistant\u0026#39;, content: response.response, data: response.data, }; setMessages((prev) =\u0026gt; [...prev, assistantMessage]); } catch (error) { const errorMessage = { role: \u0026#39;error\u0026#39;, content: \u0026#39;Không thể nhận phản hồi. Vui lòng thử lại.\u0026#39;, }; setMessages((prev) =\u0026gt; [...prev, errorMessage]); } finally { setLoading(false); } }; return ( \u0026lt;Container maxW=\u0026#34;container.md\u0026#34; py={8}\u0026gt; \u0026lt;VStack spacing={4} align=\u0026#34;stretch\u0026#34;\u0026gt; \u0026lt;Heading size=\u0026#34;lg\u0026#34;\u0026gt;🚗 EV Rental AI Agent\u0026lt;/Heading\u0026gt; \u0026lt;Box border=\u0026#34;1px\u0026#34; borderColor=\u0026#34;gray.200\u0026#34; borderRadius=\u0026#34;lg\u0026#34; p={4} h=\u0026#34;500px\u0026#34; overflowY=\u0026#34;auto\u0026#34; bg=\u0026#34;gray.50\u0026#34; \u0026gt; \u0026lt;VStack spacing={3} align=\u0026#34;stretch\u0026#34;\u0026gt; {messages.map((msg, idx) =\u0026gt; ( \u0026lt;Box key={idx} alignSelf={msg.role === \u0026#39;user\u0026#39; ? \u0026#39;flex-end\u0026#39; : \u0026#39;flex-start\u0026#39;} maxW=\u0026#34;80%\u0026#34; bg={msg.role === \u0026#39;user\u0026#39; ? \u0026#39;blue.500\u0026#39; : \u0026#39;white\u0026#39;} color={msg.role === \u0026#39;user\u0026#39; ? \u0026#39;white\u0026#39; : \u0026#39;black\u0026#39;} p={3} borderRadius=\u0026#34;lg\u0026#34; boxShadow=\u0026#34;sm\u0026#34; \u0026gt; {msg.role === \u0026#39;assistant\u0026#39; ? ( \u0026lt;ReactMarkdown\u0026gt;{msg.content}\u0026lt;/ReactMarkdown\u0026gt; ) : ( \u0026lt;Text\u0026gt;{msg.content}\u0026lt;/Text\u0026gt; )} \u0026lt;/Box\u0026gt; ))} {loading \u0026amp;\u0026amp; ( \u0026lt;Box alignSelf=\u0026#34;flex-start\u0026#34; maxW=\u0026#34;80%\u0026#34;\u0026gt; \u0026lt;Text color=\u0026#34;gray.500\u0026#34;\u0026gt;Đang nhập...\u0026lt;/Text\u0026gt; \u0026lt;/Box\u0026gt; )} \u0026lt;div ref={messagesEndRef} /\u0026gt; \u0026lt;/VStack\u0026gt; \u0026lt;/Box\u0026gt; \u0026lt;HStack\u0026gt; \u0026lt;Input value={input} onChange={(e) =\u0026gt; setInput(e.target.value)} onKeyPress={(e) =\u0026gt; e.key === \u0026#39;Enter\u0026#39; \u0026amp;\u0026amp; handleSend()} placeholder=\u0026#34;Hỏi về thuê xe, chính sách, hoặc trạm sạc...\u0026#34; disabled={loading} /\u0026gt; \u0026lt;Button onClick={handleSend} colorScheme=\u0026#34;blue\u0026#34; isLoading={loading} disabled={loading} \u0026gt; Gửi \u0026lt;/Button\u0026gt; \u0026lt;/HStack\u0026gt; \u0026lt;/VStack\u0026gt; \u0026lt;/Container\u0026gt; ); } export default ChatInterface; Bước 7: Cập nhật App.js Cập nhật file src/App.js:\nimport React from \u0026#39;react\u0026#39;; import { ChakraProvider } from \u0026#39;@chakra-ui/react\u0026#39;; import ChatInterface from \u0026#39;./components/ChatInterface\u0026#39;; function App() { return ( \u0026lt;ChakraProvider\u0026gt; \u0026lt;ChatInterface /\u0026gt; \u0026lt;/ChakraProvider\u0026gt; ); } export default App; Bước 8: Chạy Frontend Khởi động máy chủ phát triển React:\nnpm start Kết quả mong đợi:\nCompiled successfully! You can now view ev-rental-frontend in the browser. Local: http://localhost:3000 On Your Network: http://192.168.1.10:3000 Ứng dụng sẽ tự động mở trong trình duyệt tại http://localhost:3000.\nBước 9: Kiểm tra Giao diện Chat Thử các câu hỏi mẫu:\nTruy vấn Knowledge Base:\n\u0026ldquo;Chính sách thuê xe là gì?\u0026rdquo; \u0026ldquo;Tôi cần giấy tờ gì để thuê xe?\u0026rdquo; Tìm kiếm Xe:\n\u0026ldquo;Tìm xe VinFast VF8 ở Hà Nội từ ngày 20/12\u0026rdquo; \u0026ldquo;Có xe nào available?\u0026rdquo; Trạm Sạc:\n\u0026ldquo;Trạm sạc gần Hoàn Kiếm\u0026rdquo; \u0026ldquo;Tìm trạm sạc ở Quận 1\u0026rdquo; Danh sách Kiểm tra Trước khi tiếp tục, đảm bảo:\n✅ Đã cài đặt Node.js và npm ✅ Tất cả thư viện đã cài đặt thành công ✅ File .env đã cấu hình URL backend ✅ Backend server đang chạy trên cổng 8000 ✅ Frontend đang chạy trên cổng 3000 ✅ Giao diện chat tải không có lỗi ✅ Có thể gửi tin nhắn và nhận phản hồi ✅ Định dạng Markdown hiển thị đúng Xử lý Sự cố Lỗi: \u0026ldquo;Module not found\u0026rdquo;\nGiải pháp: Xóa node_modules và chạy lại npm install Kiểm tra phiên bản trong package.json Lỗi: \u0026ldquo;Network Error\u0026rdquo; khi gửi tin nhắn\nKiểm tra backend đang chạy: curl http://localhost:8000/health Xác minh REACT_APP_API_URL trong .env Kiểm tra console trình duyệt có lỗi CORS Lỗi: \u0026ldquo;CORS policy error\u0026rdquo;\nĐảm bảo backend có cấu hình CORS middleware Kiểm tra allow_origins bao gồm http://localhost:3000 Lỗi: Cổng 3000 đã được sử dụng\nĐổi cổng: PORT=3001 npm start Hoặc kill process hiện tại Lỗi: Markdown không render\nXác minh react-markdown đã được cài đặt Kiểm tra câu lệnh import trong ChatInterface.js Tiếp theo: Chuyển sang Testing để xác minh tất cả tính năng hoạt động đúng.\n"},{"uri":"https://github.com/LeThiYenVi/AWS-Report.git/vi/5-workshop/5.5-policy/","title":"VPC Endpoint Policies","tags":[],"description":"","content":"Khi bạn tạo một Interface Endpoint hoặc cổng, bạn có thể đính kèm một chính sách điểm cuối để kiểm soát quyền truy cập vào dịch vụ mà bạn đang kết nối. Chính sách VPC Endpoint là chính sách tài nguyên IAM mà bạn đính kèm vào điểm cuối. Nếu bạn không đính kèm chính sách khi tạo điểm cuối, thì AWS sẽ đính kèm chính sách mặc định cho bạn để cho phép toàn quyền truy cập vào dịch vụ thông qua điểm cuối.\nBạn có thể tạo chính sách chỉ hạn chế quyền truy cập vào các S3 bucket cụ thể. Điều này hữu ích nếu bạn chỉ muốn một số Bộ chứa S3 nhất định có thể truy cập được thông qua điểm cuối.\nTrong phần này, bạn sẽ tạo chính sách VPC Endpoint hạn chế quyền truy cập vào S3 bucket được chỉ định trong chính sách VPC Endpoint.\nKết nối tới EC2 và xác minh kết nối tới S3. Bắt đầu một phiên AWS Session Manager mới trên máy chủ có tên là Test-Gateway-Endpoint. Từ phiên này, xác minh rằng bạn có thể liệt kê nội dung của bucket mà bạn đã tạo trong Phần 1: Truy cập S3 từ VPC. aws s3 ls s3://\u0026lt;your-bucket-name\u0026gt; Nội dung của bucket bao gồm hai tệp có dung lượng 1GB đã được tải lên trước đó.\nTạo một bucket S3 mới; tuân thủ mẫu đặt tên mà bạn đã sử dụng trong Phần 1, nhưng thêm \u0026lsquo;-2\u0026rsquo; vào tên. Để các trường khác là mặc định và nhấp vào Create. Tạo bucket thành công. Policy mặc định cho phép truy cập vào tất cả các S3 Buckets thông qua VPC endpoint.\nTrong giao diện Edit Policy, sao chép và dán theo policy sau, thay thế yourbucketname-2 với tên bucket thứ hai của bạn. Policy này sẽ cho phép truy cập đến bucket mới thông qua VPC endpoint, nhưng không cho phép truy cập đến các bucket còn lại. Chọn Save để kích hoạt policy. { \u0026#34;Id\u0026#34;: \u0026#34;Policy1631305502445\u0026#34;, \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Sid\u0026#34;: \u0026#34;Stmt1631305501021\u0026#34;, \u0026#34;Action\u0026#34;: \u0026#34;s3:*\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Resource\u0026#34;: [ \u0026#34;arn:aws:s3:::yourbucketname-2\u0026#34;, \u0026#34;arn:aws:s3:::yourbucketname-2/*\u0026#34; ], \u0026#34;Principal\u0026#34;: \u0026#34;*\u0026#34; } ] } Cấu hình policy thành công.\nTừ session của bạn trên Test-Gateway-Endpoint instance, kiểm tra truy cập đến S3 bucket bạn tạo ở bước đầu aws s3 ls s3://\u0026lt;yourbucketname\u0026gt; Câu lệnh trả về lỗi bởi vì truy cập vào S3 bucket không có quyền trong VPC endpoint policy.\nTrở lại home directory của bạn trên EC2 instance cd~ Tạo file fallocate -l 1G test-bucket2.xyz Sao chép file lên bucket thứ 2 aws s3 cp test-bucket2.xyz s3://\u0026lt;your-2nd-bucket-name\u0026gt; Thao tác này được cho phép bởi VPC endpoint policy.\nSau đó chúng ta kiểm tra truy cập vào S3 bucket đầu tiên\naws s3 cp test-bucket2.xyz s3://\u0026lt;your-1st-bucket-name\u0026gt;\nCâu lệnh xảy ra lỗi bởi vì bucket không có quyền truy cập bởi VPC endpoint policy.\nTrong phần này, bạn đã tạo chính sách VPC Endpoint cho Amazon S3 và sử dụng AWS CLI để kiểm tra chính sách. Các hoạt động AWS CLI liên quan đến bucket S3 ban đầu của bạn thất bại vì bạn áp dụng một chính sách chỉ cho phép truy cập đến bucket thứ hai mà bạn đã tạo. Các hoạt động AWS CLI nhắm vào bucket thứ hai của bạn thành công vì chính sách cho phép chúng. Những chính sách này có thể hữu ích trong các tình huống khi bạn cần kiểm soát quyền truy cập vào tài nguyên thông qua VPC Endpoint.\n"},{"uri":"https://github.com/LeThiYenVi/AWS-Report.git/vi/1-worklog/1.5-week5/","title":"Worklog Tuần 5","tags":[],"description":"","content":"Mục tiêu tuần 5: VPS Nhanh: Triển khai ứng dụng WordPress hoàn chỉnh trong 5 phút sử dụng Amazon Lightsail. Container hóa: Đóng gói ứng dụng nhỏ thành Docker Image và triển khai trên Lightsail Container Service. Tính Đàn hồi: Thiết lập kiến trúc tự phục hồi (Self-healing) và tự mở rộng với EC2 Auto Scaling Group. Cân bằng Tải: Phân phối traffic người dùng thông qua Application Load Balancer (ALB). Các công việc cần triển khai trong tuần này: Task ID Thứ Công việc Ngày bắt đầu Ngày hoàn thành Trạng thái Nguồn tài liệu T5.1 2 Lightsail - WordPress Deploy: - Khởi tạo Lightsail Instance với Blueprint \u0026ldquo;WordPress\u0026rdquo; - Gán Static IP 06/10/2025 06/10/2025 Hoàn thành https://cloudjourney.awsstudygroup.com/ T5.2 2 Container - Docker Intro: - Viết Dockerfile đơn giản cho trang web Hello World - Build và chạy thử trên Cloud9 06/10/2025 07/10/2025 Hoàn thành https://cloudjourney.awsstudygroup.com/ T5.3 3 Lightsail - Container Deploy: - Đẩy Docker Image lên Lightsail Container Service - Cấu hình Public Endpoint 07/10/2025 08/10/2025 Hoàn thành https://cloudjourney.awsstudygroup.com/ T5.4 4 EC2 - Launch Template: - Tạo Launch Template: Amazon Linux 2023, t3.micro - User Data script tự động cài Apache Web Server 08/10/2025 09/10/2025 Hoàn thành https://cloudjourney.awsstudygroup.com/ T5.5 4 Networking - Target Group: - Tạo Target Group rỗng - Sẵn sàng để ASG đăng ký instance vào 09/10/2025 10/10/2025 Hoàn thành https://cloudjourney.awsstudygroup.com/ T5.6 5 EC2 - Create ALB: - Khởi tạo Application Load Balancer internet-facing - Lắng nghe port 80, trỏ traffic về Target Group 09/10/2025 10/10/2025 Hoàn thành https://cloudjourney.awsstudygroup.com/ T5.7 5 EC2 - Auto Scaling Group: - Tạo ASG: Min=1, Desired=2, Max=4 - Sử dụng Launch Template - Tích hợp với ALB Target Group 09/10/2025 10/10/2025 Hoàn thành https://cloudjourney.awsstudygroup.com/ T5.8 6 Testing - Stress Test: - SSH vào instance, cài công cụ stress - Ép CPU 100% và quan sát ASG Scale Out 10/10/2025 12/10/2025 Hoàn thành https://cloudjourney.awsstudygroup.com/ Kết quả đạt được tuần 5: So sánh:\nLightsail cực kỳ nhanh để triển khai nhưng thiếu tính tùy biến sâu về mạng VPC Peering của Lightsail có hạn chế Phù hợp cho các dự án nhỏ, blog, prototype Hệ thống Đàn hồi:\nĐã xây dựng hệ thống Web có khả năng chịu lỗi (Fault Tolerant) Khi Terminate 1 instance thủ công, ASG lập tức khởi tạo instance mới thay thế Hệ thống tự động scale up/down theo nhu cầu Cân bằng tải:\nALB phân phối đều request giữa các instance Đảm bảo người dùng không bị gián đoạn dịch vụ khi một máy chủ chết Hiểu về Health Checks và Drain Connection Kiến trúc:\nNắm vững khái niệm Stateless Architecture Không được lưu file upload hay session trên ổ cứng EC2 Kết hợp S3 (file) và RDS (dữ liệu) cho hệ thống Cloud-Native User Data để Bootstrapping là kỹ thuật then chốt tự động hóa "},{"uri":"https://github.com/LeThiYenVi/AWS-Report.git/vi/5-workshop/","title":"Workshop","tags":[],"description":"","content":"Xây dựng EV Rental AI Agent với AWS Bedrock Tổng quan EV Rental AI Agent là một chatbot thông minh được xây dựng để hỗ trợ khách hàng trong hệ thống cho thuê xe điện VinFast. Workshop này hướng dẫn cách sử dụng AWS Bedrock, Claude 3.5 Sonnet, và Knowledge Bases để tạo một AI đàm thoại có thể:\nTrả lời câu hỏi tự nhiên bằng tiếng Việt Tự động tìm kiếm thông tin từ nhiều nguồn Hiển thị dữ liệu dưới dạng card tương tác trong giao diện chat Tra cứu xe khả dụng và trạm sạc Truy cập chính sách thuê xe và FAQ từ knowledge base Trong workshop này, bạn sẽ học cách:\nThiết lập AWS Bedrock - Kích hoạt các AI model và tạo Knowledge Base để truy xuất tài liệu Triển khai Backend API - Xây dựng FastAPI server với Strands Agent SDK cho việc chọn tool thông minh Triển khai Frontend - Tạo giao diện chat React với các component Chakra UI Kiểm thử hệ thống - Tương tác với AI agent và xác minh tất cả chức năng Nội dung Tổng quan Workshop Yêu cầu chuẩn bị Thiết lập AWS Bedrock Triển khai Backend API Triển khai Frontend Kiểm thử AI Agent Dọn dẹp tài nguyên "},{"uri":"https://github.com/LeThiYenVi/AWS-Report.git/vi/5-workshop/5.6-cleanup/","title":"Dọn dẹp tài nguyên","tags":[],"description":"","content":"Dọn dẹp tài nguyên Xin chúc mừng bạn đã hoàn thành xong lab này! Trong lab này, bạn đã học về các mô hình kiến trúc để truy cập Amazon S3 mà không sử dụng Public Internet.\nBằng cách tạo Gateway endpoint, bạn đã cho phép giao tiếp trực tiếp giữa các tài nguyên EC2 và Amazon S3, mà không đi qua Internet Gateway. Bằng cách tạo Interface endpoint, bạn đã mở rộng kết nối S3 đến các tài nguyên chạy trên trung tâm dữ liệu trên chỗ của bạn thông qua AWS Site-to-Site VPN hoặc Direct Connect. Dọn dẹp Điều hướng đến Hosted Zones trên phía trái của bảng điều khiển Route 53. Nhấp vào tên của s3.us-east-1.amazonaws.com zone. Nhấp vào Delete và xác nhận việc xóa bằng cách nhập từ khóa \u0026ldquo;delete\u0026rdquo;. Disassociate Route 53 Resolver Rule - myS3Rule from \u0026ldquo;VPC Onprem\u0026rdquo; and Delete it. 4.Mở console của CloudFormation và xóa hai stack CloudFormation mà bạn đã tạo cho bài thực hành này:\nPLOnpremSetup PLCloudSetup Xóa các S3 bucket Mở bảng điều khiển S3 Chọn bucket chúng ta đã tạo cho lab, nhấp chuột và xác nhận là empty. Nhấp Delete và xác nhận delete. "},{"uri":"https://github.com/LeThiYenVi/AWS-Report.git/vi/5-workshop/5.6-testing/","title":"Kiểm thử Hệ thống","tags":[],"description":"","content":"Kiểm thử EV Rental AI Agent Trong phần này, bạn sẽ kiểm thử cả ba tính năng cốt lõi của AI Agent để đảm bảo mọi thứ hoạt động chính xác.\nĐiều kiện Trước khi Kiểm thử Trước khi kiểm thử, đảm bảo:\n✅ Backend server đang chạy tại http://localhost:8000 ✅ Frontend application đang chạy tại http://localhost:3000 ✅ Cơ sở dữ liệu PostgreSQL đang chạy và có dữ liệu test ✅ AWS Bedrock Knowledge Base đã được đồng bộ và sẵn sàng Kịch bản Kiểm thử 1: Tìm kiếm Knowledge Base AI Agent phải có khả năng trả lời câu hỏi về chính sách thuê xe, giá cả và FAQ sử dụng Knowledge Base.\nCâu hỏi Kiểm thử:\nChính sách Thuê xe:\nUser: \u0026#34;Chính sách thuê xe là gì?\u0026#34; Kết quả mong đợi: Agent trả về chi tiết chính sách từ Knowledge Base Giấy tờ Yêu cầu:\nUser: \u0026#34;Tôi cần giấy tờ gì để thuê xe?\u0026#34; Kết quả mong đợi: Agent liệt kê giấy tờ cần thiết (CMND, bằng lái, tiền cọc) Thông tin Giá cả:\nUser: \u0026#34;Giá thuê xe VinFast VF8 là bao nhiêu?\u0026#34; Kết quả mong đợi: Agent cung cấp chi tiết giá từ Knowledge Base Quy trình Đặt xe:\nUser: \u0026#34;Làm thế nào để đặt xe?\u0026#34; Kết quả mong đợi: Agent giải thích quy trình đặt xe từng bước Xác minh:\n✅ Phản hồi bao gồm trích dẫn từ Knowledge Base ✅ Câu trả lời liên quan và chính xác ✅ Định dạng Markdown hiển thị đúng ✅ Thời gian phản hồi dưới 5 giây Kịch bản Kiểm thử 2: Tìm kiếm Xe AI Agent phải tìm kiếm cơ sở dữ liệu PostgreSQL để tìm xe có sẵn theo địa điểm và ngày tháng.\nCâu hỏi Kiểm thử:\nTìm theo Địa điểm:\nUser: \u0026#34;Tìm xe ở Hà Nội\u0026#34; Kết quả mong đợi: Agent liệt kê xe có sẵn ở Hà Nội Tìm theo Model:\nUser: \u0026#34;Có xe VinFast VF8 nào available không?\u0026#34; Kết quả mong đợi: Agent hiển thị xe VF8 với trạng thái sẵn có Tìm theo Khoảng Ngày:\nUser: \u0026#34;Tìm xe VF9 ở Hồ Chí Minh từ ngày 20/12 đến 25/12\u0026#34; Kết quả mong đợi: Agent tìm xe sẵn có trong khoảng ngày đó Tìm theo Khoảng Giá:\nUser: \u0026#34;Xe nào dưới 1 triệu đồng/ngày?\u0026#34; Kết quả mong đợi: Agent lọc xe theo giá Xác minh:\n✅ Agent trích xuất đúng tham số tìm kiếm (địa điểm, model, ngày) ✅ Kết quả bao gồm chi tiết xe (model, giá, địa điểm, trạng thái) ✅ Dữ liệu được lấy từ cơ sở dữ liệu PostgreSQL ✅ Kết quả được định dạng thành bảng hoặc danh sách dễ đọc Định dạng Phản hồi Mong đợi:\n## 🚗 Xe Có Sẵn | Model | Địa điểm | Giá/Ngày | Trạng thái | |-------|----------|----------|------------| | VinFast VF8 | Hà Nội | 800,000đ | Có sẵn | | VinFast VF9 | Hà Nội | 1,200,000đ | Có sẵn | Kịch bản Kiểm thử 3: Tìm Trạm Sạc AI Agent phải tìm trạm sạc gần đó với thông tin sẵn có theo thời gian thực.\nCâu hỏi Kiểm thử:\nTìm theo Quận:\nUser: \u0026#34;Trạm sạc gần Quận Hoàn Kiếm\u0026#34; Kết quả mong đợi: Agent liệt kê trạm sạc ở quận Hoàn Kiếm Tìm theo Địa chỉ:\nUser: \u0026#34;Tìm trạm sạc ở Quận 1, TP.HCM\u0026#34; Kết quả mong đợi: Agent tìm trạm ở Quận 1, TP.HCM Kiểm tra Trạng thái Trạm:\nUser: \u0026#34;Trạm sạc nào còn trống?\u0026#34; Kết quả mong đợi: Agent hiển thị trạm có cổng sạc còn trống Lọc theo Loại Connector:\nUser: \u0026#34;Trạm sạc có CCS2 connector\u0026#34; Kết quả mong đợi: Agent lọc trạm có connector CCS2 Xác minh:\n✅ Agent nhận diện đúng địa điểm từ câu hỏi ✅ Kết quả bao gồm tên trạm, địa chỉ và trạng thái ✅ Các loại connector được liệt kê ✅ Trạng thái sẵn có theo thời gian thực được hiển thị Định dạng Phản hồi Mong đợi:\n## ⚡ Trạm Sạc Gần Bạn ### VinFast Station - Hoàn Kiếm 📍 Địa chỉ: 123 Trần Hưng Đạo, Hoàn Kiếm, Hà Nội 🔌 Connectors: CCS2 (2 sẵn có), CHAdeMO (1 sẵn có) ⏰ Giờ mở cửa: 24/7 ✅ Trạng thái: Có sẵn Kịch bản Kiểm thử 4: Cuộc hội thoại Nhiều lượt Kiểm tra khả năng duy trì ngữ cảnh của agent qua nhiều lượt hội thoại.\nCuộc hội thoại Kiểm thử:\nUser: \u0026#34;Tôi muốn thuê xe VF8\u0026#34; Agent: [Cung cấp thông tin VF8] User: \u0026#34;Giá bao nhiêu?\u0026#34; Agent: [Phải hiểu ngữ cảnh đang nói về giá VF8] User: \u0026#34;Trạm sạc gần đó ở đâu?\u0026#34; Agent: [Phải tìm trạm sạc gần vị trí VF8] Xác minh:\n✅ Agent duy trì ngữ cảnh cuộc hội thoại ✅ Đại từ và tham chiếu được hiểu đúng ✅ Session ID được giữ xuyên suốt các tin nhắn Kịch bản Kiểm thử 5: Xử lý Lỗi Kiểm tra cách agent xử lý các câu hỏi không hợp lệ hoặc không rõ ràng.\nCác Trường hợp Kiểm thử:\nCâu hỏi Mơ hồ:\nUser: \u0026#34;Xe\u0026#34; Kết quả mong đợi: Agent yêu cầu làm rõ Xe Không Có Sẵn:\nUser: \u0026#34;Tìm xe Tesla\u0026#34; Kết quả mong đợi: Agent giải thích Tesla không có, đề xuất thay thế Ngày Không hợp lệ:\nUser: \u0026#34;Thuê xe từ ngày 32/13\u0026#34; Kết quả mong đợi: Agent phát hiện ngày không hợp lệ và yêu cầu sửa Ngoài Phạm vi:\nUser: \u0026#34;Thời tiết hôm nay thế nào?\u0026#34; Kết quả mong đợi: Agent giải thích lịch sự chỉ có thể hỗ trợ về thuê xe EV Xác minh:\n✅ Agent xử lý lỗi một cách mượt mà ✅ Cung cấp thông báo lỗi hữu ích ✅ Đề xuất các phương án thay thế khi có thể Kiểm thử Hiệu năng Kiểm tra hiệu năng hệ thống trong điều kiện sử dụng bình thường:\nCác Chỉ số Cần Theo dõi:\nThời gian Phản hồi:\nTruy vấn Knowledge Base: \u0026lt; 3 giây Tìm kiếm xe: \u0026lt; 2 giây Tìm trạm sạc: \u0026lt; 2 giây Tình trạng API:\ncurl http://localhost:8000/health Kết quả mong đợi: 200 OK với trạng thái healthy\nLog Backend: Kiểm tra lỗi trong console output của FastAPI\nConsole Frontend: Mở browser DevTools → Console\nKhông có lỗi JavaScript Các API call thành công (tab Network) Danh sách Kiểm tra Tích hợp Thực hiện danh sách kiểm tra toàn diện này:\n✅ Tích hợp Knowledge Base:\nAgent có thể truy xuất thông tin chính sách Trích dẫn được bao gồm trong phản hồi Các API call Bedrock thành công ✅ Tích hợp Cơ sở dữ liệu:\nTìm kiếm xe truy vấn PostgreSQL Kết quả chính xác và cập nhật Kết nối cơ sở dữ liệu ổn định ✅ Backend API:\nEndpoint /api/chat hoạt động Endpoint /health phản hồi Quản lý session hoạt động đúng ✅ Frontend UI:\nTin nhắn hiển thị chính xác Nhập liệu người dùng được thu thập Trạng thái loading hoạt động Markdown render đúng Auto-scroll hoạt động ✅ Xử lý Lỗi:\nLỗi mạng được bắt Đầu vào không hợp lệ được xử lý mượt mà Người dùng nhận được phản hồi hữu ích Kiểm thử với Postman (Tùy chọn) Kiểm thử backend API trực tiếp:\n1. Kiểm tra Health:\nGET http://localhost:8000/health 2. Yêu cầu Chat:\nPOST http://localhost:8000/api/chat Content-Type: application/json { \u0026#34;session_id\u0026#34;: \u0026#34;test-session-123\u0026#34;, \u0026#34;message\u0026#34;: \u0026#34;Chính sách thuê xe là gì?\u0026#34; } Phản hồi Mong đợi:\n{ \u0026#34;response\u0026#34;: \u0026#34;## 📋 Chính sách thuê xe VinFast\\n\\n...\u0026#34;, \u0026#34;data\u0026#34;: null, \u0026#34;session_id\u0026#34;: \u0026#34;test-session-123\u0026#34; } Xử lý Sự cố Kiểm thử Thất bại Vấn đề: Knowledge Base trả về kết quả rỗng\nKiểm tra Knowledge Base đã được đồng bộ trong AWS Console Xác minh KNOWLEDGE_BASE_ID trong .env Test KB trực tiếp trong Bedrock console Vấn đề: Tìm kiếm xe không trả về kết quả\nKiểm tra cơ sở dữ liệu PostgreSQL có dữ liệu test Xác minh chuỗi kết nối DATABASE_URL Chạy truy vấn SQL trực tiếp: SELECT * FROM vehicles; Vấn đề: Không tìm thấy trạm sạc\nXác minh endpoint /stations của backend API hoạt động Kiểm tra dữ liệu trạm trong database Test API call: curl http://localhost:8080/stations Vấn đề: Frontend không kết nối được backend\nKiểm tra REACT_APP_API_URL trong frontend .env Xác minh backend CORS cho phép http://localhost:3000 Kiểm tra console trình duyệt có lỗi network Mẫu Báo cáo Kiểm thử Ghi lại kết quả kiểm thử của bạn:\n## Báo cáo Kiểm thử - EV Rental AI Agent **Ngày:** 2024-12-20 **Người kiểm thử:** Tên của bạn ### Tóm tắt Kết quả - Tổng số Test: 15 - Đạt: 14 - Thất bại: 1 - Tỷ lệ Thành công: 93% ### Kết quả Chi tiết #### Tìm kiếm Knowledge Base - [x] Truy vấn chính sách - ĐẠT - [x] Giấy tờ yêu cầu - ĐẠT - [x] Thông tin giá - ĐẠT - [ ] Quy trình đặt xe - THẤT BẠI (phản hồi chậm) #### Tìm kiếm Xe - [x] Tìm theo địa điểm - ĐẠT - [x] Tìm theo model - ĐẠT - [x] Tìm theo khoảng ngày - ĐẠT #### Tìm Trạm Sạc - [x] Tìm theo quận - ĐẠT - [x] Kiểm tra sẵn có - ĐẠT ### Vấn đề Phát hiện 1. Truy vấn quy trình đặt xe mất 7 giây (\u0026gt; ngưỡng 5s) - Nguyên nhân: Knowledge Base đồng bộ chưa hoàn tất - Sửa: Đồng bộ lại data source ### Khuyến nghị - Theo dõi thời gian phản hồi trong lúc sử dụng cao điểm - Thêm caching cho các câu hỏi thường gặp - Triển khai rate limiting Thành công! 🎉 EV Rental AI Agent của bạn đã được kiểm thử đầy đủ và hoạt động.\nTiếp theo: Chuyển sang Cleanup để xóa tài nguyên và tránh chi phí.\n"},{"uri":"https://github.com/LeThiYenVi/AWS-Report.git/vi/6-self-evaluation/","title":"Tự đánh giá","tags":[],"description":"","content":"Trong suốt thời gian thực tập tại CÔNG TY TNHH AMAZON WEB SERVICES VIỆT NAM từ 08/09 đến [ngày kết thúc], tôi đã có cơ hội học hỏi, rèn luyện và áp dụng kiến thức đã được trang bị tại trường vào môi trường làm việc thực tế.\nTôi đã tham gia vào dự án VoltGo - Hệ thống cho thuê xe điện tại điểm cố định (EV Station-based Rental System) với vai trò Frontend (FE).Đây là giải pháp di chuyển xanh cho đô thị thông minh, nhằm cung cấp một nền tảng \u0026ldquo;tất cả trong một\u0026rdquo; trên đám mây để hợp nhất việc tìm kiếm, đặt xe theo thời gian thực và thanh toán, giải quyết tình trạng phân mảnh dịch vụ hiện nay.\nThông qua quá trình tham gia phát triển dự án, tôi đã tích lũy và mở rộng đáng kể bộ kỹ năng chuyên môn, bao gồm:\nPhát triển Frontend và Ứng dụng: Tôi đã thành thạo việc xây dựng ứng dụng di động đa nền tảng sử dụng React Native và phát triển giao diện Web Dashboard quản trị bằng Next.js. Đồng thời, tôi cũng có kinh nghiệm thực tế trong việc triển khai và lưu trữ giao diện web thông qua AWS Amplify.\nAm hiểu Kiến trúc Cloud \u0026amp; Backend: Mặc dù tập trung vào Frontend, tôi đã nắm bắt được quy trình vận hành của hệ thống Backend Spring Boot và cách tích hợp với hệ sinh thái toàn diện của AWS. Tôi đã tiếp cận và hiểu rõ vai trò của các dịch vụ cốt lõi trong dự án, bao gồm:\nTính toán \u0026amp; Container: Amazon ECS Fargate vận hành backend và AWS Lambda cho xử lý serverless.\nLưu trữ \u0026amp; Cơ sở dữ liệu: Amazon S3 (Data Lake) , Amazon RDS PostgreSQL (lưu trữ quan hệ) , và Amazon ElastiCache for Redis (bộ nhớ đệm).\nKết nối \u0026amp; IoT: AWS IoT Core (nhận dữ liệu cảm biến) , Amazon API Gateway (quản lý API) , và Amazon Cognito (xác thực người dùng bảo mật).\nXử lý dữ liệu \u0026amp; Phân phối: AWS Glue (ETL và Crawlers) và Amazon CloudFront (mạng phân phối nội dung toàn cầu).\nCông cụ hỗ trợ: Sử dụng AWS CDK/SDK trong quá trình phát triển và triển khai hạ tầng.\nTrong công việc, tôi luôn đề cao tinh thần trách nhiệm, nỗ lực hoàn thành mọi chỉ tiêu được giao và tuân thủ các quy định của tổ chức. Bên cạnh đó, tôi chủ động phối hợp chặt chẽ với các cộng sự để đảm bảo quy trình làm việc diễn ra suôn sẻ và đạt hiệu suất tối ưu.\nĐể phản ánh một cách khách quan quá trình thực tập, tôi xin tự đánh giá bản thân dựa trên các tiêu chí dưới đây:\nSTT Tiêu chí Mô tả Tốt Khá Trung bình 1 Kiến thức và kỹ năng chuyên môn Hiểu biết về ngành, áp dụng kiến thức vào thực tế, kỹ năng sử dụng công cụ, chất lượng công việc ☐ ✅ ☐ 2 Khả năng học hỏi Tiếp thu kiến thức mới, học hỏi nhanh ☐ ✅ ☐ 3 Chủ động Tự tìm hiểu, nhận nhiệm vụ mà không chờ chỉ dẫn ✅ ☐ ☐ 4 Tinh thần trách nhiệm Hoàn thành công việc đúng hạn, đảm bảo chất lượng ✅ ☐ ☐ 5 Kỷ luật Tuân thủ giờ giấc, nội quy, quy trình làm việc ☐ ✅ ☐ 6 Tính cầu tiến Sẵn sàng nhận feedback và cải thiện bản thân ✅ ☐ ☐ 7 Giao tiếp Trình bày ý tưởng, báo cáo công việc rõ ràng ✅ ☐ ☐ 8 Hợp tác nhóm Làm việc hiệu quả với đồng nghiệp, tham gia nhóm ✅ ☐ ☐ 9 Ứng xử chuyên nghiệp Tôn trọng đồng nghiệp, đối tác, môi trường làm việc ✅ ☐ ☐ 10 Tư duy giải quyết vấn đề Nhận diện vấn đề, đề xuất giải pháp, sáng tạo ☐ ✅ ☐ 11 Đóng góp vào dự án/tổ chức Hiệu quả công việc, sáng kiến cải tiến, ghi nhận từ team ✅ ☐ ☐ 12 Tổng thể Đánh giá chung về toàn bộ quá trình thực tập ✅ ☐ ☐ Cần cải thiện Qua quá trình làm việc tại Amazon Web Services Việt Nam, tôi nhận thấy mình còn tồn tại một số hạn chế cần khắc phục:\nVề tính kỷ luật:\nThực trạng: Đôi lúc chưa thực sự nghiêm khắc với bản thân trong việc tuân thủ tuyệt đối quy trình hành chính hoặc giờ giấc.\nKế hoạch: Tôi sẽ rèn luyện thói quen quản lý thời gian chặt chẽ hơn, cam kết chấp hành nghiêm chỉnh nội quy của công ty cũng như bất kỳ tổ chức nào tôi tham gia sau này.\nVề tư duy giải quyết vấn đề:\nThực trạng: Khi gặp các vấn đề kỹ thuật phức tạp trong dự án (ví dụ: xử lý dữ liệu thời gian thực hay tích hợp AWS), tôi đôi khi còn lúng túng và chưa có phương án xử lý tối ưu ngay lập tức.\nKế hoạch: Tôi sẽ tập thói quen phân tích nguyên nhân gốc rễ, tìm hiểu kỹ tài liệu kỹ thuật (AWS Well-Architected Framework) để đề xuất giải pháp có tính hệ thống hơn.\nVề kỹ năng giao tiếp:\nThực trạng: Việc diễn đạt ý tưởng chuyên môn hoặc báo cáo tiến độ hàng ngày đôi khi chưa gãy gọn.\nKế hoạch: Tôi sẽ học cách trình bày vấn đề ngắn gọn, súc tích hơn và tích cực tham gia thảo luận nhóm để rèn luyện khả năng xử lý tình huống trong công việc.\n"},{"uri":"https://github.com/LeThiYenVi/AWS-Report.git/vi/1-worklog/1.6-week6/","title":"Worklog Tuần 6","tags":[],"description":"","content":"Mục tiêu tuần 6: Khả năng Quan sát (Observability): Xây dựng Dashboard tập trung để theo dõi sức khỏe hệ thống. Cảnh báo Chủ động: Thiết lập hệ thống cảnh báo qua Email/SMS khi tài nguyên gặp sự cố. Tự động hóa: Viết hàm Lambda (Python/Node.js) để tương tác với tài nguyên AWS. Lập lịch: Sử dụng Amazon EventBridge để kích hoạt Lambda theo lịch trình (Cron job). Các công việc cần triển khai trong tuần này: Task ID Thứ Công việc Ngày bắt đầu Ngày hoàn thành Trạng thái Nguồn tài liệu T6.1 2 CloudWatch - Dashboard: - Tạo Dashboard hiển thị CPU Utilization của ASG - Hiển thị Freeable Memory của RDS 13/10/2025 13/10/2025 Hoàn thành https://cloudjourney.awsstudygroup.com/ T6.2 2 SNS - Setup Topic: - Tạo SNS Topic DevOps-Alerts - Đăng ký email cá nhân và xác nhận 13/10/2025 14/10/2025 Hoàn thành https://cloudjourney.awsstudygroup.com/ T6.3 3 CloudWatch - Create Alarm: - Tạo Alarm: CPU \u0026gt; 70% trong 2 chu kỳ liên tiếp - Kích hoạt SNS Topic gửi email 14/10/2025 14/10/2025 Hoàn thành https://cloudjourney.awsstudygroup.com/ T6.4 4 Lambda - IAM Role: - Tạo IAM Role cho Lambda - Quyền: AmazonEC2FullAccess (lưu ý: nên giới hạn Start/Stop) 15/10/2025 15/10/2025 Hoàn thành https://cloudjourney.awsstudygroup.com/ T6.5 4 Lambda - Coding: - Viết hàm Python (boto3) - Liệt kê instances đang chạy và thực hiện stop_instances 15/10/2025 16/10/2025 Hoàn thành https://cloudjourney.awsstudygroup.com/ T6.6 5 EventBridge - Scheduler: - Tạo Rule \u0026ldquo;Cost-Saver\u0026rdquo; - Cron: 0 18 * * ? * (6:00 PM mỗi ngày) - Kích hoạt Lambda 16/10/2025 16/10/2025 Hoàn thành https://cloudjourney.awsstudygroup.com/ T6.7 6 Testing \u0026amp; Review: - Kiểm tra Lambda function hoạt động đúng theo lịch - Review CloudWatch Logs của Lambda - Tổng hợp báo cáo monitoring tuần này 17/10/2025 17/10/2025 Hoàn thành https://cloudjourney.awsstudygroup.com/ Kết quả đạt được tuần 6: Tầm nhìn:\nCó cái nhìn thời gian thực về hiệu năng hệ thống Không còn phải SSH vào từng máy để gõ lệnh top Dashboard tập trung cho toàn bộ tài nguyên Phản ứng:\nNhận email cảnh báo ngay lập tức khi CPU cao Đã test lại với Stress Test từ Tuần 5 Hệ thống cảnh báo hoạt động tốt FinOps:\nTự động tắt môi trường Development vào cuối ngày Tiết kiệm khoảng 65% chi phí EC2 (8h thay vì 24h) Lambda chạy với chi phí gần như $0 Kỹ năng:\nViết Lambda function với Python và boto3 Hiểu về Event-Driven Architecture Cấu hình EventBridge (CloudWatch Events) Tích hợp SNS cho notification system "},{"uri":"https://github.com/LeThiYenVi/AWS-Report.git/vi/7-feedback/","title":"Chia sẻ, đóng góp ý kiến","tags":[],"description":"","content":" Tại đây bạn có thể tự do đóng góp ý kiến cá nhân về những trải nghiệm khi tham gia chương trình First Cloud Journey, giúp team FCJ cải thiện những vấn đề còn thiếu sót dựa trên các hạng mục sau:\nĐánh giá chung 1. Môi trường làm việc\nMôi trường tại FCJ rất chuyên nghiệp, năng động và đậm chất công nghệ. Điều tôi ấn tượng nhất là văn hóa \u0026ldquo;Open communication\u0026rdquo; (Giao tiếp mở) – nơi mọi ý kiến đều được lắng nghe. Không gian làm việc kích thích sự sáng tạo, đặc biệt là hạ tầng và tài nguyên Cloud luôn sẵn sàng để thực tập sinh trải nghiệm. Tuy nhiên, đôi khi áp lực dự án cao khiến không khí hơi căng thẳng, tôi nghĩ việc có thêm các khoảng nghỉ ngắn (break-time activities) sẽ giúp mọi người tái tạo năng lượng tốt hơn.\n2. Sự hỗ trợ của mentor / team admin\nMentor hướng dẫn rất chi tiết, giải thích rõ ràng khi mình chưa hiểu và luôn khuyến khích mình đặt câu hỏi. Team admin hỗ trợ các thủ tục, tài liệu và tạo điều kiện để mình làm việc thuận lợi. Mình đánh giá cao việc mentor cho phép mình thử và tự xử lý vấn đề thay vì chỉ đưa đáp án.\n3. Sự phù hợp giữa công việc và chuyên ngành học\nChương trình giúp tôi mở rộng vùng an toàn, từ việc chỉ biết viết code giao diện sang việc hiểu cách frontend tương tác với hệ thống backend và hạ tầng đám mây. Đây là sự bổ trợ quý giá mà trường lớp ít có điều kiện đi sâu.\n4. Cơ hội học hỏi \u0026amp; phát triển kỹ năng\nNgoài kỹ năng cứng (React Native, AWS Services), tôi học được rất nhiều về quy trình phát triển phần mềm Agile/Scrum và cách quản lý source code chuyên nghiệp. Đặc biệt, thông qua các buổi review code và họp tiến độ, tôi nhận ra tầm quan trọng của kỹ năng giao tiếp và thuyết trình – những điểm mà tôi đang nỗ lực cải thiện từng ngày.\n5. Văn hóa \u0026amp; tinh thần đồng đội\nVăn hóa công ty rất tích cực: mọi người tôn trọng lẫn nhau, làm việc nghiêm túc nhưng vẫn vui vẻ. Tinh thần \u0026ldquo;Ownership\u0026rdquo; (Làm chủ công việc) được đề cao. Mọi thành viên đều hỗ trợ nhau hết mình. Dù tôi từng mắc lỗi do chưa tuân thủ quy trình, nhưng thay vì chỉ trích, mọi người đã cùng ngồi lại giúp tôi tìm giải pháp khắc phục. Điều này giúp tôi cảm thấy được bao dung và có động lực thay đổi tích cực hơn.\n6. Chính sách / phúc lợi cho thực tập sinh\nCác quyền lợi về hỗ trợ dấu mộc thực tập rất rõ ràng. Điểm cộng lớn nhất là tôi được cấp tài khoản AWS để thực hành thoải mái mà không lo về chi phí phát sinh – một phúc lợi cực kỳ thiết thực cho dân kỹ thuật. Ngoài ra, việc được tham gia các buổi đào tạo nội bộ là một điểm cộng lớn.\nMột số câu hỏi khác Điều bạn hài lòng nhất trong thời gian thực tập?\nĐó là cơ hội được \u0026ldquo;làm thật\u0026rdquo;. Tôi được trực tiếp tham gia xây dựng một sản phẩm phức tạp và thấy code của mình chạy thực tế trên thiết bị, chứ không chỉ dừng lại ở mức độ bài tập mô phỏng. Điều bạn nghĩ công ty cần cải thiện cho các thực tập sinh sau?\nTôi nghĩ công ty nên tổ chức thêm các buổi workshop kỹ năng mềm chuyên sâu hơn ngay từ đầu kỳ, đặc biệt là về Quản lý thời gian và Kỷ luật trong công việc. Đối với các bạn sinh viên mới như tôi, việc chuyển đổi từ môi trường học tập sang môi trường làm việc chuyên nghiệp đôi khi còn bị \u0026ldquo;sốc\u0026rdquo; văn hóa về mặt giờ giấc và quy trình. Nếu giới thiệu cho bạn bè, bạn có khuyên họ thực tập ở đây không? Vì sao?\nChắc chắn là có. Đây là môi trường lý tưởng để \u0026ldquo;ép\u0026rdquo; bản thân trưởng thành. Bạn sẽ không chỉ học được công nghệ tiên tiến nhất (Cloud, IoT) mà còn được rèn giũa thái độ làm việc nghiêm túc của một kỹ sư phần mềm thực thụ. Đề xuất \u0026amp; mong muốn Bạn có đề xuất gì để cải thiện trải nghiệm trong kỳ thực tập?\nTôi đề xuất chương trình có thể thiết lập các mốc \u0026ldquo;Check-point\u0026rdquo; về kỷ luật và thái độ định kỳ 2 tuần/lần (thay vì chỉ đánh giá chuyên môn). Việc nhận feedback sớm về tác phong sẽ giúp thực tập sinh điều chỉnh hành vi kịp thời, tránh mắc sai sót về quy trình vào cuối kỳ. Bạn có muốn tiếp tục chương trình này trong tương lai?\nTôi rất mong muốn có cơ hội tiếp tục đồng hành cùng FCJ hoặc AWS ở các vị trí cao hơn (như Fresher hoặc Junior) sau khi đã khắc phục được các điểm yếu hiện tại của bản thân. Góp ý khác (tự do chia sẻ):\nCảm ơn FCJ đã cho tôi một hành trình đáng nhớ. Dù bản thân tôi còn nhiều thiếu sót cần hoàn thiện, nhưng sự kiên nhẫn của Mentor và Team đã là động lực lớn nhất để tôi cố gắng đến cùng. "},{"uri":"https://github.com/LeThiYenVi/AWS-Report.git/vi/5-workshop/5.7-cleanup/","title":"Dọn dẹp Tài nguyên","tags":[],"description":"","content":"Dọn dẹp Tài nguyên Sau khi hoàn thành workshop, hãy làm theo các bước sau để dọn dẹp tất cả tài nguyên và tránh phí AWS không cần thiết.\nTại sao Dọn dẹp là Quan trọng Tiết kiệm Chi phí: AWS tính phí cho các tài nguyên đang hoạt động như Bedrock Knowledge Bases, S3 storage và các dịch vụ đang chạy Bảo mật: Xóa các credentials IAM không sử dụng để duy trì best practices về bảo mật Tổ chức: Giữ tài khoản AWS của bạn sạch sẽ và có tổ chức Bước 1: Xóa AWS Bedrock Knowledge Base 1.1 Xóa Knowledge Base Mở AWS Bedrock Console Điều hướng đến Knowledge Bases ở thanh bên trái Chọn Knowledge Base của bạn: ev-rental-knowledge-base Click Delete Xác nhận xóa bằng cách nhập tên Knowledge Base Click Delete để xác nhận ⚠️ Lưu ý: Điều này cũng sẽ xóa các kết nối data source liên quan.\n1.2 Xóa S3 Bucket và Documents Mở S3 Console Tìm bucket của bạn: ev-rental-knowledge-docs Chọn bucket Click Empty để xóa tất cả objects Xác nhận bằng cách nhập \u0026ldquo;permanently delete\u0026rdquo; Sau khi làm trống, click Delete trên bucket Xác nhận bằng cách nhập tên bucket Hoặc dùng AWS CLI:\n# Xóa tất cả objects trong bucket aws s3 rm s3://ev-rental-knowledge-docs --recursive # Xóa bucket aws s3 rb s3://ev-rental-knowledge-docs Bước 2: Xóa IAM User và Access Keys 2.1 Xóa Access Keys Mở IAM Console Điều hướng đến Users Chọn user của bạn (ví dụ: bedrock-agent-user) Click vào tab Security credentials Dưới Access keys, tìm access key của bạn Click Delete bên cạnh access key Xác nhận xóa 2.2 Xóa IAM User (Tùy chọn) Nếu bạn đã tạo IAM user riêng cho workshop này:\nTrong IAM Console, chọn user Click Delete user Xác nhận bằng cách check vào ô Click Delete Hoặc dùng AWS CLI:\n# Liệt kê access keys aws iam list-access-keys --user-name bedrock-agent-user # Xóa access key (thay bằng key ID của bạn) aws iam delete-access-key --user-name bedrock-agent-user --access-key-id AKIA5GPEMGJZK6E7PMEB # Xóa user aws iam delete-user --user-name bedrock-agent-user Bước 3: Dừng Các Dịch vụ Local 3.1 Dừng FastAPI Backend Trong terminal nơi FastAPI đang chạy:\nNhấn Ctrl + C để dừng server\nDeactivate virtual environment:\ndeactivate Tùy chọn xóa thư mục dự án:\n# Trên macOS/Linux rm -rf ev-rental-backend # Trên Windows rmdir /s ev-rental-backend 3.2 Dừng React Frontend Trong terminal nơi React đang chạy:\nNhấn Ctrl + C để dừng development server\nTùy chọn xóa thư mục dự án:\n# Trên macOS/Linux rm -rf ev-rental-frontend # Trên Windows rmdir /s ev-rental-frontend 3.3 Dừng PostgreSQL Database Nếu bạn đã cài PostgreSQL local cho workshop này:\nTrên macOS:\n# Dừng PostgreSQL service brew services stop postgresql@14 Trên Linux:\nsudo systemctl stop postgresql Trên Windows:\n# Mở Services (services.msc) # Tìm service \u0026#34;PostgreSQL\u0026#34; # Right-click → Stop 3.4 Xóa Database (Tùy chọn) Nếu bạn muốn xóa hoàn toàn database:\n# Kết nối PostgreSQL psql -U postgres # Xóa database DROP DATABASE ev_rental_db; # Thoát \\q Bước 4: Xóa Các File Environment Xóa các file .env nhạy cảm chứa credentials:\nBackend:\ncd ev-rental-backend rm .env Frontend:\ncd ev-rental-frontend rm .env ⚠️ Lưu ý Bảo mật: Không bao giờ commit file .env vào Git. Luôn thêm chúng vào .gitignore.\nBước 5: Xác minh Dọn dẹp 5.1 Kiểm tra Tài nguyên AWS Xác minh tất cả tài nguyên đã được xóa:\nBedrock Console:\nKhông có Knowledge Bases nào được liệt kê Không có model invocations đang hoạt động S3 Console:\nBucket ev-rental-knowledge-docs đã bị xóa IAM Console:\nAccess keys đã bị xóa IAM user đã bị xóa (nếu bạn chọn xóa) 5.2 Kiểm tra Chi phí AWS Mở AWS Billing Console Kiểm tra Bills cho tháng hiện tại Xác minh các khoản phí: Phí Bedrock sẽ dừng sau khi xóa Knowledge Base Phí S3 storage sẽ dừng sau khi xóa bucket Không có phí compute đang chạy Hoặc dùng AWS CLI:\naws ce get-cost-and-usage \\ --time-period Start=2024-12-01,End=2024-12-31 \\ --granularity MONTHLY \\ --metrics UnblendedCost \\ --group-by Type=SERVICE Chi tiết Chi phí Đây là những gì bạn có thể đã bị tính phí trong workshop:\nDịch vụ Chi phí Ước tính Ghi chú AWS Bedrock - Claude 3.5 Sonnet ~$0.50 - $2.00 Phụ thuộc số lượng truy vấn AWS Bedrock - Knowledge Base ~$0.10 - $0.50 Vector storage và retrieval S3 Storage ~$0.02 Tối thiểu cho documents nhỏ Data Transfer ~$0.05 Thường trong free tier Tổng ~$0.67 - $2.57 Ước tính cho workshop ⚠️ Lưu ý: Hầu hết chi phí đến từ các API calls Bedrock. Càng test lâu, chi phí càng cao.\nDanh sách Kiểm tra Dọn dẹp Trước khi kết thúc, xác minh tất cả mục đã hoàn thành:\nTài nguyên AWS ✅ Bedrock Knowledge Base đã xóa ✅ S3 bucket đã làm trống và xóa ✅ IAM Access Keys đã xóa ✅ IAM User đã xóa (tùy chọn) Tài nguyên Local ✅ FastAPI backend đã dừng ✅ React frontend đã dừng ✅ PostgreSQL database đã dừng ✅ PostgreSQL database đã xóa (tùy chọn) File Nhạy cảm ✅ File .env backend đã xóa ✅ File .env frontend đã xóa ✅ Không có AWS credentials trong các file dự án Xác minh ✅ AWS Console không hiển thị tài nguyên đang hoạt động ✅ Billing dashboard hiển thị phí đã dừng ✅ Các dịch vụ local không chạy Xử lý Sự cố Dọn dẹp Vấn đề: Không thể xóa S3 bucket - \u0026ldquo;Bucket not empty\u0026rdquo;\nGiải pháp: Làm trống tất cả objects trước bằng S3 Console hoặc CLI Lệnh: aws s3 rm s3://bucket-name --recursive Vấn đề: Không thể xóa Knowledge Base - \u0026ldquo;In use\u0026rdquo;\nGiải pháp: Đợi vài phút để các thao tác đang chờ hoàn thành Kiểm tra xem có API calls nào vẫn đang tham chiếu đến nó Vấn đề: Xóa IAM User thất bại - \u0026ldquo;User has attached policies\u0026rdquo;\nGiải pháp: Detach tất cả policies trước Vào IAM → Users → Chọn user → Permissions → Detach policies Vấn đề: PostgreSQL không dừng\nGiải pháp: Force kill process Trên macOS/Linux: sudo killall postgres Trên Windows: Dùng Task Manager để end các processes PostgreSQL Tùy chọn: Tiếp tục Học Nếu bạn muốn tiếp tục thử nghiệm:\nGiữ lại Các Tài nguyên: ✅ IAM User (với permissions tối thiểu) ✅ Bedrock model access (không tính phí khi không sử dụng) Những gì Bạn Có thể Làm Tiếp: Thêm nhiều documents vào Knowledge Base Triển khai thêm agent tools Deploy lên AWS Lambda cho serverless operation Thêm authentication và user management Tích hợp với hệ thống đặt xe thực Kết luận 🎉 Chúc mừng! Bạn đã thành công:\n✅ Xây dựng AI Agent sử dụng AWS Bedrock và Claude 3.5 Sonnet ✅ Tích hợp Knowledge Bases cho việc truy xuất tài liệu thông minh ✅ Tạo FastAPI backend với Strands Agent SDK ✅ Phát triển React frontend cho tương tác người dùng ✅ Kiểm thử tất cả tính năng end-to-end ✅ Dọn dẹp tài nguyên để tránh phí Những Điều Chính: AI Agents có thể tự động chọn tools và đưa ra quyết định AWS Bedrock đơn giản hóa truy cập đến các foundation models như Claude Knowledge Bases cho phép semantic search trên documents Strands SDK cung cấp framework cho xây dựng agent workflows FastAPI + React tạo ứng dụng AI full-stack hiện đại Các Bước Tiếp theo: Khám phá các Bedrock models khác (Llama 3, Mistral, v.v.) Học về RAG (Retrieval Augmented Generation) Xây dựng agent workflows phức tạp hơn Deploy lên production sử dụng các dịch vụ AWS "},{"uri":"https://github.com/LeThiYenVi/AWS-Report.git/vi/1-worklog/1.7-week7/","title":"Worklog Tuần 7","tags":[],"description":"","content":"Mục tiêu tuần 7: Bảo mật Truy cập: Loại bỏ nhu cầu sử dụng SSH Key và Port 22 bằng SSM Session Manager. Quản lý Tài nguyên: Tổ chức tài nguyên bằng Resource Groups và Tagging Strategy. Vận hành Quy mô lớn: Thực thi lệnh trên nhiều máy chủ đồng thời không cần đăng nhập từng máy. Vá lỗi: Tự động hóa quy trình cập nhật bản vá bảo mật. Các công việc cần triển khai trong tuần này: Task ID Thứ Công việc Ngày bắt đầu Ngày hoàn thành Trạng thái Nguồn tài liệu T7.1 2 Tagging - Tag Audit: - Rà soát và gắn tag chuẩn cho tất cả tài nguyên - Format: Env:Dev, Project:FCJ, Owner:Student 20/10/2025 20/10/2025 Hoàn thành https://cloudjourney.awsstudygroup.com/ T7.2 2 SSM - Role Update: - Cập nhật IAM Role của EC2 - Thêm policy AmazonSSMManagedInstanceCore 20/10/2025 21/10/2025 Hoàn thành https://cloudjourney.awsstudygroup.com/ T7.3 3 SSM - Session Manager: - Truy cập EC2 Instance qua Console - Sử dụng Session Manager thay vì SSH 21/10/2025 22/10/2025 Hoàn thành https://cloudjourney.awsstudygroup.com/ T7.4 4 Security - Hardening: - Xóa Rule Port 22 trong Security Group Web-SG - Kiểm tra truy cập qua SSM (thành công) - Kiểm tra qua SSH (thất bại như mong đợi) 22/10/2025 23/10/2025 Hoàn thành https://cloudjourney.awsstudygroup.com/ T7.5 5 Resource Groups - Grouping: - Tạo Resource Group dựa trên tag Project:FCJ - Quản lý tập trung tài nguyên 23/10/2025 24/10/2025 Hoàn thành https://cloudjourney.awsstudygroup.com/ T7.6 6 SSM - Run Command: - Sử dụng Run Command - Chạy yum update -y trên toàn bộ instances Env:Dev 24/10/2025 25/10/2025 Hoàn thành https://cloudjourney.awsstudygroup.com/ Kết quả đạt được tuần 7: Tăng cường Bảo mật:\nBề mặt tấn công (Attack Surface) giảm đáng kể Không còn port quản trị nào mở ra Internet Mọi phiên truy cập được log trong CloudTrail và Session Manager logs Có thể ghi hình (record) phiên làm việc để audit Hiệu quả Vận hành:\nĐã thực hiện cập nhật phần mềm cho cả Autoscaling Group chỉ với vài cú click Không cần quản lý SSH keys cho từng user Có thể chạy scripts trên hàng trăm servers cùng lúc Tư duy:\nChuyển từ \u0026ldquo;Quản lý từng máy chủ\u0026rdquo; sang \u0026ldquo;Quản lý đội hình máy chủ\u0026rdquo; (Fleet Management) Hiểu về Zero Trust Network Access Không cần bastion host hay VPN Kỹ năng:\nThành thạo SSM Session Manager Hiểu về IAM Instance Profile Biết cách tổ chức tài nguyên với Tags và Resource Groups Sử dụng SSM Run Command cho automation "},{"uri":"https://github.com/LeThiYenVi/AWS-Report.git/vi/1-worklog/1.8-week8/","title":"Worklog Tuần 8","tags":[],"description":"","content":"Mục tiêu tuần 8: Tự động hóa Hạ tầng: Tái tạo lại kiến trúc mạng (VPC) và máy chủ (EC2) bằng code. Hiểu bản chất: Nắm vững cấu trúc CloudFormation (Parameters, Resources, Outputs). Công cụ Hiện đại: Làm quen với AWS CDK và quy trình cdk init, cdk synth, cdk deploy. Quản lý Vòng đời: Thực hành xóa sạch (Destroy) và tạo lại (Deploy) toàn bộ stack trong vài phút. Các công việc cần triển khai trong tuần này: Task ID Thứ Công việc Ngày bắt đầu Ngày hoàn thành Trạng thái Nguồn tài liệu T8.1 2 CloudFormation - Write Template: - Viết file vpc.yaml định nghĩa VPC - Bao gồm: Subnet, Internet Gateway, Route Table 27/10/2025 27/10/2025 Hoàn thành https://cloudjourney.awsstudygroup.com/ T8.2 2 CloudFormation - Deploy Stack: - Upload file lên CloudFormation Console - Tạo stack FCJ-VPC-Stack - Kiểm tra tài nguyên được tạo 27/10/2025 28/10/2025 Hoàn thành https://cloudjourney.awsstudygroup.com/ T8.3 3 CDK - Init Project: - Cài đặt AWS CDK - Khởi tạo dự án TypeScript: cdk init app --language typescript 28/10/2025 28/10/2025 Hoàn thành https://cloudjourney.awsstudygroup.com/ T8.4 4 CDK - Define S3: - Trong lib/stack.ts, thêm code tạo S3 Bucket - Bật versioning và encryption (L2 Construct) 29/10/2025 29/10/2025 Hoàn thành https://cloudjourney.awsstudygroup.com/ T8.5 5 CDK - Deploy: - Chạy cdk deploy - Quan sát quá trình tạo ChangeSet và thực thi 30/10/2025 30/10/2025 Hoàn thành https://cloudjourney.awsstudygroup.com/ T8.6 5 IaC - Drift Detection: - Thay đổi thủ công tag của S3 bucket trên Console - Chạy Drift Detection để phát hiện sự sai lệch 30/10/2025 31/10/2025 Hoàn thành https://cloudjourney.awsstudygroup.com/ T8.7 6 IaC - Cleanup: - Chạy cdk destroy để xóa toàn bộ tài nguyên - Đảm bảo không sót chi phí 31/10/2025 31/10/2025 Hoàn thành https://cloudjourney.awsstudygroup.com/ Kết quả đạt được tuần 8: Tốc độ:\nCó thể dựng lại toàn bộ môi trường mạng chỉ trong 2 phút chạy lệnh Thay vì 30 phút click chuột thủ công Giảm thiểu human errors Kiểm soát:\nCode hạ tầng được lưu trong Git Xem lại lịch sử thay đổi (Ai đã sửa Subnet? Tại sao?) Code review cho infrastructure changes Version control cho infrastructure Trải nghiệm:\nCDK trực quan và viết ít code hơn CloudFormation thuần túy Nhờ các Construct cấp cao (L2, L3) Có type checking và autocomplete Dễ test infrastructure code Kỹ năng:\nHiểu về Infrastructure as Code (IaC) Nắm vững CloudFormation template structure Thành thạo AWS CDK với TypeScript Biết cách sử dụng Drift Detection Sử dụng AWS CLI để thực hiện các thao tác cơ bản như:\nKiểm tra thông tin tài khoản \u0026amp; cấu hình Lấy danh sách region Xem dịch vụ EC2 Tạo và quản lý key pair Kiểm tra thông tin dịch vụ đang chạy \u0026hellip; Có khả năng kết nối giữa giao diện web và CLI để quản lý tài nguyên AWS song song.\n\u0026hellip;\n"},{"uri":"https://github.com/LeThiYenVi/AWS-Report.git/vi/1-worklog/1.9-week9/","title":"Worklog Tuần 9","tags":[],"description":"","content":"Mục tiêu tuần 9: Minh bạch Mạng: Thu thập và phân tích lưu lượng mạng để phát hiện các kết nối bất thường. Truy vấn Log: Sử dụng CloudWatch Logs Insights để chạy query trên dữ liệu log khổng lồ. Tối ưu Chi phí: Xác định các tài nguyên đang lãng phí và thực hiện \u0026ldquo;Right Sizing\u0026rdquo;. Phân quyền Billing: Cấu hình quyền truy cập Billing cho tài khoản IAM. Các công việc cần triển khai trong tuần này: Task ID Thứ Công việc Ngày bắt đầu Ngày hoàn thành Trạng thái Nguồn tài liệu T9.1 2 VPC - Enable Flow Logs: - Bật Flow Logs cho VPC - Đích đến: CloudWatch Logs Group /aws/vpc/flowlogs 03/11/2025 03/11/2025 Hoàn thành https://cloudjourney.awsstudygroup.com/ T9.2 2 Testing - Generate Deny: - Thử SSH từ IP không có trong Security Group - Tạo ra các bản ghi REJECT 03/11/2025 04/11/2025 Hoàn thành https://cloudjourney.awsstudygroup.com/ T9.3 3 Logs - Insights Query: - Viết query đếm số gói tin bị từ chối theo Source IP - filter action=\u0026quot;REJECT\u0026quot; stats count() by srcAddr 04/11/2025 04/11/2025 Hoàn thành https://cloudjourney.awsstudygroup.com/ T9.4 4 Cost - Compute Optimizer: - Truy cập Compute Optimizer - Xem khuyến nghị (cần ít nhất 12-24h dữ liệu) 05/11/2025 05/11/2025 Hoàn thành https://cloudjourney.awsstudygroup.com/ T9.5 5 Cost - Cost Explorer: - Phân tích chi phí theo ngày và dịch vụ - Group by Service - Xác định EC2 hay RDS tốn nhiều tiền nhất 06/11/2025 06/11/2025 Hoàn thành https://cloudjourney.awsstudygroup.com/ T9.6 6 Report \u0026amp; Recommendations: - Tổng hợp báo cáo chi phí và khuyến nghị tối ưu - Phân tích Flow Logs để tìm vấn đề bảo mật - Đề xuất cải tiến kiến trúc 07/11/2025 07/11/2025 Hoàn thành https://cloudjourney.awsstudygroup.com/ Kết quả đạt được tuần 9: Điều tra số:\nĐã xác định địa chỉ IP nào đang cố quét port SSH Phát hiện các pattern tấn công Có thể trace được network path Tiết kiệm:\nCompute Optimizer chỉ ra instances đang chạy dưới 5% CPU Xác nhận t3.micro phù hợp hoặc có thể gom lại Phát hiện tài nguyên không sử dụng Kỹ năng:\nThành thạo cú pháp query của Logs Insights Kỹ năng quan trọng để xử lý sự cố nhanh Hiểu về VPC Flow Logs format FinOps:\nBiết cách phân tích chi phí theo nhiều chiều Hiểu về Cost Allocation Tags Có thể dự báo chi phí hàng tháng "},{"uri":"https://github.com/LeThiYenVi/AWS-Report.git/vi/1-worklog/1.10-week10/","title":"Worklog Tuần 10","tags":[],"description":"","content":"Mục tiêu tuần 10: Xây dựng API: Tạo RESTful API cho ứng dụng quản lý sách (Book Store). Logic Serverless: Viết các hàm Lambda thực hiện CRUD (Create, Read, Update, Delete). Lưu trữ NoSQL: Thiết kế bảng DynamoDB hiệu năng cao. Tích hợp: Kết nối API Gateway -\u0026gt; Lambda -\u0026gt; DynamoDB. Các công việc cần triển khai trong tuần này: Task ID Thứ Công việc Ngày bắt đầu Ngày hoàn thành Trạng thái Nguồn tài liệu T10.1 2 DynamoDB - Create Table: - Tạo bảng Books với Partition Key là ISBN (String) - Cấu hình chế độ On-Demand Capacity 10/11/2025 10/11/2025 Hoàn thành https://cloudjourney.awsstudygroup.com/ T10.2 2 IAM - Lambda Role: - Tạo Role cho Lambda - Quyền: PutItem, GetItem, Scan trên bảng Books - Quyền ghi log CloudWatch 10/11/2025 11/11/2025 Hoàn thành https://cloudjourney.awsstudygroup.com/ T10.3 3 Lambda - Function Logic: - Viết hàm add_book (Python) nhận JSON và ghi DynamoDB - Viết hàm get_books để đọc dữ liệu 11/11/2025 12/11/2025 Hoàn thành https://cloudjourney.awsstudygroup.com/ T10.4 4 API Gateway - REST API: - Tạo API BookStoreAPI - Tạo resource /books và method POST, GET - Tích hợp với Lambda functions 12/11/2025 13/11/2025 Hoàn thành https://cloudjourney.awsstudygroup.com/ T10.5 5 API Gateway - Deploy: - Deploy API ra Stage dev - Lấy Invoke URL 13/11/2025 14/11/2025 Hoàn thành https://cloudjourney.awsstudygroup.com/ T10.6 6 Testing - Postman: - Gửi POST request thêm sách - Gửi GET request kiểm tra danh sách trả về 14/11/2025 14/11/2025 Hoàn thành https://cloudjourney.awsstudygroup.com/ Kết quả đạt được tuần 10: Sản phẩm:\nMột backend API hoàn chỉnh hoạt động Không cần bất kỳ máy chủ nào (No EC2) Truly serverless architecture Hiệu năng:\nTốc độ phản hồi cực nhanh (\u0026lt; 100ms) Khả năng chịu tải hàng nghìn request/giây mặc định Auto scaling không cần cấu hình Chi phí:\nGần như $0 trong giai đoạn phát triển Nhờ Free Tier của Lambda và DynamoDB Pay-per-request model Kiến trúc:\nHiểu về Microservices architecture Event-driven programming API-first design NoSQL data modeling "},{"uri":"https://github.com/LeThiYenVi/AWS-Report.git/vi/1-worklog/1.11-week11/","title":"Worklog Tuần 11","tags":[],"description":"","content":"Mục tiêu tuần 11: Kiểm toán Kiến trúc: Đánh giá lại toàn bộ hạ tầng dựa trên AWS Well-Architected Tool. Quản lý Hạn mức: Kiểm tra Service Quotas và hiểu quy trình yêu cầu tăng hạn mức. Vệ sinh Tài nguyên: Tìm và xóa tài nguyên \u0026ldquo;mồ côi\u0026rdquo; (Orphaned resources). Ngân sách Nâng cao: Thiết lập AWS Budgets với cảnh báo dự báo (Forecasted breach). Các công việc cần triển khai trong tuần này: Task ID Thứ Công việc Ngày bắt đầu Ngày hoàn thành Trạng thái Nguồn tài liệu T11.1 2 Governance - Quota Check: - Kiểm tra hạn mức vCPU cho dòng instance - Running On-Demand Standard instances 17/11/2025 17/11/2025 Hoàn thành https://cloudjourney.awsstudygroup.com/ T11.2 2 Cost - Budget Forecast: - Tạo Budget cảnh báo nếu dự báo cuối tháng vượt $10 - Thay vì đợi vượt rồi mới báo 17/11/2025 18/11/2025 Hoàn thành https://cloudjourney.awsstudygroup.com/ T11.3 3 WAF - Tool Review: - Mở AWS Well-Architected Tool - Tạo Workload mới - Trả lời câu hỏi trong trụ cột Security 18/11/2025 18/11/2025 Hoàn thành https://cloudjourney.awsstudygroup.com/ T11.4 4 Cleanup - EBS Audit: - Tìm EBS Volume có trạng thái Available - Xóa để cắt giảm chi phí 19/11/2025 19/11/2025 Hoàn thành https://cloudjourney.awsstudygroup.com/ T11.5 5 Cleanup - EIP Audit: - Release Elastic IP không gắn vào instance nào - AWS tính phí phạt cho EIP không sử dụng 20/11/2025 20/11/2025 Hoàn thành https://cloudjourney.awsstudygroup.com/ T11.6 6 Documentation \u0026amp; Best Practices: - Tổng hợp tài liệu Well-Architected Review - Viết báo cáo khuyến nghị cải tiến - Cập nhật architecture diagram với các findings 21/11/2025 21/11/2025 Hoàn thành https://cloudjourney.awsstudygroup.com/ Kết quả đạt được tuần 11: Báo cáo rủi ro:\nWell-Architected Tool chỉ ra High Risk Issue Database Tuần 4 đang chạy Single-AZ Nếu AZ sập, DB mất kết nối Cần cân nhắc Multi-AZ cho production Tối ưu:\nĐã xóa 2 volume EBS 10GB còn sót lại Tiết kiệm khoảng $2/tháng Release 1 Elastic IP không dùng Tránh phí phạt $3.6/tháng Nhận thức:\n\u0026ldquo;Kiến trúc tốt\u0026rdquo; là quá trình liên tục Không phải đích đến Cần review và cải thiện thường xuyên Well-Architected Framework là kim chỉ nam Governance:\nHiểu về Service Quotas và Limits Biết cách request tăng quota Có thể dự báo khi cần scale Proactive capacity planning "},{"uri":"https://github.com/LeThiYenVi/AWS-Report.git/vi/1-worklog/1.12-week12/","title":"Worklog Tuần 12","tags":[],"description":"","content":"Mục tiêu tuần 12: Tổng hợp Kiến thức: Triển khai dự án cuối khóa (Capstone) kết hợp IaaS và PaaS. Chứng nhận: Hoàn thành bài thi thử (Mock Exam) cho chứng chỉ SAA-C03 với điểm số \u0026gt;70%. Hồ sơ Năng lực: Cập nhật CV, GitHub Profile với các dự án đã làm. Dọn dẹp: Hủy bỏ toàn bộ tài nguyên để tránh phát sinh chi phí sau khóa học. Các công việc cần triển khai trong tuần này: Task ID Thứ Công việc Ngày bắt đầu Ngày hoàn thành Trạng thái Nguồn tài liệu T12.1 2 Capstone - Architecture: - Vẽ sơ đồ kiến trúc cho dự án cuối khóa (AWS Icons) - Bao gồm: ALB, ASG, RDS, S3, CloudFront 24/11/2025 24/11/2025 Hoàn thành https://cloudjourney.awsstudygroup.com/ T12.2 3 Capstone - Deployment: - Triển khai dự án sử dụng CDK hoặc CloudFormation - Đảm bảo ứng dụng chạy tốt, kết nối DB thành công 25/11/2025 26/11/2025 Hoàn thành https://cloudjourney.awsstudygroup.com/ T12.3 4 Career - Community: - Tham gia nhóm \u0026ldquo;AWS Study Group\u0026rdquo; trên Facebook/LinkedIn - Kết nối với các mentor FCJ Workforce 26/11/2025 27/11/2025 Hoàn thành https://cloudjourney.awsstudygroup.com/ T12.4 5 Exam - Practice Test: - Làm bài test 65 câu trong 130 phút (mô phỏng thi thật) - Review các câu sai 27/11/2025 28/11/2025 Hoàn thành https://cloudjourney.awsstudygroup.com/ T12.5 6 Cleanup - NUKE: - Sử dụng công cụ aws-nuke (hoặc xóa thủ công) - Dọn sạch tài khoản - Kiểm tra lại ở mọi Region 28/11/2025 30/11/2025 Hoàn thành https://cloudjourney.awsstudygroup.com/ Kết quả đạt được tuần 12: Sản phẩm:\nMột GitHub Repository chứa code CDK Kiến trúc 3-Tier chuẩn mực Documentation đầy đủ README với architecture diagram Tự tin:\nSẵn sàng cho kỳ thi chứng chỉ AWS SAA-C03 Sẵn sàng cho phỏng vấn thực tập sinh Cloud Có portfolio để showcase Hiểu rõ các dịch vụ AWS core Hoàn tất:\nTài khoản AWS sạch sẽ Không còn chi phí phát sinh Đã backup tất cả artifacts quan trọng Sẵn sàng cho hành trình tiếp theo Hành trình:\nTừ \u0026ldquo;không biết gì\u0026rdquo; về Cloud Đến \u0026ldquo;AWS Builder\u0026rdquo; thực thụ 12 tuần = 84 ngày thay đổi Foundation vững chắc cho career Cloud Engineer "},{"uri":"https://github.com/LeThiYenVi/AWS-Report.git/vi/categories/","title":"Categories","tags":[],"description":"","content":""},{"uri":"https://github.com/LeThiYenVi/AWS-Report.git/vi/tags/","title":"Tags","tags":[],"description":"","content":""}]